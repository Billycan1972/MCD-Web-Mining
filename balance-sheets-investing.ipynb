{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping datos balance anuales investing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_balance_sheet(tk):\n",
    "    dfs = []\n",
    "    # Configurar el navegador\n",
    "    # chrome_options = Options()\n",
    "    # chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome()\n",
    "    try:\n",
    "        # Abrir la URL\n",
    "        url = f\"https://es.investing.com/equities/{tk}-balance-sheet\"\n",
    "        driver.get(url)\n",
    "\n",
    "        # Esperar a que al menos una tabla esté presente\n",
    "        \n",
    "        wait = WebDriverWait(driver, 5)\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, \"table\")))\n",
    "\n",
    "        # Obtener el HTML de la página\n",
    "        page_html = driver.page_source\n",
    "\n",
    "        # Parsear el HTML de la página con BeautifulSoup\n",
    "        soup = BeautifulSoup(page_html, \"html.parser\")\n",
    "\n",
    "        # Encontrar todas las tablas en la página\n",
    "        tables = soup.find_all(\"table\")\n",
    "\n",
    "        # Procesar cada tabla\n",
    "        for i, table in enumerate(tables):\n",
    "            # Extraer las filas de la tabla\n",
    "            rows = table.find_all(\"tr\")\n",
    "            data = []\n",
    "            for row in rows:\n",
    "                cells = row.find_all([\"td\", \"th\"])  # Buscar celdas (td) y encabezados (th)\n",
    "                cell_texts = [cell.get_text(strip=True) for cell in cells]\n",
    "                data.append(cell_texts)\n",
    "\n",
    "            # Convertir los datos en un DataFrame de Pandas\n",
    "            df = pd.DataFrame(data)\n",
    "            dfs.append(df)\n",
    "        print(\"exito al procesar!\")\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"Error: No se encontraron tablas en la página.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        # Cerrar el navegador\n",
    "        driver.quit()\n",
    "        time.sleep(5)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procesamiento de datos capturados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_tab(df):\n",
    "  titulos = df[1].T[0].dropna().reset_index(drop=True).tolist()[1:]\n",
    "  titulos[0] = \"indicador\"\n",
    "\n",
    "  result = pd.DataFrame()\n",
    "   \n",
    "  estructura = [\n",
    "  {\"seccion\":\"activo_corriente\", \"rubros\":2,\"valores\":3},\n",
    "  {\"seccion\":\"activo_total\", \"rubros\":4,\"valores\":5},\n",
    "  {\"seccion\":\"pasivo_corriente\", \"rubros\":6,\"valores\":7},\n",
    "  {\"seccion\":\"pasivo_total\", \"rubros\":8,\"valores\":9},\n",
    "  {\"seccion\":\"patrimonio_neto\", \"rubros\":10,\"valores\":11},\n",
    "  {\"seccion\":\"crecimiento_deuda\", \"rubros\":14,\"valores\":15},\n",
    "]\n",
    "  for e in estructura:\n",
    "    try:\n",
    "      data =  pd.concat([df[e[\"rubros\"]][1],df[e[\"valores\"]]], axis=1)\n",
    "      data.columns = titulos\n",
    "      data.replace(\"aa.aa\",None,inplace=True)\n",
    "      data.dropna(inplace=True, axis=1)\n",
    "      data[\"seccion\"] = e[\"seccion\"]\n",
    "      result = pd.concat([result, data.reset_index(drop=True)], axis=0)\n",
    "    except:\n",
    "      pass\n",
    "    \n",
    "  return result.set_index(\"indicador\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista de Empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [\n",
    "  #  \"apple-computer-inc\",\n",
    "  # \"microsoft-corp\",\n",
    "  # \"google-inc\",\n",
    "  # \"tesla-motors\",\n",
    "  # \"visa-inc\",\n",
    "  # \"berkshire-hathaway-inc\",\n",
    "  # \"johnson-johnson\",\n",
    "  # \"pfizer\",\n",
    "  # \"amazon-com-inc\",\n",
    "  # \"disney\",\n",
    "  \"nike\",\n",
    "  # \"procter-gamble\",\n",
    "  # \"coca-cola-co\",\n",
    "  # \"chevron\",\n",
    "  # \"3m-co\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in companies:\n",
    "  print(f\"Procesando {company}\")\n",
    "  dfs = get_balance_sheet(company)\n",
    "  if len(dfs) > 1:\n",
    "    df = procesar_tab(dfs)\n",
    "    df.to_csv(f\"balance-sheet/{company}.csv\",encoding=\"utf-8-sig\")\n",
    "    print(f\"Guardado {company}.csv\")\n",
    "  else:\n",
    "    print(f\"Error al procesar {company}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
