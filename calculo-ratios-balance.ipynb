{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo de Ratios\n",
    "\n",
    "#### liquidez\n",
    "* Razón corriente = Activos corrientes / Pasivos corrientes\n",
    "* Prueba ácida = (Activo corriente - Inventarios) / Pasivo corriente\n",
    "\n",
    "#### Solvencia y endeudamiento\n",
    "* Endeudamiento total = Total de pasivos / Total de activos\n",
    "* Endeudamiento de largo plazo = Pasivo no corriente / Total de activos\n",
    "* Cobertura de intereses = EBIT / Gastos por intereses\n",
    "\n",
    "#### Rentabilidad\n",
    "* ROA (Return on Assets) = Beneficio neto / Activo total\n",
    "* ROE (Return on Equity) =  Beneficio neto / Patrimonio neto\n",
    "* Margen de utilidad = \tBeneficio neto / Ventas (ingresos totales) (escrapeado \"Margen del beneficio neto %\")\n",
    "* Rotación de activos = ingresos totales / Total de activos\n",
    "* Rotación de inventarios = ingresos totales / Inventario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "# Consultar datos\n",
    "conn = sqlite3.connect('webmining.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT * FROM datos_anuales\")\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "filas = cursor.fetchall()\n",
    "\n",
    "# Guardar los datos en un dataframe\n",
    "df = pd.DataFrame(filas, columns=column_names)\n",
    "df.loc[df[\"company\"] == \"ypf-sa\", \"company\"] = \"YPF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "informe     seccion            indicador                                                 \n",
      "balance     activo_corriente   Crecimiento de efectivo y equivalentes                        75\n",
      "                               Créditos totales                                              75\n",
      "                               Efectivo restringido                                          29\n",
      "                               Efectivo y equivalentes                                       75\n",
      "                               Gastos pagados por adelantado                                 43\n",
      "                               Inventario                                                    67\n",
      "                               Inversiones a corto plazo                                     63\n",
      "                               Otros activos corrientes                                      71\n",
      "                               Otros créditos                                                46\n",
      "                               Total de cuentas por cobrar                                   75\n",
      "                               Total de otros activos corrientes                             61\n",
      "            activo_total       Activos intangibles                                           70\n",
      "                               Activos por impuestos diferidos a largo plazo                 50\n",
      "                               Amortización acumulada                                        75\n",
      "                               Cargos diferidos a largo plazo                                 8\n",
      "                               Crecimiento de activos totales                                75\n",
      "                               Cuentas por cobrar a largo plazo                              19\n",
      "                               Fondo de comercio                                             65\n",
      "                               Inmovilizado material bruto                                   75\n",
      "                               Inversiones a largo plazo                                     62\n",
      "                               Otros intangibles, total                                      62\n",
      "                               Planta, propiedad y equipo, neto                              75\n",
      "                               Préstamos por cobrar a largo plazo                            10\n",
      "                               Total de otros activos                                        75\n",
      "                               Total de otros activos a largo plazo                          75\n",
      "            crecimiento_deuda  Crecimiento de la deuda total                                 75\n",
      "            pasivo_corriente   Impuestos corrientes sobre la renta a pagar                   64\n",
      "                               Otros pasivos corrientes                                      68\n",
      "                               Parte actual de arrendamientos                                75\n",
      "                               Parte actual de la deuda a largo plazo                        65\n",
      "                               Parte actual de la deuda a largo plazo/arrendamientos         75\n",
      "                               Préstamos a corto plazo                                       53\n",
      "                               Total de cuentas por pagar                                    75\n",
      "                               Total de gastos devengados                                    65\n",
      "                               Total de otros pasivos corrientes                             75\n",
      "                               total de ingresos corrientes no devengados                    45\n",
      "            pasivo_total       Arrendamientos a largo plazo                                  75\n",
      "                               Crecimiento del pasivo total                                  75\n",
      "                               Deuda a largo plazo                                           75\n",
      "                               Ingresos no devengados no corrientes                          30\n",
      "                               Otros pasivos no corrientes                                   75\n",
      "                               Pasivos por impuestos no corrientes diferidos                 60\n",
      "                               Pensiones y otras prestaciones posteriores a la jubilación    31\n",
      "                               Total de otros pasivos                                        75\n",
      "            patrimonio_neto    Acciones ordinarias y APIC                                    75\n",
      "                               Acciones preferentes convertibles                             10\n",
      "                               Acciones propias                                              45\n",
      "                               Acciones propias y otras                                      75\n",
      "                               Capital pagado adicional                                      53\n",
      "                               Ganancias retenidas                                           75\n",
      "                               Ingresos globales y otros                                     75\n",
      "                               Intereses minoritarios                                        45\n",
      "                               Total de acciones ordinarias                                  72\n",
      "                               Total de acciones preferentes                                 10\n",
      "resultados                     BPA básico: Crecimiento de actividades continuadas            75\n",
      "                               BPA básico: crecimiento de actividades continuadas            75\n",
      "                               BPA diluido: Actividades continuadas                          75\n",
      "                               BPA diluido: Crecimiento de actividades continuadas           75\n",
      "                               Beneficio bruto                                               75\n",
      "                               Beneficio neto                                                75\n",
      "                               Beneficio neto sobre ingresos ordinarios                      75\n",
      "                               Beneficios netos para la empresa                              75\n",
      "                               Coste de los ingresos                                         75\n",
      "                               Crecimiento de gastos netos por intereses                     72\n",
      "                               Crecimiento de los ingresos totales                           75\n",
      "                               Crecimiento del EBITDA                                        75\n",
      "                               Crecimiento del EBT incluidas las partidas inusuales          75\n",
      "                               Crecimiento del beneficio bruto                               75\n",
      "                               Crecimiento del beneficio neto                                75\n",
      "                               Crecimiento del dividendo por acción                          46\n",
      "                               Crecimiento del margen neto                                   75\n",
      "                               Dividendo por acción                                          48\n",
      "                               Dividendo preferente y otros ajustes                          15\n",
      "                               EBIT                                                          75\n",
      "                               EBITDA                                                        75\n",
      "                               EBT excepto elementos no habituales                           75\n",
      "                               EBT incluyendo las partidas inusuales                         75\n",
      "                               Ganancia (pérdida) de la venta de activos                     16\n",
      "                               Gastos netos por intereses                                    72\n",
      "                               Impuesto sobre la renta                                       75\n",
      "                               Ingresos por intereses e inversiones                          61\n",
      "                               Ingresos totales                                              75\n",
      "                               Intereses minoritarios                                        45\n",
      "                               Margen EBIT %                                                 75\n",
      "                               Margen EBITDA %                                               75\n",
      "                               Margen de beneficio bruto %                                   75\n",
      "                               Margen del EBT incluidas las partidas inusuales               75\n",
      "                               Margen del beneficio neto %                                   75\n",
      "                               Margen neto                                                   75\n",
      "                               Promedio ponderado básico de acciones en circulación          75\n",
      "                               Promedio ponderado diluido de acciones en circulación         75\n",
      "                               Total de gastos de intereses                                  72\n",
      "                               Total de otras partidas no habituales                         39\n",
      "                               Total de otros gastos no operativos                           75\n",
      "                               Total de otros gastos operativos                              70\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "indicadores = df.groupby([\"informe\",\"seccion\",\"indicador\"]).size()\n",
    "\n",
    "print(indicadores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rubros que componen cada seccion\n",
    "# no se incluye por ejemplo el rubro \"otros creditos\" ya que forma parte de \"Creditos totales\"\n",
    "activo_corriente = [\n",
    "    \"Efectivo y equivalentes\",\n",
    "    \"Inversiones a corto plazo\",\n",
    "    \"Créditos totales\",\n",
    "    \"Inventario\",\n",
    "    \"Gastos pagados por adelantado\",\n",
    "    \"Otros activos corrientes\"\n",
    "]\n",
    "activo_no_corriente = [\n",
    "    \"Planta, propiedad y equipo, neto\",\n",
    "    \"Inversiones a largo plazo\",\n",
    "    \"Activos intangibles\",\n",
    "    \"Total de otros activos\"\n",
    "]\n",
    "pasivo_corriente = [\n",
    "    \"Total de cuentas por pagar\",\n",
    "    \"Total de gastos devengados\",\n",
    "    \"Préstamos a corto plazo\",\n",
    "    \"Parte actual de la deuda a largo plazo/arrendamientos\",\n",
    "    \"Total de otros pasivos corrientes\"\n",
    "]\n",
    "pasivo_no_corriente = [\n",
    "    \"Deuda a largo plazo\",\n",
    "    \"Arrendamientos a largo plazo\",\n",
    "    \"Total de otros pasivos\"\n",
    "]\n",
    "patrimonio_neto = [\n",
    "    \"Total de acciones preferentes\",\n",
    "    \"Acciones ordinarias y APIC\",\n",
    "    \"Ganancias retenidas\",\n",
    "    \"Acciones propias y otras\",\n",
    "    \"Intereses minoritarios\"\n",
    "]\n",
    "\n",
    "inventario = [\"Inventario\"]\n",
    "\n",
    "EBIT = [\"EBIT\"]\n",
    "\t\n",
    "intereses = [\"Total de gastos de intereses\"]\n",
    "\n",
    "beneficio_neto = [\"Beneficio neto\"]\n",
    "\n",
    "mbn = [\"Margen del beneficio neto %\"]\n",
    "\n",
    "ing = [\"Ingresos totales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features de indicadores ya escrapeados\n",
    "\n",
    "indicadores_scrapeados = [\n",
    "  \"Crecimiento de efectivo y equivalentes\",\n",
    "  \"Crecimiento de activos totales\",\n",
    "  \"Crecimiento del pasivo total\",\n",
    "  \"Crecimiento de la deuda total\",\n",
    "  \"Crecimiento del beneficio neto\",\n",
    "  \"Crecimiento del EBITDA\",\n",
    "  \"Crecimiento de los ingresos totales\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('company', 'ejercicio')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "activo_corriente",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "activo_no_corriente",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pasivo_corriente",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pasivo_no_corriente",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "patrimonio_neto",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "inventario",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "EBIT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "intereses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "beneficio_neto",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "margen_beneficio_neto",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ingresos_totales",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a7332c2d-bde5-4672-9466-c0603904a0d6",
       "rows": [
        [
         "('3m-co', 2020)",
         "14975.0",
         "32362.0",
         "7948.0",
         "26465.0",
         "12927.0",
         "4239.0",
         "7156.0",
         "-529.0",
         "5449.0",
         "16.93",
         "32184.0"
        ],
        [
         "('3m-co', 2021)",
         "15403.0",
         "31669.0",
         "9035.0",
         "22920.0",
         "15109.0",
         "4985.0",
         "7754.0",
         "-488.0",
         "5921.0",
         "16.75",
         "35355.0"
        ],
        [
         "('3m-co', 2022)",
         "14688.0",
         "31767.0",
         "9523.0",
         "22162.0",
         "14756.0",
         "5372.0",
         "3348.0",
         "-462.0",
         "5777.0",
         "22.08",
         "26161.0"
        ],
        [
         "('3m-co', 2023)",
         "16379.0",
         "34201.0",
         "15297.0",
         "30415.0",
         "4852.0",
         "3944.0",
         "4281.0",
         "-941.0",
         "-6995.0",
         "-28.42",
         "24610.0"
        ],
        [
         "('3m-co', 2024)",
         "15884.0",
         "23984.0",
         "11256.0",
         "24718.0",
         "3879.0",
         "3698.0",
         "4290.0",
         "-1191.0",
         "4173.0",
         "16.98",
         "24575.0"
        ],
        [
         "('YPF', 2020)",
         "317687.0",
         "1595656.0",
         "370669.0",
         "869161.0",
         "684763.0",
         "100137.0",
         "-67821.0",
         "-65821.0",
         "-69649.0",
         "-10.06",
         "692514.0"
        ],
        [
         "('YPF', 2021)",
         "456211.0",
         "1923825.0",
         "391078.0",
         "1150872.0",
         "849183.0",
         "153927.0",
         "94934.0",
         "-71870.0",
         "257.0",
         "0.02",
         "1315633.0"
        ],
        [
         "('YPF', 2022)",
         "897680.0",
         "3677450.0",
         "846905.0",
         "1872950.0",
         "1867097.0",
         "307766.0",
         "287344.0",
         "-90151.0",
         "289057.0",
         "11.44",
         "2526466.0"
        ],
        [
         "('YPF', 2023)",
         "3486126.0",
         "16624393.0",
         "3969790.0",
         "8928518.0",
         "7275343.0",
         "1357716.0",
         "157574.0",
         "-227085.0",
         "-1561217.0",
         "-28.47",
         "5484544.0"
        ],
        [
         "('YPF', 2024)",
         "6598756.0",
         "23287159.0",
         "8939509.0",
         "9115828.0",
         "12186627.0",
         "1593666.0",
         "1597061.0",
         "-608969.0",
         "2077482.0",
         "11.61",
         "17895031.0"
        ],
        [
         "('amazon-com-inc', 2020)",
         "132733.0",
         "188462.0",
         "126385.0",
         "101406.0",
         "93404.0",
         "23795.0",
         "22899.0",
         "-1647.0",
         "21331.0",
         "5.53",
         "386064.0"
        ],
        [
         "('amazon-com-inc', 2021)",
         "161580.0",
         "258969.0",
         "142266.0",
         "140038.0",
         "138245.0",
         "32640.0",
         "24879.0",
         "-1809.0",
         "33364.0",
         "7.1",
         "469822.0"
        ],
        [
         "('amazon-com-inc', 2022)",
         "146791.0",
         "315884.0",
         "155393.0",
         "161239.0",
         "146043.0",
         "34405.0",
         "13348.0",
         "-2367.0",
         "-2722.0",
         "-0.53",
         "513983.0"
        ],
        [
         "('amazon-com-inc', 2023)",
         "172351.0",
         "355503.0",
         "164917.0",
         "161062.0",
         "201875.0",
         "33318.0",
         "36852.0",
         "-3182.0",
         "30425.0",
         "5.29",
         "574785.0"
        ],
        [
         "('amazon-com-inc', 2024)",
         "190867.0",
         "434027.0",
         "179431.0",
         "159493.0",
         "285970.0",
         "34214.0",
         "68593.0",
         "-2406.0",
         "59248.0",
         "9.29",
         "637959.0"
        ],
        [
         "('apple-computer-inc', 2020)",
         "143713.0",
         "180175.0",
         "105392.0",
         "153157.0",
         "65339.0",
         "4061.0",
         "66288.0",
         "-2873.0",
         "57411.0",
         "20.91",
         "274515.0"
        ],
        [
         "('apple-computer-inc', 2021)",
         "134836.0",
         "216166.0",
         "125481.0",
         "162431.0",
         "63090.0",
         "6580.0",
         "108949.0",
         "-2645.0",
         "94680.0",
         "25.88",
         "365817.0"
        ],
        [
         "('apple-computer-inc', 2022)",
         "135405.0",
         "217350.0",
         "153982.0",
         "148101.0",
         "50672.0",
         "4946.0",
         "119437.0",
         null,
         "99803.0",
         "25.31",
         "394328.0"
        ],
        [
         "('apple-computer-inc', 2023)",
         "143566.0",
         "209017.0",
         "145308.0",
         "145129.0",
         "62146.0",
         "6331.0",
         "114301.0",
         null,
         "96995.0",
         "25.31",
         "383285.0"
        ],
        [
         "('apple-computer-inc', 2024)",
         "152987.0",
         "211993.0",
         "176392.0",
         "131638.0",
         "56950.0",
         "7286.0",
         "123216.0",
         null,
         "93736.0",
         "23.97",
         "391035.0"
        ],
        [
         "('berkshire-hathaway-inc', 2020)",
         "194026.0",
         "679703.0",
         "45626.0",
         "376767.0",
         "450604.0",
         "19208.0",
         "69790.0",
         "-4083.0",
         "42521.0",
         "17.31",
         "245579.0"
        ],
        [
         "('berkshire-hathaway-inc', 2021)",
         "208089.0",
         "750695.0",
         "45234.0",
         "398620.0",
         "513918.0",
         "20954.0",
         "115147.0",
         "-4172.0",
         "89937.0",
         "32.56",
         "276185.0"
        ],
        [
         "('berkshire-hathaway-inc', 2022)",
         "203413.0",
         "745052.0",
         "49540.0",
         "417244.0",
         "480920.0",
         "25366.0",
         "-28011.0",
         "-4352.0",
         "-22759.0",
         "-7.54",
         "302020.0"
        ],
        [
         "('berkshire-hathaway-inc', 2023)",
         "245712.0",
         "824266.0",
         "56986.0",
         "442222.0",
         "569846.0",
         "25856.0",
         "123196.0",
         "-5003.0",
         "96223.0",
         "26.4",
         "364482.0"
        ],
        [
         "('berkshire-hathaway-inc', 2024)",
         "407447.0",
         "746434.0",
         "75652.0",
         "426574.0",
         "651089.0",
         "24008.0",
         "113735.0",
         "-5200.0",
         "88995.0",
         "23.96",
         "371433.0"
        ],
        [
         "('chevron', 2020)",
         "26078.0",
         "213712.0",
         "22183.0",
         "84881.0",
         "132744.0",
         "5676.0",
         "-4252.0",
         "-697.0",
         "-5543.0",
         "-5.9",
         "94005.0"
        ],
        [
         "('chevron', 2021)",
         "33738.0",
         "205797.0",
         "26791.0",
         "72804.0",
         "139876.0",
         "6795.0",
         "16087.0",
         "-712.0",
         "15625.0",
         "10.08",
         "155067.0"
        ],
        [
         "('chevron', 2022)",
         "50343.0",
         "207366.0",
         "34208.0",
         "63259.0",
         "160099.0",
         "8247.0",
         "42005.0",
         "-516.0",
         "35465.0",
         "15.03",
         "235916.0"
        ],
        [
         "('chevron', 2023)",
         "41128.0",
         "220504.0",
         "32258.0",
         "67445.0",
         "161887.0",
         "8612.0",
         "26964.0",
         "-469.0",
         "21369.0",
         "10.97",
         "194799.0"
        ],
        [
         "('chevron', 2024)",
         "40911.0",
         "216027.0",
         "38558.0",
         "65223.0",
         "153069.0",
         "9074.0",
         "23299.0",
         "-594.0",
         "17661.0",
         "9.03",
         "195568.0"
        ],
        [
         "('coca-cola-co', 2020)",
         "19240.0",
         "68056.0",
         "14601.0",
         "51411.0",
         "21263.0",
         "3266.0",
         "9992.0",
         "-1437.0",
         "7747.0",
         "23.47",
         "33014.0"
        ],
        [
         "('coca-cola-co', 2021)",
         "22544.0",
         "71809.0",
         "19950.0",
         "49544.0",
         "24827.0",
         "3414.0",
         "11433.0",
         "-1597.0",
         "9771.0",
         "25.28",
         "38655.0"
        ],
        [
         "('coca-cola-co', 2022)",
         "22591.0",
         "70172.0",
         "19724.0",
         "47213.0",
         "25797.0",
         "4233.0",
         "12341.0",
         "-882.0",
         "9542.0",
         "22.19",
         "43004.0"
        ],
        [
         "('coca-cola-co', 2023)",
         "26732.0",
         "70971.0",
         "23571.0",
         "46652.0",
         "27491.0",
         "4424.0",
         "13246.0",
         "-1527.0",
         "10714.0",
         "23.42",
         "45754.0"
        ],
        [
         "('coca-cola-co', 2024)",
         "25997.0",
         "74552.0",
         "25249.0",
         "48928.0",
         "26354.0",
         "4728.0",
         "14301.0",
         "-1656.0",
         "10631.0",
         "22.59",
         "47061.0"
        ],
        [
         "('disney', 2020)",
         "35251.0",
         "166298.0",
         "26628.0",
         "77409.0",
         "97122.0",
         "3754.0",
         "3781.0",
         "-1647.0",
         "-2864.0",
         "-4.38",
         "65388.0"
        ],
        [
         "('disney', 2021)",
         "33657.0",
         "169952.0",
         "31077.0",
         "70308.0",
         "101712.0",
         "3514.0",
         "3492.0",
         "-1546.0",
         "1995.0",
         "2.96",
         "67418.0"
        ],
        [
         "('disney', 2022)",
         "29098.0",
         "174533.0",
         "29073.0",
         "66180.0",
         "108018.0",
         "3632.0",
         "6832.0",
         "-1549.0",
         "3145.0",
         "3.8",
         "82722.0"
        ],
        [
         "('disney', 2023)",
         "32763.0",
         "172816.0",
         "31139.0",
         "61428.0",
         "111976.0",
         "4965.0",
         "9332.0",
         "-1973.0",
         "2354.0",
         "2.65",
         "88898.0"
        ],
        [
         "('disney', 2024)",
         "25241.0",
         "170978.0",
         "34599.0",
         "56098.0",
         "104721.0",
         "4119.0",
         "12318.0",
         "-2070.0",
         "4972.0",
         "5.44",
         "91361.0"
        ],
        [
         "('google-inc', 2020)",
         "174296.0",
         "145320.0",
         "56834.0",
         "40238.0",
         "222544.0",
         "728.0",
         "41224.0",
         "-135.0",
         "40269.0",
         "22.06",
         "182527.0"
        ],
        [
         "('google-inc', 2021)",
         "188143.0",
         "171125.0",
         "64254.0",
         "43379.0",
         "251635.0",
         "1170.0",
         "78714.0",
         "-346.0",
         "76033.0",
         "29.51",
         "257637.0"
        ],
        [
         "('google-inc', 2022)",
         "164795.0",
         "200469.0",
         "69300.0",
         "39820.0",
         "256144.0",
         null,
         "74842.0",
         "-357.0",
         "59972.0",
         "21.2",
         "282836.0"
        ],
        [
         "('google-inc', 2023)",
         "171530.0",
         "230862.0",
         "81814.0",
         "37199.0",
         "283379.0",
         null,
         "84293.0",
         "-308.0",
         "73795.0",
         "24.01",
         "307394.0"
        ],
        [
         "('google-inc', 2024)",
         "163711.0",
         "286545.0",
         "89122.0",
         "36050.0",
         "325084.0",
         null,
         "114186.0",
         "-268.0",
         "100118.0",
         "28.6",
         "350018.0"
        ],
        [
         "('microsoft-corp', 2020)",
         "181915.0",
         "119396.0",
         "72310.0",
         "110697.0",
         "118304.0",
         "1895.0",
         "52959.0",
         "-2591.0",
         "44281.0",
         "30.96",
         "143015.0"
        ],
        [
         "('microsoft-corp', 2021)",
         "184406.0",
         "149373.0",
         "88657.0",
         "103134.0",
         "141988.0",
         "2636.0",
         "69916.0",
         "-2330.0",
         "61271.0",
         "36.45",
         "168088.0"
        ],
        [
         "('microsoft-corp', 2022)",
         "169684.0",
         "195156.0",
         "95082.0",
         "103216.0",
         "166542.0",
         "3742.0",
         "83383.0",
         "-2047.0",
         "72738.0",
         "36.69",
         "198270.0"
        ],
        [
         "('microsoft-corp', 2023)",
         "184257.0",
         "227719.0",
         "104149.0",
         "101604.0",
         "206223.0",
         "2500.0",
         "88675.0",
         "-1995.0",
         "72361.0",
         "34.15",
         "211915.0"
        ],
        [
         "('microsoft-corp', 2024)",
         "159734.0",
         "352429.0",
         "125286.0",
         "118400.0",
         "268477.0",
         "1246.0",
         "109433.0",
         "-2983.0",
         "88136.0",
         "35.96",
         "245122.0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 75
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>activo_corriente</th>\n",
       "      <th>activo_no_corriente</th>\n",
       "      <th>pasivo_corriente</th>\n",
       "      <th>pasivo_no_corriente</th>\n",
       "      <th>patrimonio_neto</th>\n",
       "      <th>inventario</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>intereses</th>\n",
       "      <th>beneficio_neto</th>\n",
       "      <th>margen_beneficio_neto</th>\n",
       "      <th>ingresos_totales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <th>ejercicio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3m-co</th>\n",
       "      <th>2020</th>\n",
       "      <td>14975.0</td>\n",
       "      <td>32362.0</td>\n",
       "      <td>7948.0</td>\n",
       "      <td>26465.0</td>\n",
       "      <td>12927.0</td>\n",
       "      <td>4239.0</td>\n",
       "      <td>7156.0</td>\n",
       "      <td>-529.0</td>\n",
       "      <td>5449.0</td>\n",
       "      <td>16.93</td>\n",
       "      <td>32184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>15403.0</td>\n",
       "      <td>31669.0</td>\n",
       "      <td>9035.0</td>\n",
       "      <td>22920.0</td>\n",
       "      <td>15109.0</td>\n",
       "      <td>4985.0</td>\n",
       "      <td>7754.0</td>\n",
       "      <td>-488.0</td>\n",
       "      <td>5921.0</td>\n",
       "      <td>16.75</td>\n",
       "      <td>35355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>14688.0</td>\n",
       "      <td>31767.0</td>\n",
       "      <td>9523.0</td>\n",
       "      <td>22162.0</td>\n",
       "      <td>14756.0</td>\n",
       "      <td>5372.0</td>\n",
       "      <td>3348.0</td>\n",
       "      <td>-462.0</td>\n",
       "      <td>5777.0</td>\n",
       "      <td>22.08</td>\n",
       "      <td>26161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>16379.0</td>\n",
       "      <td>34201.0</td>\n",
       "      <td>15297.0</td>\n",
       "      <td>30415.0</td>\n",
       "      <td>4852.0</td>\n",
       "      <td>3944.0</td>\n",
       "      <td>4281.0</td>\n",
       "      <td>-941.0</td>\n",
       "      <td>-6995.0</td>\n",
       "      <td>-28.42</td>\n",
       "      <td>24610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>15884.0</td>\n",
       "      <td>23984.0</td>\n",
       "      <td>11256.0</td>\n",
       "      <td>24718.0</td>\n",
       "      <td>3879.0</td>\n",
       "      <td>3698.0</td>\n",
       "      <td>4290.0</td>\n",
       "      <td>-1191.0</td>\n",
       "      <td>4173.0</td>\n",
       "      <td>16.98</td>\n",
       "      <td>24575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">YPF</th>\n",
       "      <th>2020</th>\n",
       "      <td>317687.0</td>\n",
       "      <td>1595656.0</td>\n",
       "      <td>370669.0</td>\n",
       "      <td>869161.0</td>\n",
       "      <td>684763.0</td>\n",
       "      <td>100137.0</td>\n",
       "      <td>-67821.0</td>\n",
       "      <td>-65821.0</td>\n",
       "      <td>-69649.0</td>\n",
       "      <td>-10.06</td>\n",
       "      <td>692514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>456211.0</td>\n",
       "      <td>1923825.0</td>\n",
       "      <td>391078.0</td>\n",
       "      <td>1150872.0</td>\n",
       "      <td>849183.0</td>\n",
       "      <td>153927.0</td>\n",
       "      <td>94934.0</td>\n",
       "      <td>-71870.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1315633.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>897680.0</td>\n",
       "      <td>3677450.0</td>\n",
       "      <td>846905.0</td>\n",
       "      <td>1872950.0</td>\n",
       "      <td>1867097.0</td>\n",
       "      <td>307766.0</td>\n",
       "      <td>287344.0</td>\n",
       "      <td>-90151.0</td>\n",
       "      <td>289057.0</td>\n",
       "      <td>11.44</td>\n",
       "      <td>2526466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>3486126.0</td>\n",
       "      <td>16624393.0</td>\n",
       "      <td>3969790.0</td>\n",
       "      <td>8928518.0</td>\n",
       "      <td>7275343.0</td>\n",
       "      <td>1357716.0</td>\n",
       "      <td>157574.0</td>\n",
       "      <td>-227085.0</td>\n",
       "      <td>-1561217.0</td>\n",
       "      <td>-28.47</td>\n",
       "      <td>5484544.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>6598756.0</td>\n",
       "      <td>23287159.0</td>\n",
       "      <td>8939509.0</td>\n",
       "      <td>9115828.0</td>\n",
       "      <td>12186627.0</td>\n",
       "      <td>1593666.0</td>\n",
       "      <td>1597061.0</td>\n",
       "      <td>-608969.0</td>\n",
       "      <td>2077482.0</td>\n",
       "      <td>11.61</td>\n",
       "      <td>17895031.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">amazon-com-inc</th>\n",
       "      <th>2020</th>\n",
       "      <td>132733.0</td>\n",
       "      <td>188462.0</td>\n",
       "      <td>126385.0</td>\n",
       "      <td>101406.0</td>\n",
       "      <td>93404.0</td>\n",
       "      <td>23795.0</td>\n",
       "      <td>22899.0</td>\n",
       "      <td>-1647.0</td>\n",
       "      <td>21331.0</td>\n",
       "      <td>5.53</td>\n",
       "      <td>386064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>161580.0</td>\n",
       "      <td>258969.0</td>\n",
       "      <td>142266.0</td>\n",
       "      <td>140038.0</td>\n",
       "      <td>138245.0</td>\n",
       "      <td>32640.0</td>\n",
       "      <td>24879.0</td>\n",
       "      <td>-1809.0</td>\n",
       "      <td>33364.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>469822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>146791.0</td>\n",
       "      <td>315884.0</td>\n",
       "      <td>155393.0</td>\n",
       "      <td>161239.0</td>\n",
       "      <td>146043.0</td>\n",
       "      <td>34405.0</td>\n",
       "      <td>13348.0</td>\n",
       "      <td>-2367.0</td>\n",
       "      <td>-2722.0</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>513983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>172351.0</td>\n",
       "      <td>355503.0</td>\n",
       "      <td>164917.0</td>\n",
       "      <td>161062.0</td>\n",
       "      <td>201875.0</td>\n",
       "      <td>33318.0</td>\n",
       "      <td>36852.0</td>\n",
       "      <td>-3182.0</td>\n",
       "      <td>30425.0</td>\n",
       "      <td>5.29</td>\n",
       "      <td>574785.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>190867.0</td>\n",
       "      <td>434027.0</td>\n",
       "      <td>179431.0</td>\n",
       "      <td>159493.0</td>\n",
       "      <td>285970.0</td>\n",
       "      <td>34214.0</td>\n",
       "      <td>68593.0</td>\n",
       "      <td>-2406.0</td>\n",
       "      <td>59248.0</td>\n",
       "      <td>9.29</td>\n",
       "      <td>637959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">apple-computer-inc</th>\n",
       "      <th>2020</th>\n",
       "      <td>143713.0</td>\n",
       "      <td>180175.0</td>\n",
       "      <td>105392.0</td>\n",
       "      <td>153157.0</td>\n",
       "      <td>65339.0</td>\n",
       "      <td>4061.0</td>\n",
       "      <td>66288.0</td>\n",
       "      <td>-2873.0</td>\n",
       "      <td>57411.0</td>\n",
       "      <td>20.91</td>\n",
       "      <td>274515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>134836.0</td>\n",
       "      <td>216166.0</td>\n",
       "      <td>125481.0</td>\n",
       "      <td>162431.0</td>\n",
       "      <td>63090.0</td>\n",
       "      <td>6580.0</td>\n",
       "      <td>108949.0</td>\n",
       "      <td>-2645.0</td>\n",
       "      <td>94680.0</td>\n",
       "      <td>25.88</td>\n",
       "      <td>365817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>135405.0</td>\n",
       "      <td>217350.0</td>\n",
       "      <td>153982.0</td>\n",
       "      <td>148101.0</td>\n",
       "      <td>50672.0</td>\n",
       "      <td>4946.0</td>\n",
       "      <td>119437.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99803.0</td>\n",
       "      <td>25.31</td>\n",
       "      <td>394328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>143566.0</td>\n",
       "      <td>209017.0</td>\n",
       "      <td>145308.0</td>\n",
       "      <td>145129.0</td>\n",
       "      <td>62146.0</td>\n",
       "      <td>6331.0</td>\n",
       "      <td>114301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96995.0</td>\n",
       "      <td>25.31</td>\n",
       "      <td>383285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>152987.0</td>\n",
       "      <td>211993.0</td>\n",
       "      <td>176392.0</td>\n",
       "      <td>131638.0</td>\n",
       "      <td>56950.0</td>\n",
       "      <td>7286.0</td>\n",
       "      <td>123216.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93736.0</td>\n",
       "      <td>23.97</td>\n",
       "      <td>391035.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">berkshire-hathaway-inc</th>\n",
       "      <th>2020</th>\n",
       "      <td>194026.0</td>\n",
       "      <td>679703.0</td>\n",
       "      <td>45626.0</td>\n",
       "      <td>376767.0</td>\n",
       "      <td>450604.0</td>\n",
       "      <td>19208.0</td>\n",
       "      <td>69790.0</td>\n",
       "      <td>-4083.0</td>\n",
       "      <td>42521.0</td>\n",
       "      <td>17.31</td>\n",
       "      <td>245579.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>208089.0</td>\n",
       "      <td>750695.0</td>\n",
       "      <td>45234.0</td>\n",
       "      <td>398620.0</td>\n",
       "      <td>513918.0</td>\n",
       "      <td>20954.0</td>\n",
       "      <td>115147.0</td>\n",
       "      <td>-4172.0</td>\n",
       "      <td>89937.0</td>\n",
       "      <td>32.56</td>\n",
       "      <td>276185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>203413.0</td>\n",
       "      <td>745052.0</td>\n",
       "      <td>49540.0</td>\n",
       "      <td>417244.0</td>\n",
       "      <td>480920.0</td>\n",
       "      <td>25366.0</td>\n",
       "      <td>-28011.0</td>\n",
       "      <td>-4352.0</td>\n",
       "      <td>-22759.0</td>\n",
       "      <td>-7.54</td>\n",
       "      <td>302020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>245712.0</td>\n",
       "      <td>824266.0</td>\n",
       "      <td>56986.0</td>\n",
       "      <td>442222.0</td>\n",
       "      <td>569846.0</td>\n",
       "      <td>25856.0</td>\n",
       "      <td>123196.0</td>\n",
       "      <td>-5003.0</td>\n",
       "      <td>96223.0</td>\n",
       "      <td>26.40</td>\n",
       "      <td>364482.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>407447.0</td>\n",
       "      <td>746434.0</td>\n",
       "      <td>75652.0</td>\n",
       "      <td>426574.0</td>\n",
       "      <td>651089.0</td>\n",
       "      <td>24008.0</td>\n",
       "      <td>113735.0</td>\n",
       "      <td>-5200.0</td>\n",
       "      <td>88995.0</td>\n",
       "      <td>23.96</td>\n",
       "      <td>371433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">chevron</th>\n",
       "      <th>2020</th>\n",
       "      <td>26078.0</td>\n",
       "      <td>213712.0</td>\n",
       "      <td>22183.0</td>\n",
       "      <td>84881.0</td>\n",
       "      <td>132744.0</td>\n",
       "      <td>5676.0</td>\n",
       "      <td>-4252.0</td>\n",
       "      <td>-697.0</td>\n",
       "      <td>-5543.0</td>\n",
       "      <td>-5.90</td>\n",
       "      <td>94005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>33738.0</td>\n",
       "      <td>205797.0</td>\n",
       "      <td>26791.0</td>\n",
       "      <td>72804.0</td>\n",
       "      <td>139876.0</td>\n",
       "      <td>6795.0</td>\n",
       "      <td>16087.0</td>\n",
       "      <td>-712.0</td>\n",
       "      <td>15625.0</td>\n",
       "      <td>10.08</td>\n",
       "      <td>155067.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>50343.0</td>\n",
       "      <td>207366.0</td>\n",
       "      <td>34208.0</td>\n",
       "      <td>63259.0</td>\n",
       "      <td>160099.0</td>\n",
       "      <td>8247.0</td>\n",
       "      <td>42005.0</td>\n",
       "      <td>-516.0</td>\n",
       "      <td>35465.0</td>\n",
       "      <td>15.03</td>\n",
       "      <td>235916.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>41128.0</td>\n",
       "      <td>220504.0</td>\n",
       "      <td>32258.0</td>\n",
       "      <td>67445.0</td>\n",
       "      <td>161887.0</td>\n",
       "      <td>8612.0</td>\n",
       "      <td>26964.0</td>\n",
       "      <td>-469.0</td>\n",
       "      <td>21369.0</td>\n",
       "      <td>10.97</td>\n",
       "      <td>194799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>40911.0</td>\n",
       "      <td>216027.0</td>\n",
       "      <td>38558.0</td>\n",
       "      <td>65223.0</td>\n",
       "      <td>153069.0</td>\n",
       "      <td>9074.0</td>\n",
       "      <td>23299.0</td>\n",
       "      <td>-594.0</td>\n",
       "      <td>17661.0</td>\n",
       "      <td>9.03</td>\n",
       "      <td>195568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">coca-cola-co</th>\n",
       "      <th>2020</th>\n",
       "      <td>19240.0</td>\n",
       "      <td>68056.0</td>\n",
       "      <td>14601.0</td>\n",
       "      <td>51411.0</td>\n",
       "      <td>21263.0</td>\n",
       "      <td>3266.0</td>\n",
       "      <td>9992.0</td>\n",
       "      <td>-1437.0</td>\n",
       "      <td>7747.0</td>\n",
       "      <td>23.47</td>\n",
       "      <td>33014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>71809.0</td>\n",
       "      <td>19950.0</td>\n",
       "      <td>49544.0</td>\n",
       "      <td>24827.0</td>\n",
       "      <td>3414.0</td>\n",
       "      <td>11433.0</td>\n",
       "      <td>-1597.0</td>\n",
       "      <td>9771.0</td>\n",
       "      <td>25.28</td>\n",
       "      <td>38655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>22591.0</td>\n",
       "      <td>70172.0</td>\n",
       "      <td>19724.0</td>\n",
       "      <td>47213.0</td>\n",
       "      <td>25797.0</td>\n",
       "      <td>4233.0</td>\n",
       "      <td>12341.0</td>\n",
       "      <td>-882.0</td>\n",
       "      <td>9542.0</td>\n",
       "      <td>22.19</td>\n",
       "      <td>43004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>26732.0</td>\n",
       "      <td>70971.0</td>\n",
       "      <td>23571.0</td>\n",
       "      <td>46652.0</td>\n",
       "      <td>27491.0</td>\n",
       "      <td>4424.0</td>\n",
       "      <td>13246.0</td>\n",
       "      <td>-1527.0</td>\n",
       "      <td>10714.0</td>\n",
       "      <td>23.42</td>\n",
       "      <td>45754.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>25997.0</td>\n",
       "      <td>74552.0</td>\n",
       "      <td>25249.0</td>\n",
       "      <td>48928.0</td>\n",
       "      <td>26354.0</td>\n",
       "      <td>4728.0</td>\n",
       "      <td>14301.0</td>\n",
       "      <td>-1656.0</td>\n",
       "      <td>10631.0</td>\n",
       "      <td>22.59</td>\n",
       "      <td>47061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">disney</th>\n",
       "      <th>2020</th>\n",
       "      <td>35251.0</td>\n",
       "      <td>166298.0</td>\n",
       "      <td>26628.0</td>\n",
       "      <td>77409.0</td>\n",
       "      <td>97122.0</td>\n",
       "      <td>3754.0</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>-1647.0</td>\n",
       "      <td>-2864.0</td>\n",
       "      <td>-4.38</td>\n",
       "      <td>65388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>33657.0</td>\n",
       "      <td>169952.0</td>\n",
       "      <td>31077.0</td>\n",
       "      <td>70308.0</td>\n",
       "      <td>101712.0</td>\n",
       "      <td>3514.0</td>\n",
       "      <td>3492.0</td>\n",
       "      <td>-1546.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>2.96</td>\n",
       "      <td>67418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>29098.0</td>\n",
       "      <td>174533.0</td>\n",
       "      <td>29073.0</td>\n",
       "      <td>66180.0</td>\n",
       "      <td>108018.0</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>6832.0</td>\n",
       "      <td>-1549.0</td>\n",
       "      <td>3145.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>82722.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>32763.0</td>\n",
       "      <td>172816.0</td>\n",
       "      <td>31139.0</td>\n",
       "      <td>61428.0</td>\n",
       "      <td>111976.0</td>\n",
       "      <td>4965.0</td>\n",
       "      <td>9332.0</td>\n",
       "      <td>-1973.0</td>\n",
       "      <td>2354.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>88898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>25241.0</td>\n",
       "      <td>170978.0</td>\n",
       "      <td>34599.0</td>\n",
       "      <td>56098.0</td>\n",
       "      <td>104721.0</td>\n",
       "      <td>4119.0</td>\n",
       "      <td>12318.0</td>\n",
       "      <td>-2070.0</td>\n",
       "      <td>4972.0</td>\n",
       "      <td>5.44</td>\n",
       "      <td>91361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">google-inc</th>\n",
       "      <th>2020</th>\n",
       "      <td>174296.0</td>\n",
       "      <td>145320.0</td>\n",
       "      <td>56834.0</td>\n",
       "      <td>40238.0</td>\n",
       "      <td>222544.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>41224.0</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>40269.0</td>\n",
       "      <td>22.06</td>\n",
       "      <td>182527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>188143.0</td>\n",
       "      <td>171125.0</td>\n",
       "      <td>64254.0</td>\n",
       "      <td>43379.0</td>\n",
       "      <td>251635.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>78714.0</td>\n",
       "      <td>-346.0</td>\n",
       "      <td>76033.0</td>\n",
       "      <td>29.51</td>\n",
       "      <td>257637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>164795.0</td>\n",
       "      <td>200469.0</td>\n",
       "      <td>69300.0</td>\n",
       "      <td>39820.0</td>\n",
       "      <td>256144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74842.0</td>\n",
       "      <td>-357.0</td>\n",
       "      <td>59972.0</td>\n",
       "      <td>21.20</td>\n",
       "      <td>282836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>171530.0</td>\n",
       "      <td>230862.0</td>\n",
       "      <td>81814.0</td>\n",
       "      <td>37199.0</td>\n",
       "      <td>283379.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84293.0</td>\n",
       "      <td>-308.0</td>\n",
       "      <td>73795.0</td>\n",
       "      <td>24.01</td>\n",
       "      <td>307394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>163711.0</td>\n",
       "      <td>286545.0</td>\n",
       "      <td>89122.0</td>\n",
       "      <td>36050.0</td>\n",
       "      <td>325084.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114186.0</td>\n",
       "      <td>-268.0</td>\n",
       "      <td>100118.0</td>\n",
       "      <td>28.60</td>\n",
       "      <td>350018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">microsoft-corp</th>\n",
       "      <th>2020</th>\n",
       "      <td>181915.0</td>\n",
       "      <td>119396.0</td>\n",
       "      <td>72310.0</td>\n",
       "      <td>110697.0</td>\n",
       "      <td>118304.0</td>\n",
       "      <td>1895.0</td>\n",
       "      <td>52959.0</td>\n",
       "      <td>-2591.0</td>\n",
       "      <td>44281.0</td>\n",
       "      <td>30.96</td>\n",
       "      <td>143015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>184406.0</td>\n",
       "      <td>149373.0</td>\n",
       "      <td>88657.0</td>\n",
       "      <td>103134.0</td>\n",
       "      <td>141988.0</td>\n",
       "      <td>2636.0</td>\n",
       "      <td>69916.0</td>\n",
       "      <td>-2330.0</td>\n",
       "      <td>61271.0</td>\n",
       "      <td>36.45</td>\n",
       "      <td>168088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>169684.0</td>\n",
       "      <td>195156.0</td>\n",
       "      <td>95082.0</td>\n",
       "      <td>103216.0</td>\n",
       "      <td>166542.0</td>\n",
       "      <td>3742.0</td>\n",
       "      <td>83383.0</td>\n",
       "      <td>-2047.0</td>\n",
       "      <td>72738.0</td>\n",
       "      <td>36.69</td>\n",
       "      <td>198270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>184257.0</td>\n",
       "      <td>227719.0</td>\n",
       "      <td>104149.0</td>\n",
       "      <td>101604.0</td>\n",
       "      <td>206223.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>88675.0</td>\n",
       "      <td>-1995.0</td>\n",
       "      <td>72361.0</td>\n",
       "      <td>34.15</td>\n",
       "      <td>211915.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>159734.0</td>\n",
       "      <td>352429.0</td>\n",
       "      <td>125286.0</td>\n",
       "      <td>118400.0</td>\n",
       "      <td>268477.0</td>\n",
       "      <td>1246.0</td>\n",
       "      <td>109433.0</td>\n",
       "      <td>-2983.0</td>\n",
       "      <td>88136.0</td>\n",
       "      <td>35.96</td>\n",
       "      <td>245122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">nike</th>\n",
       "      <th>2020</th>\n",
       "      <td>20556.0</td>\n",
       "      <td>10786.0</td>\n",
       "      <td>8284.0</td>\n",
       "      <td>15003.0</td>\n",
       "      <td>8055.0</td>\n",
       "      <td>7367.0</td>\n",
       "      <td>3115.0</td>\n",
       "      <td>-151.0</td>\n",
       "      <td>2539.0</td>\n",
       "      <td>6.79</td>\n",
       "      <td>37403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>26291.0</td>\n",
       "      <td>11449.0</td>\n",
       "      <td>9674.0</td>\n",
       "      <td>15299.0</td>\n",
       "      <td>12767.0</td>\n",
       "      <td>6854.0</td>\n",
       "      <td>7231.0</td>\n",
       "      <td>-296.0</td>\n",
       "      <td>5727.0</td>\n",
       "      <td>12.86</td>\n",
       "      <td>44538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>28213.0</td>\n",
       "      <td>12108.0</td>\n",
       "      <td>10730.0</td>\n",
       "      <td>14310.0</td>\n",
       "      <td>15281.0</td>\n",
       "      <td>8420.0</td>\n",
       "      <td>6675.0</td>\n",
       "      <td>-299.0</td>\n",
       "      <td>6046.0</td>\n",
       "      <td>12.94</td>\n",
       "      <td>46710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>25202.0</td>\n",
       "      <td>12329.0</td>\n",
       "      <td>9256.0</td>\n",
       "      <td>14271.0</td>\n",
       "      <td>14004.0</td>\n",
       "      <td>8454.0</td>\n",
       "      <td>5915.0</td>\n",
       "      <td>-291.0</td>\n",
       "      <td>5070.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>51217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>25382.0</td>\n",
       "      <td>12728.0</td>\n",
       "      <td>10593.0</td>\n",
       "      <td>13087.0</td>\n",
       "      <td>14430.0</td>\n",
       "      <td>7519.0</td>\n",
       "      <td>6754.0</td>\n",
       "      <td>-269.0</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>11.10</td>\n",
       "      <td>51362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">pfizer</th>\n",
       "      <th>2020</th>\n",
       "      <td>35049.0</td>\n",
       "      <td>119162.0</td>\n",
       "      <td>25920.0</td>\n",
       "      <td>64836.0</td>\n",
       "      <td>63437.0</td>\n",
       "      <td>8020.0</td>\n",
       "      <td>9791.0</td>\n",
       "      <td>-1449.0</td>\n",
       "      <td>9159.0</td>\n",
       "      <td>21.99</td>\n",
       "      <td>41651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>59689.0</td>\n",
       "      <td>121783.0</td>\n",
       "      <td>42671.0</td>\n",
       "      <td>61342.0</td>\n",
       "      <td>77418.0</td>\n",
       "      <td>9059.0</td>\n",
       "      <td>26980.0</td>\n",
       "      <td>-1291.0</td>\n",
       "      <td>21979.0</td>\n",
       "      <td>27.04</td>\n",
       "      <td>81288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>51259.0</td>\n",
       "      <td>145946.0</td>\n",
       "      <td>42138.0</td>\n",
       "      <td>59150.0</td>\n",
       "      <td>95882.0</td>\n",
       "      <td>8981.0</td>\n",
       "      <td>39841.0</td>\n",
       "      <td>-1238.0</td>\n",
       "      <td>31372.0</td>\n",
       "      <td>31.01</td>\n",
       "      <td>101175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>43333.0</td>\n",
       "      <td>183168.0</td>\n",
       "      <td>47794.0</td>\n",
       "      <td>89419.0</td>\n",
       "      <td>89249.0</td>\n",
       "      <td>10189.0</td>\n",
       "      <td>6317.0</td>\n",
       "      <td>-2209.0</td>\n",
       "      <td>2119.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>59554.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>50358.0</td>\n",
       "      <td>163038.0</td>\n",
       "      <td>42995.0</td>\n",
       "      <td>81904.0</td>\n",
       "      <td>88466.0</td>\n",
       "      <td>10851.0</td>\n",
       "      <td>16328.0</td>\n",
       "      <td>-3091.0</td>\n",
       "      <td>8031.0</td>\n",
       "      <td>12.62</td>\n",
       "      <td>63627.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">procter-gamble</th>\n",
       "      <th>2020</th>\n",
       "      <td>27987.0</td>\n",
       "      <td>92713.0</td>\n",
       "      <td>32976.0</td>\n",
       "      <td>40846.0</td>\n",
       "      <td>46802.0</td>\n",
       "      <td>5498.0</td>\n",
       "      <td>16103.0</td>\n",
       "      <td>-465.0</td>\n",
       "      <td>13027.0</td>\n",
       "      <td>18.36</td>\n",
       "      <td>70950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>23091.0</td>\n",
       "      <td>96216.0</td>\n",
       "      <td>33132.0</td>\n",
       "      <td>39521.0</td>\n",
       "      <td>46608.0</td>\n",
       "      <td>5983.0</td>\n",
       "      <td>18483.0</td>\n",
       "      <td>-502.0</td>\n",
       "      <td>14306.0</td>\n",
       "      <td>18.79</td>\n",
       "      <td>76118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>21653.0</td>\n",
       "      <td>95555.0</td>\n",
       "      <td>33081.0</td>\n",
       "      <td>37273.0</td>\n",
       "      <td>46803.0</td>\n",
       "      <td>6924.0</td>\n",
       "      <td>18445.0</td>\n",
       "      <td>-439.0</td>\n",
       "      <td>14742.0</td>\n",
       "      <td>18.38</td>\n",
       "      <td>80187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>22648.0</td>\n",
       "      <td>98181.0</td>\n",
       "      <td>35756.0</td>\n",
       "      <td>38008.0</td>\n",
       "      <td>46980.0</td>\n",
       "      <td>7073.0</td>\n",
       "      <td>19057.0</td>\n",
       "      <td>-756.0</td>\n",
       "      <td>14653.0</td>\n",
       "      <td>17.87</td>\n",
       "      <td>82006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>24709.0</td>\n",
       "      <td>97661.0</td>\n",
       "      <td>33627.0</td>\n",
       "      <td>38185.0</td>\n",
       "      <td>50463.0</td>\n",
       "      <td>7016.0</td>\n",
       "      <td>20948.0</td>\n",
       "      <td>-925.0</td>\n",
       "      <td>14879.0</td>\n",
       "      <td>17.70</td>\n",
       "      <td>84039.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">tesla-motors</th>\n",
       "      <th>2020</th>\n",
       "      <td>26717.0</td>\n",
       "      <td>25431.0</td>\n",
       "      <td>14248.0</td>\n",
       "      <td>14221.0</td>\n",
       "      <td>23538.0</td>\n",
       "      <td>4101.0</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>-748.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>2.29</td>\n",
       "      <td>31536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>27100.0</td>\n",
       "      <td>35031.0</td>\n",
       "      <td>19705.0</td>\n",
       "      <td>10843.0</td>\n",
       "      <td>31458.0</td>\n",
       "      <td>5757.0</td>\n",
       "      <td>6523.0</td>\n",
       "      <td>-371.0</td>\n",
       "      <td>5519.0</td>\n",
       "      <td>10.25</td>\n",
       "      <td>53823.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>40917.0</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>26709.0</td>\n",
       "      <td>9731.0</td>\n",
       "      <td>45867.0</td>\n",
       "      <td>12839.0</td>\n",
       "      <td>13692.0</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>12556.0</td>\n",
       "      <td>15.41</td>\n",
       "      <td>81462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>49616.0</td>\n",
       "      <td>57002.0</td>\n",
       "      <td>28748.0</td>\n",
       "      <td>14261.0</td>\n",
       "      <td>63632.0</td>\n",
       "      <td>13626.0</td>\n",
       "      <td>8891.0</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>14997.0</td>\n",
       "      <td>15.50</td>\n",
       "      <td>96773.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>58360.0</td>\n",
       "      <td>63710.0</td>\n",
       "      <td>28821.0</td>\n",
       "      <td>19569.0</td>\n",
       "      <td>73618.0</td>\n",
       "      <td>12017.0</td>\n",
       "      <td>7659.0</td>\n",
       "      <td>-350.0</td>\n",
       "      <td>7091.0</td>\n",
       "      <td>7.26</td>\n",
       "      <td>97690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">visa-inc</th>\n",
       "      <th>2020</th>\n",
       "      <td>27645.0</td>\n",
       "      <td>53274.0</td>\n",
       "      <td>14510.0</td>\n",
       "      <td>30199.0</td>\n",
       "      <td>36210.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14125.0</td>\n",
       "      <td>-516.0</td>\n",
       "      <td>10866.0</td>\n",
       "      <td>49.74</td>\n",
       "      <td>21846.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>27607.0</td>\n",
       "      <td>55289.0</td>\n",
       "      <td>15739.0</td>\n",
       "      <td>29568.0</td>\n",
       "      <td>37589.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15807.0</td>\n",
       "      <td>-513.0</td>\n",
       "      <td>12311.0</td>\n",
       "      <td>51.07</td>\n",
       "      <td>24105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>30205.0</td>\n",
       "      <td>55296.0</td>\n",
       "      <td>20853.0</td>\n",
       "      <td>29067.0</td>\n",
       "      <td>35581.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19681.0</td>\n",
       "      <td>-538.0</td>\n",
       "      <td>14957.0</td>\n",
       "      <td>51.03</td>\n",
       "      <td>29310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>33532.0</td>\n",
       "      <td>56967.0</td>\n",
       "      <td>23098.0</td>\n",
       "      <td>28668.0</td>\n",
       "      <td>38733.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21927.0</td>\n",
       "      <td>-644.0</td>\n",
       "      <td>17273.0</td>\n",
       "      <td>52.90</td>\n",
       "      <td>32653.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>34033.0</td>\n",
       "      <td>60478.0</td>\n",
       "      <td>26517.0</td>\n",
       "      <td>28857.0</td>\n",
       "      <td>39137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23939.0</td>\n",
       "      <td>-641.0</td>\n",
       "      <td>19743.0</td>\n",
       "      <td>54.95</td>\n",
       "      <td>35926.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  activo_corriente  activo_no_corriente  \\\n",
       "company                ejercicio                                          \n",
       "3m-co                  2020                14975.0              32362.0   \n",
       "                       2021                15403.0              31669.0   \n",
       "                       2022                14688.0              31767.0   \n",
       "                       2023                16379.0              34201.0   \n",
       "                       2024                15884.0              23984.0   \n",
       "YPF                    2020               317687.0            1595656.0   \n",
       "                       2021               456211.0            1923825.0   \n",
       "                       2022               897680.0            3677450.0   \n",
       "                       2023              3486126.0           16624393.0   \n",
       "                       2024              6598756.0           23287159.0   \n",
       "amazon-com-inc         2020               132733.0             188462.0   \n",
       "                       2021               161580.0             258969.0   \n",
       "                       2022               146791.0             315884.0   \n",
       "                       2023               172351.0             355503.0   \n",
       "                       2024               190867.0             434027.0   \n",
       "apple-computer-inc     2020               143713.0             180175.0   \n",
       "                       2021               134836.0             216166.0   \n",
       "                       2022               135405.0             217350.0   \n",
       "                       2023               143566.0             209017.0   \n",
       "                       2024               152987.0             211993.0   \n",
       "berkshire-hathaway-inc 2020               194026.0             679703.0   \n",
       "                       2021               208089.0             750695.0   \n",
       "                       2022               203413.0             745052.0   \n",
       "                       2023               245712.0             824266.0   \n",
       "                       2024               407447.0             746434.0   \n",
       "chevron                2020                26078.0             213712.0   \n",
       "                       2021                33738.0             205797.0   \n",
       "                       2022                50343.0             207366.0   \n",
       "                       2023                41128.0             220504.0   \n",
       "                       2024                40911.0             216027.0   \n",
       "coca-cola-co           2020                19240.0              68056.0   \n",
       "                       2021                22544.0              71809.0   \n",
       "                       2022                22591.0              70172.0   \n",
       "                       2023                26732.0              70971.0   \n",
       "                       2024                25997.0              74552.0   \n",
       "disney                 2020                35251.0             166298.0   \n",
       "                       2021                33657.0             169952.0   \n",
       "                       2022                29098.0             174533.0   \n",
       "                       2023                32763.0             172816.0   \n",
       "                       2024                25241.0             170978.0   \n",
       "google-inc             2020               174296.0             145320.0   \n",
       "                       2021               188143.0             171125.0   \n",
       "                       2022               164795.0             200469.0   \n",
       "                       2023               171530.0             230862.0   \n",
       "                       2024               163711.0             286545.0   \n",
       "microsoft-corp         2020               181915.0             119396.0   \n",
       "                       2021               184406.0             149373.0   \n",
       "                       2022               169684.0             195156.0   \n",
       "                       2023               184257.0             227719.0   \n",
       "                       2024               159734.0             352429.0   \n",
       "nike                   2020                20556.0              10786.0   \n",
       "                       2021                26291.0              11449.0   \n",
       "                       2022                28213.0              12108.0   \n",
       "                       2023                25202.0              12329.0   \n",
       "                       2024                25382.0              12728.0   \n",
       "pfizer                 2020                35049.0             119162.0   \n",
       "                       2021                59689.0             121783.0   \n",
       "                       2022                51259.0             145946.0   \n",
       "                       2023                43333.0             183168.0   \n",
       "                       2024                50358.0             163038.0   \n",
       "procter-gamble         2020                27987.0              92713.0   \n",
       "                       2021                23091.0              96216.0   \n",
       "                       2022                21653.0              95555.0   \n",
       "                       2023                22648.0              98181.0   \n",
       "                       2024                24709.0              97661.0   \n",
       "tesla-motors           2020                26717.0              25431.0   \n",
       "                       2021                27100.0              35031.0   \n",
       "                       2022                40917.0              41421.0   \n",
       "                       2023                49616.0              57002.0   \n",
       "                       2024                58360.0              63710.0   \n",
       "visa-inc               2020                27645.0              53274.0   \n",
       "                       2021                27607.0              55289.0   \n",
       "                       2022                30205.0              55296.0   \n",
       "                       2023                33532.0              56967.0   \n",
       "                       2024                34033.0              60478.0   \n",
       "\n",
       "                                  pasivo_corriente  pasivo_no_corriente  \\\n",
       "company                ejercicio                                          \n",
       "3m-co                  2020                 7948.0              26465.0   \n",
       "                       2021                 9035.0              22920.0   \n",
       "                       2022                 9523.0              22162.0   \n",
       "                       2023                15297.0              30415.0   \n",
       "                       2024                11256.0              24718.0   \n",
       "YPF                    2020               370669.0             869161.0   \n",
       "                       2021               391078.0            1150872.0   \n",
       "                       2022               846905.0            1872950.0   \n",
       "                       2023              3969790.0            8928518.0   \n",
       "                       2024              8939509.0            9115828.0   \n",
       "amazon-com-inc         2020               126385.0             101406.0   \n",
       "                       2021               142266.0             140038.0   \n",
       "                       2022               155393.0             161239.0   \n",
       "                       2023               164917.0             161062.0   \n",
       "                       2024               179431.0             159493.0   \n",
       "apple-computer-inc     2020               105392.0             153157.0   \n",
       "                       2021               125481.0             162431.0   \n",
       "                       2022               153982.0             148101.0   \n",
       "                       2023               145308.0             145129.0   \n",
       "                       2024               176392.0             131638.0   \n",
       "berkshire-hathaway-inc 2020                45626.0             376767.0   \n",
       "                       2021                45234.0             398620.0   \n",
       "                       2022                49540.0             417244.0   \n",
       "                       2023                56986.0             442222.0   \n",
       "                       2024                75652.0             426574.0   \n",
       "chevron                2020                22183.0              84881.0   \n",
       "                       2021                26791.0              72804.0   \n",
       "                       2022                34208.0              63259.0   \n",
       "                       2023                32258.0              67445.0   \n",
       "                       2024                38558.0              65223.0   \n",
       "coca-cola-co           2020                14601.0              51411.0   \n",
       "                       2021                19950.0              49544.0   \n",
       "                       2022                19724.0              47213.0   \n",
       "                       2023                23571.0              46652.0   \n",
       "                       2024                25249.0              48928.0   \n",
       "disney                 2020                26628.0              77409.0   \n",
       "                       2021                31077.0              70308.0   \n",
       "                       2022                29073.0              66180.0   \n",
       "                       2023                31139.0              61428.0   \n",
       "                       2024                34599.0              56098.0   \n",
       "google-inc             2020                56834.0              40238.0   \n",
       "                       2021                64254.0              43379.0   \n",
       "                       2022                69300.0              39820.0   \n",
       "                       2023                81814.0              37199.0   \n",
       "                       2024                89122.0              36050.0   \n",
       "microsoft-corp         2020                72310.0             110697.0   \n",
       "                       2021                88657.0             103134.0   \n",
       "                       2022                95082.0             103216.0   \n",
       "                       2023               104149.0             101604.0   \n",
       "                       2024               125286.0             118400.0   \n",
       "nike                   2020                 8284.0              15003.0   \n",
       "                       2021                 9674.0              15299.0   \n",
       "                       2022                10730.0              14310.0   \n",
       "                       2023                 9256.0              14271.0   \n",
       "                       2024                10593.0              13087.0   \n",
       "pfizer                 2020                25920.0              64836.0   \n",
       "                       2021                42671.0              61342.0   \n",
       "                       2022                42138.0              59150.0   \n",
       "                       2023                47794.0              89419.0   \n",
       "                       2024                42995.0              81904.0   \n",
       "procter-gamble         2020                32976.0              40846.0   \n",
       "                       2021                33132.0              39521.0   \n",
       "                       2022                33081.0              37273.0   \n",
       "                       2023                35756.0              38008.0   \n",
       "                       2024                33627.0              38185.0   \n",
       "tesla-motors           2020                14248.0              14221.0   \n",
       "                       2021                19705.0              10843.0   \n",
       "                       2022                26709.0               9731.0   \n",
       "                       2023                28748.0              14261.0   \n",
       "                       2024                28821.0              19569.0   \n",
       "visa-inc               2020                14510.0              30199.0   \n",
       "                       2021                15739.0              29568.0   \n",
       "                       2022                20853.0              29067.0   \n",
       "                       2023                23098.0              28668.0   \n",
       "                       2024                26517.0              28857.0   \n",
       "\n",
       "                                  patrimonio_neto  inventario       EBIT  \\\n",
       "company                ejercicio                                           \n",
       "3m-co                  2020               12927.0      4239.0     7156.0   \n",
       "                       2021               15109.0      4985.0     7754.0   \n",
       "                       2022               14756.0      5372.0     3348.0   \n",
       "                       2023                4852.0      3944.0     4281.0   \n",
       "                       2024                3879.0      3698.0     4290.0   \n",
       "YPF                    2020              684763.0    100137.0   -67821.0   \n",
       "                       2021              849183.0    153927.0    94934.0   \n",
       "                       2022             1867097.0    307766.0   287344.0   \n",
       "                       2023             7275343.0   1357716.0   157574.0   \n",
       "                       2024            12186627.0   1593666.0  1597061.0   \n",
       "amazon-com-inc         2020               93404.0     23795.0    22899.0   \n",
       "                       2021              138245.0     32640.0    24879.0   \n",
       "                       2022              146043.0     34405.0    13348.0   \n",
       "                       2023              201875.0     33318.0    36852.0   \n",
       "                       2024              285970.0     34214.0    68593.0   \n",
       "apple-computer-inc     2020               65339.0      4061.0    66288.0   \n",
       "                       2021               63090.0      6580.0   108949.0   \n",
       "                       2022               50672.0      4946.0   119437.0   \n",
       "                       2023               62146.0      6331.0   114301.0   \n",
       "                       2024               56950.0      7286.0   123216.0   \n",
       "berkshire-hathaway-inc 2020              450604.0     19208.0    69790.0   \n",
       "                       2021              513918.0     20954.0   115147.0   \n",
       "                       2022              480920.0     25366.0   -28011.0   \n",
       "                       2023              569846.0     25856.0   123196.0   \n",
       "                       2024              651089.0     24008.0   113735.0   \n",
       "chevron                2020              132744.0      5676.0    -4252.0   \n",
       "                       2021              139876.0      6795.0    16087.0   \n",
       "                       2022              160099.0      8247.0    42005.0   \n",
       "                       2023              161887.0      8612.0    26964.0   \n",
       "                       2024              153069.0      9074.0    23299.0   \n",
       "coca-cola-co           2020               21263.0      3266.0     9992.0   \n",
       "                       2021               24827.0      3414.0    11433.0   \n",
       "                       2022               25797.0      4233.0    12341.0   \n",
       "                       2023               27491.0      4424.0    13246.0   \n",
       "                       2024               26354.0      4728.0    14301.0   \n",
       "disney                 2020               97122.0      3754.0     3781.0   \n",
       "                       2021              101712.0      3514.0     3492.0   \n",
       "                       2022              108018.0      3632.0     6832.0   \n",
       "                       2023              111976.0      4965.0     9332.0   \n",
       "                       2024              104721.0      4119.0    12318.0   \n",
       "google-inc             2020              222544.0       728.0    41224.0   \n",
       "                       2021              251635.0      1170.0    78714.0   \n",
       "                       2022              256144.0         NaN    74842.0   \n",
       "                       2023              283379.0         NaN    84293.0   \n",
       "                       2024              325084.0         NaN   114186.0   \n",
       "microsoft-corp         2020              118304.0      1895.0    52959.0   \n",
       "                       2021              141988.0      2636.0    69916.0   \n",
       "                       2022              166542.0      3742.0    83383.0   \n",
       "                       2023              206223.0      2500.0    88675.0   \n",
       "                       2024              268477.0      1246.0   109433.0   \n",
       "nike                   2020                8055.0      7367.0     3115.0   \n",
       "                       2021               12767.0      6854.0     7231.0   \n",
       "                       2022               15281.0      8420.0     6675.0   \n",
       "                       2023               14004.0      8454.0     5915.0   \n",
       "                       2024               14430.0      7519.0     6754.0   \n",
       "pfizer                 2020               63437.0      8020.0     9791.0   \n",
       "                       2021               77418.0      9059.0    26980.0   \n",
       "                       2022               95882.0      8981.0    39841.0   \n",
       "                       2023               89249.0     10189.0     6317.0   \n",
       "                       2024               88466.0     10851.0    16328.0   \n",
       "procter-gamble         2020               46802.0      5498.0    16103.0   \n",
       "                       2021               46608.0      5983.0    18483.0   \n",
       "                       2022               46803.0      6924.0    18445.0   \n",
       "                       2023               46980.0      7073.0    19057.0   \n",
       "                       2024               50463.0      7016.0    20948.0   \n",
       "tesla-motors           2020               23538.0      4101.0     1951.0   \n",
       "                       2021               31458.0      5757.0     6523.0   \n",
       "                       2022               45867.0     12839.0    13692.0   \n",
       "                       2023               63632.0     13626.0     8891.0   \n",
       "                       2024               73618.0     12017.0     7659.0   \n",
       "visa-inc               2020               36210.0         NaN    14125.0   \n",
       "                       2021               37589.0         NaN    15807.0   \n",
       "                       2022               35581.0         NaN    19681.0   \n",
       "                       2023               38733.0         NaN    21927.0   \n",
       "                       2024               39137.0         NaN    23939.0   \n",
       "\n",
       "                                  intereses  beneficio_neto  \\\n",
       "company                ejercicio                              \n",
       "3m-co                  2020          -529.0          5449.0   \n",
       "                       2021          -488.0          5921.0   \n",
       "                       2022          -462.0          5777.0   \n",
       "                       2023          -941.0         -6995.0   \n",
       "                       2024         -1191.0          4173.0   \n",
       "YPF                    2020        -65821.0        -69649.0   \n",
       "                       2021        -71870.0           257.0   \n",
       "                       2022        -90151.0        289057.0   \n",
       "                       2023       -227085.0      -1561217.0   \n",
       "                       2024       -608969.0       2077482.0   \n",
       "amazon-com-inc         2020         -1647.0         21331.0   \n",
       "                       2021         -1809.0         33364.0   \n",
       "                       2022         -2367.0         -2722.0   \n",
       "                       2023         -3182.0         30425.0   \n",
       "                       2024         -2406.0         59248.0   \n",
       "apple-computer-inc     2020         -2873.0         57411.0   \n",
       "                       2021         -2645.0         94680.0   \n",
       "                       2022             NaN         99803.0   \n",
       "                       2023             NaN         96995.0   \n",
       "                       2024             NaN         93736.0   \n",
       "berkshire-hathaway-inc 2020         -4083.0         42521.0   \n",
       "                       2021         -4172.0         89937.0   \n",
       "                       2022         -4352.0        -22759.0   \n",
       "                       2023         -5003.0         96223.0   \n",
       "                       2024         -5200.0         88995.0   \n",
       "chevron                2020          -697.0         -5543.0   \n",
       "                       2021          -712.0         15625.0   \n",
       "                       2022          -516.0         35465.0   \n",
       "                       2023          -469.0         21369.0   \n",
       "                       2024          -594.0         17661.0   \n",
       "coca-cola-co           2020         -1437.0          7747.0   \n",
       "                       2021         -1597.0          9771.0   \n",
       "                       2022          -882.0          9542.0   \n",
       "                       2023         -1527.0         10714.0   \n",
       "                       2024         -1656.0         10631.0   \n",
       "disney                 2020         -1647.0         -2864.0   \n",
       "                       2021         -1546.0          1995.0   \n",
       "                       2022         -1549.0          3145.0   \n",
       "                       2023         -1973.0          2354.0   \n",
       "                       2024         -2070.0          4972.0   \n",
       "google-inc             2020          -135.0         40269.0   \n",
       "                       2021          -346.0         76033.0   \n",
       "                       2022          -357.0         59972.0   \n",
       "                       2023          -308.0         73795.0   \n",
       "                       2024          -268.0        100118.0   \n",
       "microsoft-corp         2020         -2591.0         44281.0   \n",
       "                       2021         -2330.0         61271.0   \n",
       "                       2022         -2047.0         72738.0   \n",
       "                       2023         -1995.0         72361.0   \n",
       "                       2024         -2983.0         88136.0   \n",
       "nike                   2020          -151.0          2539.0   \n",
       "                       2021          -296.0          5727.0   \n",
       "                       2022          -299.0          6046.0   \n",
       "                       2023          -291.0          5070.0   \n",
       "                       2024          -269.0          5700.0   \n",
       "pfizer                 2020         -1449.0          9159.0   \n",
       "                       2021         -1291.0         21979.0   \n",
       "                       2022         -1238.0         31372.0   \n",
       "                       2023         -2209.0          2119.0   \n",
       "                       2024         -3091.0          8031.0   \n",
       "procter-gamble         2020          -465.0         13027.0   \n",
       "                       2021          -502.0         14306.0   \n",
       "                       2022          -439.0         14742.0   \n",
       "                       2023          -756.0         14653.0   \n",
       "                       2024          -925.0         14879.0   \n",
       "tesla-motors           2020          -748.0           721.0   \n",
       "                       2021          -371.0          5519.0   \n",
       "                       2022          -191.0         12556.0   \n",
       "                       2023          -156.0         14997.0   \n",
       "                       2024          -350.0          7091.0   \n",
       "visa-inc               2020          -516.0         10866.0   \n",
       "                       2021          -513.0         12311.0   \n",
       "                       2022          -538.0         14957.0   \n",
       "                       2023          -644.0         17273.0   \n",
       "                       2024          -641.0         19743.0   \n",
       "\n",
       "                                  margen_beneficio_neto  ingresos_totales  \n",
       "company                ejercicio                                           \n",
       "3m-co                  2020                       16.93           32184.0  \n",
       "                       2021                       16.75           35355.0  \n",
       "                       2022                       22.08           26161.0  \n",
       "                       2023                      -28.42           24610.0  \n",
       "                       2024                       16.98           24575.0  \n",
       "YPF                    2020                      -10.06          692514.0  \n",
       "                       2021                        0.02         1315633.0  \n",
       "                       2022                       11.44         2526466.0  \n",
       "                       2023                      -28.47         5484544.0  \n",
       "                       2024                       11.61        17895031.0  \n",
       "amazon-com-inc         2020                        5.53          386064.0  \n",
       "                       2021                        7.10          469822.0  \n",
       "                       2022                       -0.53          513983.0  \n",
       "                       2023                        5.29          574785.0  \n",
       "                       2024                        9.29          637959.0  \n",
       "apple-computer-inc     2020                       20.91          274515.0  \n",
       "                       2021                       25.88          365817.0  \n",
       "                       2022                       25.31          394328.0  \n",
       "                       2023                       25.31          383285.0  \n",
       "                       2024                       23.97          391035.0  \n",
       "berkshire-hathaway-inc 2020                       17.31          245579.0  \n",
       "                       2021                       32.56          276185.0  \n",
       "                       2022                       -7.54          302020.0  \n",
       "                       2023                       26.40          364482.0  \n",
       "                       2024                       23.96          371433.0  \n",
       "chevron                2020                       -5.90           94005.0  \n",
       "                       2021                       10.08          155067.0  \n",
       "                       2022                       15.03          235916.0  \n",
       "                       2023                       10.97          194799.0  \n",
       "                       2024                        9.03          195568.0  \n",
       "coca-cola-co           2020                       23.47           33014.0  \n",
       "                       2021                       25.28           38655.0  \n",
       "                       2022                       22.19           43004.0  \n",
       "                       2023                       23.42           45754.0  \n",
       "                       2024                       22.59           47061.0  \n",
       "disney                 2020                       -4.38           65388.0  \n",
       "                       2021                        2.96           67418.0  \n",
       "                       2022                        3.80           82722.0  \n",
       "                       2023                        2.65           88898.0  \n",
       "                       2024                        5.44           91361.0  \n",
       "google-inc             2020                       22.06          182527.0  \n",
       "                       2021                       29.51          257637.0  \n",
       "                       2022                       21.20          282836.0  \n",
       "                       2023                       24.01          307394.0  \n",
       "                       2024                       28.60          350018.0  \n",
       "microsoft-corp         2020                       30.96          143015.0  \n",
       "                       2021                       36.45          168088.0  \n",
       "                       2022                       36.69          198270.0  \n",
       "                       2023                       34.15          211915.0  \n",
       "                       2024                       35.96          245122.0  \n",
       "nike                   2020                        6.79           37403.0  \n",
       "                       2021                       12.86           44538.0  \n",
       "                       2022                       12.94           46710.0  \n",
       "                       2023                        9.90           51217.0  \n",
       "                       2024                       11.10           51362.0  \n",
       "pfizer                 2020                       21.99           41651.0  \n",
       "                       2021                       27.04           81288.0  \n",
       "                       2022                       31.01          101175.0  \n",
       "                       2023                        3.56           59554.0  \n",
       "                       2024                       12.62           63627.0  \n",
       "procter-gamble         2020                       18.36           70950.0  \n",
       "                       2021                       18.79           76118.0  \n",
       "                       2022                       18.38           80187.0  \n",
       "                       2023                       17.87           82006.0  \n",
       "                       2024                       17.70           84039.0  \n",
       "tesla-motors           2020                        2.29           31536.0  \n",
       "                       2021                       10.25           53823.0  \n",
       "                       2022                       15.41           81462.0  \n",
       "                       2023                       15.50           96773.0  \n",
       "                       2024                        7.26           97690.0  \n",
       "visa-inc               2020                       49.74           21846.0  \n",
       "                       2021                       51.07           24105.0  \n",
       "                       2022                       51.03           29310.0  \n",
       "                       2023                       52.90           32653.0  \n",
       "                       2024                       54.95           35926.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = pd.pivot_table(df[df.indicador.isin(activo_corriente)], index=[\"company\",\"ejercicio\"], values=\"valor\",aggfunc=\"sum\").rename(columns={\"valor\":\"activo_corriente\"})\n",
    "anc = pd.pivot_table(df[df.indicador.isin(activo_no_corriente)], index=[\"company\",\"ejercicio\"], values=\"valor\",aggfunc=\"sum\").rename(columns={\"valor\":\"activo_no_corriente\"})\n",
    "pc = pd.pivot_table(df[df.indicador.isin(pasivo_corriente)], index=[\"company\",\"ejercicio\"], values=\"valor\",aggfunc=\"sum\").rename(columns={\"valor\":\"pasivo_corriente\"})\n",
    "pnc = pd.pivot_table(df[df.indicador.isin(pasivo_no_corriente)], index=[\"company\",\"ejercicio\"], values=\"valor\",aggfunc=\"sum\").rename(columns={\"valor\":\"pasivo_no_corriente\"})\n",
    "pn = pd.pivot_table(df[df.indicador.isin(patrimonio_neto)], index=[\"company\",\"ejercicio\"], values=\"valor\",aggfunc=\"sum\").rename(columns={\"valor\":\"patrimonio_neto\"})\n",
    "inv = pd.pivot_table(df[df.indicador.isin(inventario)], index=[\"company\",\"ejercicio\"], values=\"valor\",aggfunc=\"sum\").rename(columns={\"valor\":\"inventario\"})\n",
    "ebit = pd.pivot_table(df[df.indicador.isin(EBIT)], index=[\"company\",\"ejercicio\"], values=\"valor\",aggfunc=\"sum\").rename(columns={\"valor\":\"EBIT\"})\n",
    "int = pd.pivot_table(df[df.indicador.isin(intereses)], index=[\"company\",\"ejercicio\"], values=\"valor\",aggfunc=\"sum\").rename(columns={\"valor\":\"intereses\"})\n",
    "bn = pd.pivot_table(df[df.indicador.isin(beneficio_neto)], index=[\"company\",\"ejercicio\"], values=\"valor\",aggfunc=\"sum\").rename(columns={\"valor\":\"beneficio_neto\"})\n",
    "mbn = pd.pivot_table(df[df.indicador.isin(mbn)], index=[\"company\",\"ejercicio\"], values=\"valor\",aggfunc=\"sum\").rename(columns={\"valor\":\"margen_beneficio_neto\"})\n",
    "ingt = pd.pivot_table(df[df.indicador.isin(ing)], index=[\"company\",\"ejercicio\"], values=\"valor\",aggfunc=\"sum\").rename(columns={\"valor\":\"ingresos_totales\"})\n",
    "\n",
    "data = pd.concat([ac,anc,pc,pnc,pn,inv,ebit,int,bn,mbn,ingt], axis=1)\n",
    "data.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"inventario\"] = data[\"inventario\"].fillna(0)\n",
    "data[\"intereses\"] = data[\"intereses\"].fillna(0)\n",
    "data[\"intereses\"] = data[\"intereses\"].abs()\n",
    "data[\"razon_corriente\"] = data[\"activo_corriente\"] / data[\"pasivo_corriente\"]\n",
    "data[\"activo_total\"] = data[\"activo_corriente\"] + data[\"activo_no_corriente\"]\n",
    "data[\"pasivo_total\"] = data[\"pasivo_corriente\"] + data[\"pasivo_no_corriente\"]\n",
    "data[\"prueba_acida\"] = (data[\"activo_corriente\"] - data[\"inventario\"]) / data[\"pasivo_corriente\"]\n",
    "data[\"endeudamiento\"] = (data[\"pasivo_total\"]) / (data[\"activo_total\"])\n",
    "data[\"endeudamiento_a_largo_plazo\"] = data[\"pasivo_no_corriente\"] / (data[\"activo_total\"])\n",
    "data[\"covertura_de_intereses\"] = data[\"EBIT\"] / data[\"intereses\"]\n",
    "data.loc[data[\"intereses\"] == 0, \"covertura_de_intereses\"] = 0\n",
    "data[\"ROA\"] = data[\"beneficio_neto\"] / data[\"activo_total\"]\n",
    "data[\"ROE\"] = data[\"beneficio_neto\"] / data[\"patrimonio_neto\"]\n",
    "data[\"rotacion_activos\"] = data[\"ingresos_totales\"] / data[\"activo_total\"]\n",
    "data[\"rotacion_inventario\"] = data[\"ingresos_totales\"] / data[\"inventario\"]\n",
    "data.loc[data[\"inventario\"] == 0, \"rotacion_inventario\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"razon_corriente\",\n",
    "    \"prueba_acida\",\n",
    "    \"endeudamiento\",\n",
    "    \"endeudamiento_a_largo_plazo\",\n",
    "    \"covertura_de_intereses\",\n",
    "    \"ROA\",\n",
    "    \"ROE\",\n",
    "    \"rotacion_activos\",\n",
    "    \"rotacion_inventario\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ejercicio",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "razon_corriente",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prueba_acida",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "endeudamiento",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "endeudamiento_a_largo_plazo",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "covertura_de_intereses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ROA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ROE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rotacion_activos",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rotacion_inventario",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "417a490b-df99-45e3-a055-b0a63560d3b8",
       "rows": [
        [
         "0",
         "3m-co",
         "2020",
         "1.88",
         "1.35",
         "0.73",
         "0.56",
         "13.53",
         "0.12",
         "0.42",
         "0.68",
         "7.59"
        ],
        [
         "1",
         "3m-co",
         "2021",
         "1.7",
         "1.15",
         "0.68",
         "0.49",
         "15.89",
         "0.13",
         "0.39",
         "0.75",
         "7.09"
        ],
        [
         "2",
         "3m-co",
         "2022",
         "1.54",
         "0.98",
         "0.68",
         "0.48",
         "7.25",
         "0.12",
         "0.39",
         "0.56",
         "4.87"
        ],
        [
         "3",
         "3m-co",
         "2023",
         "1.07",
         "0.81",
         "0.9",
         "0.6",
         "4.55",
         "-0.14",
         "-1.44",
         "0.49",
         "6.24"
        ],
        [
         "4",
         "3m-co",
         "2024",
         "1.41",
         "1.08",
         "0.9",
         "0.62",
         "3.6",
         "0.1",
         "1.08",
         "0.62",
         "6.65"
        ],
        [
         "5",
         "YPF",
         "2020",
         "0.86",
         "0.59",
         "0.65",
         "0.45",
         "-1.03",
         "-0.04",
         "-0.1",
         "0.36",
         "6.92"
        ],
        [
         "6",
         "YPF",
         "2021",
         "1.17",
         "0.77",
         "0.65",
         "0.48",
         "1.32",
         "0.0",
         "0.0",
         "0.55",
         "8.55"
        ],
        [
         "7",
         "YPF",
         "2022",
         "1.06",
         "0.7",
         "0.59",
         "0.41",
         "3.19",
         "0.06",
         "0.15",
         "0.55",
         "8.21"
        ],
        [
         "8",
         "YPF",
         "2023",
         "0.88",
         "0.54",
         "0.64",
         "0.44",
         "0.69",
         "-0.08",
         "-0.21",
         "0.27",
         "4.04"
        ],
        [
         "9",
         "YPF",
         "2024",
         "0.74",
         "0.56",
         "0.6",
         "0.31",
         "2.62",
         "0.07",
         "0.17",
         "0.6",
         "11.23"
        ],
        [
         "10",
         "amazon-com-inc",
         "2020",
         "1.05",
         "0.86",
         "0.71",
         "0.32",
         "13.9",
         "0.07",
         "0.23",
         "1.2",
         "16.22"
        ],
        [
         "11",
         "amazon-com-inc",
         "2021",
         "1.14",
         "0.91",
         "0.67",
         "0.33",
         "13.75",
         "0.08",
         "0.24",
         "1.12",
         "14.39"
        ],
        [
         "12",
         "amazon-com-inc",
         "2022",
         "0.94",
         "0.72",
         "0.68",
         "0.35",
         "5.64",
         "-0.01",
         "-0.02",
         "1.11",
         "14.94"
        ],
        [
         "13",
         "amazon-com-inc",
         "2023",
         "1.05",
         "0.84",
         "0.62",
         "0.31",
         "11.58",
         "0.06",
         "0.15",
         "1.09",
         "17.25"
        ],
        [
         "14",
         "amazon-com-inc",
         "2024",
         "1.06",
         "0.87",
         "0.54",
         "0.26",
         "28.51",
         "0.09",
         "0.21",
         "1.02",
         "18.65"
        ],
        [
         "15",
         "apple-computer-inc",
         "2020",
         "1.36",
         "1.33",
         "0.8",
         "0.47",
         "23.07",
         "0.18",
         "0.88",
         "0.85",
         "67.6"
        ],
        [
         "16",
         "apple-computer-inc",
         "2021",
         "1.07",
         "1.02",
         "0.82",
         "0.46",
         "41.19",
         "0.27",
         "1.5",
         "1.04",
         "55.6"
        ],
        [
         "17",
         "apple-computer-inc",
         "2022",
         "0.88",
         "0.85",
         "0.86",
         "0.42",
         "0.0",
         "0.28",
         "1.97",
         "1.12",
         "79.73"
        ],
        [
         "18",
         "apple-computer-inc",
         "2023",
         "0.99",
         "0.94",
         "0.82",
         "0.41",
         "0.0",
         "0.28",
         "1.56",
         "1.09",
         "60.54"
        ],
        [
         "19",
         "apple-computer-inc",
         "2024",
         "0.87",
         "0.83",
         "0.84",
         "0.36",
         "0.0",
         "0.26",
         "1.65",
         "1.07",
         "53.67"
        ],
        [
         "20",
         "berkshire-hathaway-inc",
         "2020",
         "4.25",
         "3.83",
         "0.48",
         "0.43",
         "17.09",
         "0.05",
         "0.09",
         "0.28",
         "12.79"
        ],
        [
         "21",
         "berkshire-hathaway-inc",
         "2021",
         "4.6",
         "4.14",
         "0.46",
         "0.42",
         "27.6",
         "0.09",
         "0.18",
         "0.29",
         "13.18"
        ],
        [
         "22",
         "berkshire-hathaway-inc",
         "2022",
         "4.11",
         "3.59",
         "0.49",
         "0.44",
         "-6.44",
         "-0.02",
         "-0.05",
         "0.32",
         "11.91"
        ],
        [
         "23",
         "berkshire-hathaway-inc",
         "2023",
         "4.31",
         "3.86",
         "0.47",
         "0.41",
         "24.62",
         "0.09",
         "0.17",
         "0.34",
         "14.1"
        ],
        [
         "24",
         "berkshire-hathaway-inc",
         "2024",
         "5.39",
         "5.07",
         "0.44",
         "0.37",
         "21.87",
         "0.08",
         "0.14",
         "0.32",
         "15.47"
        ],
        [
         "25",
         "chevron",
         "2020",
         "1.18",
         "0.92",
         "0.45",
         "0.35",
         "-6.1",
         "-0.02",
         "-0.04",
         "0.39",
         "16.56"
        ],
        [
         "26",
         "chevron",
         "2021",
         "1.26",
         "1.01",
         "0.42",
         "0.3",
         "22.59",
         "0.07",
         "0.11",
         "0.65",
         "22.82"
        ],
        [
         "27",
         "chevron",
         "2022",
         "1.47",
         "1.23",
         "0.38",
         "0.25",
         "81.41",
         "0.14",
         "0.22",
         "0.92",
         "28.61"
        ],
        [
         "28",
         "chevron",
         "2023",
         "1.27",
         "1.01",
         "0.38",
         "0.26",
         "57.49",
         "0.08",
         "0.13",
         "0.74",
         "22.62"
        ],
        [
         "29",
         "chevron",
         "2024",
         "1.06",
         "0.83",
         "0.4",
         "0.25",
         "39.22",
         "0.07",
         "0.12",
         "0.76",
         "21.55"
        ],
        [
         "30",
         "coca-cola-co",
         "2020",
         "1.32",
         "1.09",
         "0.76",
         "0.59",
         "6.95",
         "0.09",
         "0.36",
         "0.38",
         "10.11"
        ],
        [
         "31",
         "coca-cola-co",
         "2021",
         "1.13",
         "0.96",
         "0.74",
         "0.53",
         "7.16",
         "0.1",
         "0.39",
         "0.41",
         "11.32"
        ],
        [
         "32",
         "coca-cola-co",
         "2022",
         "1.15",
         "0.93",
         "0.72",
         "0.51",
         "13.99",
         "0.1",
         "0.37",
         "0.46",
         "10.16"
        ],
        [
         "33",
         "coca-cola-co",
         "2023",
         "1.13",
         "0.95",
         "0.72",
         "0.48",
         "8.67",
         "0.11",
         "0.39",
         "0.47",
         "10.34"
        ],
        [
         "34",
         "coca-cola-co",
         "2024",
         "1.03",
         "0.84",
         "0.74",
         "0.49",
         "8.64",
         "0.11",
         "0.4",
         "0.47",
         "9.95"
        ],
        [
         "35",
         "disney",
         "2020",
         "1.32",
         "1.18",
         "0.52",
         "0.38",
         "2.3",
         "-0.01",
         "-0.03",
         "0.32",
         "17.42"
        ],
        [
         "36",
         "disney",
         "2021",
         "1.08",
         "0.97",
         "0.5",
         "0.35",
         "2.26",
         "0.01",
         "0.02",
         "0.33",
         "19.19"
        ],
        [
         "37",
         "disney",
         "2022",
         "1.0",
         "0.88",
         "0.47",
         "0.32",
         "4.41",
         "0.02",
         "0.03",
         "0.41",
         "22.78"
        ],
        [
         "38",
         "disney",
         "2023",
         "1.05",
         "0.89",
         "0.45",
         "0.3",
         "4.73",
         "0.01",
         "0.02",
         "0.43",
         "17.9"
        ],
        [
         "39",
         "disney",
         "2024",
         "0.73",
         "0.61",
         "0.46",
         "0.29",
         "5.95",
         "0.03",
         "0.05",
         "0.47",
         "22.18"
        ],
        [
         "40",
         "google-inc",
         "2020",
         "3.07",
         "3.05",
         "0.3",
         "0.13",
         "305.36",
         "0.13",
         "0.18",
         "0.57",
         "250.72"
        ],
        [
         "41",
         "google-inc",
         "2021",
         "2.93",
         "2.91",
         "0.3",
         "0.12",
         "227.5",
         "0.21",
         "0.3",
         "0.72",
         "220.2"
        ],
        [
         "42",
         "google-inc",
         "2022",
         "2.38",
         "2.38",
         "0.3",
         "0.11",
         "209.64",
         "0.16",
         "0.23",
         "0.77",
         "0.0"
        ],
        [
         "43",
         "google-inc",
         "2023",
         "2.1",
         "2.1",
         "0.3",
         "0.09",
         "273.68",
         "0.18",
         "0.26",
         "0.76",
         "0.0"
        ],
        [
         "44",
         "google-inc",
         "2024",
         "1.84",
         "1.84",
         "0.28",
         "0.08",
         "426.07",
         "0.22",
         "0.31",
         "0.78",
         "0.0"
        ],
        [
         "45",
         "microsoft-corp",
         "2020",
         "2.52",
         "2.49",
         "0.61",
         "0.37",
         "20.44",
         "0.15",
         "0.37",
         "0.47",
         "75.47"
        ],
        [
         "46",
         "microsoft-corp",
         "2021",
         "2.08",
         "2.05",
         "0.57",
         "0.31",
         "30.01",
         "0.18",
         "0.43",
         "0.5",
         "63.77"
        ],
        [
         "47",
         "microsoft-corp",
         "2022",
         "1.78",
         "1.75",
         "0.54",
         "0.28",
         "40.73",
         "0.2",
         "0.44",
         "0.54",
         "52.99"
        ],
        [
         "48",
         "microsoft-corp",
         "2023",
         "1.77",
         "1.75",
         "0.5",
         "0.25",
         "44.45",
         "0.18",
         "0.35",
         "0.51",
         "84.77"
        ],
        [
         "49",
         "microsoft-corp",
         "2024",
         "1.27",
         "1.27",
         "0.48",
         "0.23",
         "36.69",
         "0.17",
         "0.33",
         "0.48",
         "196.73"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 75
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>ejercicio</th>\n",
       "      <th>razon_corriente</th>\n",
       "      <th>prueba_acida</th>\n",
       "      <th>endeudamiento</th>\n",
       "      <th>endeudamiento_a_largo_plazo</th>\n",
       "      <th>covertura_de_intereses</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>rotacion_activos</th>\n",
       "      <th>rotacion_inventario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.56</td>\n",
       "      <td>13.53</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.68</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.49</td>\n",
       "      <td>15.89</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.75</td>\n",
       "      <td>7.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.56</td>\n",
       "      <td>4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.55</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>0.49</td>\n",
       "      <td>6.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.62</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.62</td>\n",
       "      <td>6.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YPF</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YPF</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>YPF</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>YPF</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>YPF</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.60</td>\n",
       "      <td>11.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.32</td>\n",
       "      <td>13.90</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.20</td>\n",
       "      <td>16.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.33</td>\n",
       "      <td>13.75</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.12</td>\n",
       "      <td>14.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.35</td>\n",
       "      <td>5.64</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>1.11</td>\n",
       "      <td>14.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.31</td>\n",
       "      <td>11.58</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.09</td>\n",
       "      <td>17.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.26</td>\n",
       "      <td>28.51</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.02</td>\n",
       "      <td>18.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.47</td>\n",
       "      <td>23.07</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>67.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.46</td>\n",
       "      <td>41.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.04</td>\n",
       "      <td>55.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.12</td>\n",
       "      <td>79.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.09</td>\n",
       "      <td>60.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.07</td>\n",
       "      <td>53.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3.83</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.43</td>\n",
       "      <td>17.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.28</td>\n",
       "      <td>12.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>2021</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.14</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.42</td>\n",
       "      <td>27.60</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.29</td>\n",
       "      <td>13.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>2022</td>\n",
       "      <td>4.11</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-6.44</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>2023</td>\n",
       "      <td>4.31</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.41</td>\n",
       "      <td>24.62</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>2024</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.07</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.37</td>\n",
       "      <td>21.87</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>15.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chevron</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-6.10</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>16.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>chevron</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.30</td>\n",
       "      <td>22.59</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.65</td>\n",
       "      <td>22.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chevron</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.25</td>\n",
       "      <td>81.41</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.92</td>\n",
       "      <td>28.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>chevron</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.26</td>\n",
       "      <td>57.49</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.74</td>\n",
       "      <td>22.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>chevron</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>39.22</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.76</td>\n",
       "      <td>21.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.59</td>\n",
       "      <td>6.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.53</td>\n",
       "      <td>7.16</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.41</td>\n",
       "      <td>11.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>13.99</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>10.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.48</td>\n",
       "      <td>8.67</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.49</td>\n",
       "      <td>8.64</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>disney</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.32</td>\n",
       "      <td>17.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>disney</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.33</td>\n",
       "      <td>19.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>disney</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.32</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.41</td>\n",
       "      <td>22.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>disney</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.73</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.43</td>\n",
       "      <td>17.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>disney</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.29</td>\n",
       "      <td>5.95</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.47</td>\n",
       "      <td>22.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.13</td>\n",
       "      <td>305.36</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.57</td>\n",
       "      <td>250.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>227.50</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.72</td>\n",
       "      <td>220.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>2022</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>209.64</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>2023</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.09</td>\n",
       "      <td>273.68</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.08</td>\n",
       "      <td>426.07</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.37</td>\n",
       "      <td>20.44</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.47</td>\n",
       "      <td>75.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.31</td>\n",
       "      <td>30.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.50</td>\n",
       "      <td>63.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.28</td>\n",
       "      <td>40.73</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.54</td>\n",
       "      <td>52.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>44.45</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.51</td>\n",
       "      <td>84.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.23</td>\n",
       "      <td>36.69</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.48</td>\n",
       "      <td>196.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>nike</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.48</td>\n",
       "      <td>20.63</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.19</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>nike</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.41</td>\n",
       "      <td>24.43</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.18</td>\n",
       "      <td>6.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>nike</td>\n",
       "      <td>2022</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.35</td>\n",
       "      <td>22.32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.16</td>\n",
       "      <td>5.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>nike</td>\n",
       "      <td>2023</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.38</td>\n",
       "      <td>20.33</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.36</td>\n",
       "      <td>6.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>nike</td>\n",
       "      <td>2024</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.34</td>\n",
       "      <td>25.11</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.35</td>\n",
       "      <td>6.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.42</td>\n",
       "      <td>6.76</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.27</td>\n",
       "      <td>5.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.34</td>\n",
       "      <td>20.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.30</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.51</td>\n",
       "      <td>11.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.26</td>\n",
       "      <td>5.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.38</td>\n",
       "      <td>5.28</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.34</td>\n",
       "      <td>34.63</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.59</td>\n",
       "      <td>12.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.33</td>\n",
       "      <td>36.82</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.64</td>\n",
       "      <td>12.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.32</td>\n",
       "      <td>42.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.68</td>\n",
       "      <td>11.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.31</td>\n",
       "      <td>25.21</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.68</td>\n",
       "      <td>11.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.31</td>\n",
       "      <td>22.65</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.69</td>\n",
       "      <td>11.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tesla-motors</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.60</td>\n",
       "      <td>7.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tesla-motors</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>17.58</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.87</td>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tesla-motors</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.12</td>\n",
       "      <td>71.69</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.99</td>\n",
       "      <td>6.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tesla-motors</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.13</td>\n",
       "      <td>56.99</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.91</td>\n",
       "      <td>7.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tesla-motors</td>\n",
       "      <td>2024</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.16</td>\n",
       "      <td>21.88</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>8.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.37</td>\n",
       "      <td>27.37</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.36</td>\n",
       "      <td>30.81</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.34</td>\n",
       "      <td>36.58</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.32</td>\n",
       "      <td>34.05</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.31</td>\n",
       "      <td>37.35</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company  ejercicio  razon_corriente  prueba_acida  \\\n",
       "0                    3m-co       2020             1.88          1.35   \n",
       "1                    3m-co       2021             1.70          1.15   \n",
       "2                    3m-co       2022             1.54          0.98   \n",
       "3                    3m-co       2023             1.07          0.81   \n",
       "4                    3m-co       2024             1.41          1.08   \n",
       "5                      YPF       2020             0.86          0.59   \n",
       "6                      YPF       2021             1.17          0.77   \n",
       "7                      YPF       2022             1.06          0.70   \n",
       "8                      YPF       2023             0.88          0.54   \n",
       "9                      YPF       2024             0.74          0.56   \n",
       "10          amazon-com-inc       2020             1.05          0.86   \n",
       "11          amazon-com-inc       2021             1.14          0.91   \n",
       "12          amazon-com-inc       2022             0.94          0.72   \n",
       "13          amazon-com-inc       2023             1.05          0.84   \n",
       "14          amazon-com-inc       2024             1.06          0.87   \n",
       "15      apple-computer-inc       2020             1.36          1.33   \n",
       "16      apple-computer-inc       2021             1.07          1.02   \n",
       "17      apple-computer-inc       2022             0.88          0.85   \n",
       "18      apple-computer-inc       2023             0.99          0.94   \n",
       "19      apple-computer-inc       2024             0.87          0.83   \n",
       "20  berkshire-hathaway-inc       2020             4.25          3.83   \n",
       "21  berkshire-hathaway-inc       2021             4.60          4.14   \n",
       "22  berkshire-hathaway-inc       2022             4.11          3.59   \n",
       "23  berkshire-hathaway-inc       2023             4.31          3.86   \n",
       "24  berkshire-hathaway-inc       2024             5.39          5.07   \n",
       "25                 chevron       2020             1.18          0.92   \n",
       "26                 chevron       2021             1.26          1.01   \n",
       "27                 chevron       2022             1.47          1.23   \n",
       "28                 chevron       2023             1.27          1.01   \n",
       "29                 chevron       2024             1.06          0.83   \n",
       "30            coca-cola-co       2020             1.32          1.09   \n",
       "31            coca-cola-co       2021             1.13          0.96   \n",
       "32            coca-cola-co       2022             1.15          0.93   \n",
       "33            coca-cola-co       2023             1.13          0.95   \n",
       "34            coca-cola-co       2024             1.03          0.84   \n",
       "35                  disney       2020             1.32          1.18   \n",
       "36                  disney       2021             1.08          0.97   \n",
       "37                  disney       2022             1.00          0.88   \n",
       "38                  disney       2023             1.05          0.89   \n",
       "39                  disney       2024             0.73          0.61   \n",
       "40              google-inc       2020             3.07          3.05   \n",
       "41              google-inc       2021             2.93          2.91   \n",
       "42              google-inc       2022             2.38          2.38   \n",
       "43              google-inc       2023             2.10          2.10   \n",
       "44              google-inc       2024             1.84          1.84   \n",
       "45          microsoft-corp       2020             2.52          2.49   \n",
       "46          microsoft-corp       2021             2.08          2.05   \n",
       "47          microsoft-corp       2022             1.78          1.75   \n",
       "48          microsoft-corp       2023             1.77          1.75   \n",
       "49          microsoft-corp       2024             1.27          1.27   \n",
       "50                    nike       2020             2.48          1.59   \n",
       "51                    nike       2021             2.72          2.01   \n",
       "52                    nike       2022             2.63          1.84   \n",
       "53                    nike       2023             2.72          1.81   \n",
       "54                    nike       2024             2.40          1.69   \n",
       "55                  pfizer       2020             1.35          1.04   \n",
       "56                  pfizer       2021             1.40          1.19   \n",
       "57                  pfizer       2022             1.22          1.00   \n",
       "58                  pfizer       2023             0.91          0.69   \n",
       "59                  pfizer       2024             1.17          0.92   \n",
       "60          procter-gamble       2020             0.85          0.68   \n",
       "61          procter-gamble       2021             0.70          0.52   \n",
       "62          procter-gamble       2022             0.65          0.45   \n",
       "63          procter-gamble       2023             0.63          0.44   \n",
       "64          procter-gamble       2024             0.73          0.53   \n",
       "65            tesla-motors       2020             1.88          1.59   \n",
       "66            tesla-motors       2021             1.38          1.08   \n",
       "67            tesla-motors       2022             1.53          1.05   \n",
       "68            tesla-motors       2023             1.73          1.25   \n",
       "69            tesla-motors       2024             2.02          1.61   \n",
       "70                visa-inc       2020             1.91          1.91   \n",
       "71                visa-inc       2021             1.75          1.75   \n",
       "72                visa-inc       2022             1.45          1.45   \n",
       "73                visa-inc       2023             1.45          1.45   \n",
       "74                visa-inc       2024             1.28          1.28   \n",
       "\n",
       "    endeudamiento  endeudamiento_a_largo_plazo  covertura_de_intereses   ROA  \\\n",
       "0            0.73                         0.56                   13.53  0.12   \n",
       "1            0.68                         0.49                   15.89  0.13   \n",
       "2            0.68                         0.48                    7.25  0.12   \n",
       "3            0.90                         0.60                    4.55 -0.14   \n",
       "4            0.90                         0.62                    3.60  0.10   \n",
       "5            0.65                         0.45                   -1.03 -0.04   \n",
       "6            0.65                         0.48                    1.32  0.00   \n",
       "7            0.59                         0.41                    3.19  0.06   \n",
       "8            0.64                         0.44                    0.69 -0.08   \n",
       "9            0.60                         0.31                    2.62  0.07   \n",
       "10           0.71                         0.32                   13.90  0.07   \n",
       "11           0.67                         0.33                   13.75  0.08   \n",
       "12           0.68                         0.35                    5.64 -0.01   \n",
       "13           0.62                         0.31                   11.58  0.06   \n",
       "14           0.54                         0.26                   28.51  0.09   \n",
       "15           0.80                         0.47                   23.07  0.18   \n",
       "16           0.82                         0.46                   41.19  0.27   \n",
       "17           0.86                         0.42                    0.00  0.28   \n",
       "18           0.82                         0.41                    0.00  0.28   \n",
       "19           0.84                         0.36                    0.00  0.26   \n",
       "20           0.48                         0.43                   17.09  0.05   \n",
       "21           0.46                         0.42                   27.60  0.09   \n",
       "22           0.49                         0.44                   -6.44 -0.02   \n",
       "23           0.47                         0.41                   24.62  0.09   \n",
       "24           0.44                         0.37                   21.87  0.08   \n",
       "25           0.45                         0.35                   -6.10 -0.02   \n",
       "26           0.42                         0.30                   22.59  0.07   \n",
       "27           0.38                         0.25                   81.41  0.14   \n",
       "28           0.38                         0.26                   57.49  0.08   \n",
       "29           0.40                         0.25                   39.22  0.07   \n",
       "30           0.76                         0.59                    6.95  0.09   \n",
       "31           0.74                         0.53                    7.16  0.10   \n",
       "32           0.72                         0.51                   13.99  0.10   \n",
       "33           0.72                         0.48                    8.67  0.11   \n",
       "34           0.74                         0.49                    8.64  0.11   \n",
       "35           0.52                         0.38                    2.30 -0.01   \n",
       "36           0.50                         0.35                    2.26  0.01   \n",
       "37           0.47                         0.32                    4.41  0.02   \n",
       "38           0.45                         0.30                    4.73  0.01   \n",
       "39           0.46                         0.29                    5.95  0.03   \n",
       "40           0.30                         0.13                  305.36  0.13   \n",
       "41           0.30                         0.12                  227.50  0.21   \n",
       "42           0.30                         0.11                  209.64  0.16   \n",
       "43           0.30                         0.09                  273.68  0.18   \n",
       "44           0.28                         0.08                  426.07  0.22   \n",
       "45           0.61                         0.37                   20.44  0.15   \n",
       "46           0.57                         0.31                   30.01  0.18   \n",
       "47           0.54                         0.28                   40.73  0.20   \n",
       "48           0.50                         0.25                   44.45  0.18   \n",
       "49           0.48                         0.23                   36.69  0.17   \n",
       "50           0.74                         0.48                   20.63  0.08   \n",
       "51           0.66                         0.41                   24.43  0.15   \n",
       "52           0.62                         0.35                   22.32  0.15   \n",
       "53           0.63                         0.38                   20.33  0.14   \n",
       "54           0.62                         0.34                   25.11  0.15   \n",
       "55           0.59                         0.42                    6.76  0.06   \n",
       "56           0.57                         0.34                   20.90  0.12   \n",
       "57           0.51                         0.30                   32.18  0.16   \n",
       "58           0.61                         0.39                    2.86  0.01   \n",
       "59           0.59                         0.38                    5.28  0.04   \n",
       "60           0.61                         0.34                   34.63  0.11   \n",
       "61           0.61                         0.33                   36.82  0.12   \n",
       "62           0.60                         0.32                   42.02  0.13   \n",
       "63           0.61                         0.31                   25.21  0.12   \n",
       "64           0.59                         0.31                   22.65  0.12   \n",
       "65           0.55                         0.27                    2.61  0.01   \n",
       "66           0.49                         0.17                   17.58  0.09   \n",
       "67           0.44                         0.12                   71.69  0.15   \n",
       "68           0.40                         0.13                   56.99  0.14   \n",
       "69           0.40                         0.16                   21.88  0.06   \n",
       "70           0.55                         0.37                   27.37  0.13   \n",
       "71           0.55                         0.36                   30.81  0.15   \n",
       "72           0.58                         0.34                   36.58  0.17   \n",
       "73           0.57                         0.32                   34.05  0.19   \n",
       "74           0.59                         0.31                   37.35  0.21   \n",
       "\n",
       "     ROE  rotacion_activos  rotacion_inventario  \n",
       "0   0.42              0.68                 7.59  \n",
       "1   0.39              0.75                 7.09  \n",
       "2   0.39              0.56                 4.87  \n",
       "3  -1.44              0.49                 6.24  \n",
       "4   1.08              0.62                 6.65  \n",
       "5  -0.10              0.36                 6.92  \n",
       "6   0.00              0.55                 8.55  \n",
       "7   0.15              0.55                 8.21  \n",
       "8  -0.21              0.27                 4.04  \n",
       "9   0.17              0.60                11.23  \n",
       "10  0.23              1.20                16.22  \n",
       "11  0.24              1.12                14.39  \n",
       "12 -0.02              1.11                14.94  \n",
       "13  0.15              1.09                17.25  \n",
       "14  0.21              1.02                18.65  \n",
       "15  0.88              0.85                67.60  \n",
       "16  1.50              1.04                55.60  \n",
       "17  1.97              1.12                79.73  \n",
       "18  1.56              1.09                60.54  \n",
       "19  1.65              1.07                53.67  \n",
       "20  0.09              0.28                12.79  \n",
       "21  0.18              0.29                13.18  \n",
       "22 -0.05              0.32                11.91  \n",
       "23  0.17              0.34                14.10  \n",
       "24  0.14              0.32                15.47  \n",
       "25 -0.04              0.39                16.56  \n",
       "26  0.11              0.65                22.82  \n",
       "27  0.22              0.92                28.61  \n",
       "28  0.13              0.74                22.62  \n",
       "29  0.12              0.76                21.55  \n",
       "30  0.36              0.38                10.11  \n",
       "31  0.39              0.41                11.32  \n",
       "32  0.37              0.46                10.16  \n",
       "33  0.39              0.47                10.34  \n",
       "34  0.40              0.47                 9.95  \n",
       "35 -0.03              0.32                17.42  \n",
       "36  0.02              0.33                19.19  \n",
       "37  0.03              0.41                22.78  \n",
       "38  0.02              0.43                17.90  \n",
       "39  0.05              0.47                22.18  \n",
       "40  0.18              0.57               250.72  \n",
       "41  0.30              0.72               220.20  \n",
       "42  0.23              0.77                 0.00  \n",
       "43  0.26              0.76                 0.00  \n",
       "44  0.31              0.78                 0.00  \n",
       "45  0.37              0.47                75.47  \n",
       "46  0.43              0.50                63.77  \n",
       "47  0.44              0.54                52.99  \n",
       "48  0.35              0.51                84.77  \n",
       "49  0.33              0.48               196.73  \n",
       "50  0.32              1.19                 5.08  \n",
       "51  0.45              1.18                 6.50  \n",
       "52  0.40              1.16                 5.55  \n",
       "53  0.36              1.36                 6.06  \n",
       "54  0.40              1.35                 6.83  \n",
       "55  0.14              0.27                 5.19  \n",
       "56  0.28              0.45                 8.97  \n",
       "57  0.33              0.51                11.27  \n",
       "58  0.02              0.26                 5.84  \n",
       "59  0.09              0.30                 5.86  \n",
       "60  0.28              0.59                12.90  \n",
       "61  0.31              0.64                12.72  \n",
       "62  0.31              0.68                11.58  \n",
       "63  0.31              0.68                11.59  \n",
       "64  0.29              0.69                11.98  \n",
       "65  0.03              0.60                 7.69  \n",
       "66  0.18              0.87                 9.35  \n",
       "67  0.27              0.99                 6.34  \n",
       "68  0.24              0.91                 7.10  \n",
       "69  0.10              0.80                 8.13  \n",
       "70  0.30              0.27                 0.00  \n",
       "71  0.33              0.29                 0.00  \n",
       "72  0.42              0.34                 0.00  \n",
       "73  0.45              0.36                 0.00  \n",
       "74  0.50              0.38                 0.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[features].reset_index().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ejercicio",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "variacion",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c52d901a-9b40-4d47-8f6c-3836faf4ed40",
       "rows": [
        [
         "0",
         "76",
         "apple-computer-inc",
         "AAPL",
         "2019",
         "81.16829001155277"
        ],
        [
         "1",
         "77",
         "apple-computer-inc",
         "AAPL",
         "2020",
         "39.4682109756487"
        ],
        [
         "2",
         "78",
         "apple-computer-inc",
         "AAPL",
         "2021",
         "-28.376331018325995"
        ],
        [
         "3",
         "79",
         "apple-computer-inc",
         "AAPL",
         "2022",
         "54.79822815057525"
        ],
        [
         "4",
         "80",
         "apple-computer-inc",
         "AAPL",
         "2023",
         "38.354958595509416"
        ],
        [
         "5",
         "81",
         "microsoft-corp",
         "MSFT",
         "2019",
         "41.03136574533666"
        ],
        [
         "6",
         "82",
         "microsoft-corp",
         "MSFT",
         "2020",
         "58.39789192405092"
        ],
        [
         "7",
         "83",
         "microsoft-corp",
         "MSFT",
         "2021",
         "-27.328361635927422"
        ],
        [
         "8",
         "84",
         "microsoft-corp",
         "MSFT",
         "2022",
         "58.34974952470342"
        ],
        [
         "9",
         "85",
         "microsoft-corp",
         "MSFT",
         "2023",
         "16.954590118710012"
        ],
        [
         "10",
         "86",
         "google-inc",
         "GOOGL",
         "2019",
         "28.427392050341993"
        ],
        [
         "11",
         "87",
         "google-inc",
         "GOOGL",
         "2020",
         "69.9234714270234"
        ],
        [
         "12",
         "88",
         "google-inc",
         "GOOGL",
         "2021",
         "-38.996425908987575"
        ],
        [
         "13",
         "89",
         "google-inc",
         "GOOGL",
         "2022",
         "56.743711870640844"
        ],
        [
         "14",
         "90",
         "google-inc",
         "GOOGL",
         "2023",
         "40.01503325058091"
        ],
        [
         "15",
         "91",
         "tesla-motors",
         "TSLA",
         "2019",
         "673.9390373235624"
        ],
        [
         "16",
         "92",
         "tesla-motors",
         "TSLA",
         "2020",
         "48.84004077513402"
        ],
        [
         "17",
         "93",
         "tesla-motors",
         "TSLA",
         "2021",
         "-69.53941560483538"
        ],
        [
         "18",
         "94",
         "tesla-motors",
         "TSLA",
         "2022",
         "129.8612388852389"
        ],
        [
         "19",
         "95",
         "tesla-motors",
         "TSLA",
         "2023",
         "73.76217971330405"
        ],
        [
         "20",
         "96",
         "visa-inc",
         "V",
         "2019",
         "12.855539387247262"
        ],
        [
         "21",
         "97",
         "visa-inc",
         "V",
         "2020",
         "0.8037081056345929"
        ],
        [
         "22",
         "98",
         "visa-inc",
         "V",
         "2021",
         "-5.327237785352668"
        ],
        [
         "23",
         "99",
         "visa-inc",
         "V",
         "2022",
         "26.533369861209046"
        ],
        [
         "24",
         "100",
         "visa-inc",
         "V",
         "2023",
         "24.037441439743446"
        ],
        [
         "25",
         "101",
         "berkshire-hathaway-inc",
         "BRK-A",
         "2019",
         "0.7476750199409299"
        ],
        [
         "26",
         "102",
         "berkshire-hathaway-inc",
         "BRK-A",
         "2020",
         "31.606724401426376"
        ],
        [
         "27",
         "103",
         "berkshire-hathaway-inc",
         "BRK-A",
         "2021",
         "3.1752146158925854"
        ],
        [
         "28",
         "104",
         "berkshire-hathaway-inc",
         "BRK-A",
         "2022",
         "15.568926042276775"
        ],
        [
         "29",
         "105",
         "berkshire-hathaway-inc",
         "BRK-A",
         "2023",
         "24.57715442525923"
        ],
        [
         "30",
         "106",
         "YPF",
         "YPF",
         "2019",
         "-56.21669868448846"
        ],
        [
         "31",
         "107",
         "YPF",
         "YPF",
         "2020",
         "-11.725663133324405"
        ],
        [
         "32",
         "108",
         "YPF",
         "YPF",
         "2021",
         "124.0099078264322"
        ],
        [
         "33",
         "109",
         "YPF",
         "YPF",
         "2022",
         "97.3593623280252"
        ],
        [
         "34",
         "110",
         "YPF",
         "YPF",
         "2023",
         "158.11136929847672"
        ],
        [
         "35",
         "111",
         "pfizer",
         "PFE",
         "2019",
         "3.847527475548085"
        ],
        [
         "36",
         "112",
         "pfizer",
         "PFE",
         "2020",
         "62.54537549230701"
        ],
        [
         "37",
         "113",
         "pfizer",
         "PFE",
         "2021",
         "-6.448355883861623"
        ],
        [
         "38",
         "114",
         "pfizer",
         "PFE",
         "2022",
         "-41.28702479084323"
        ],
        [
         "39",
         "115",
         "pfizer",
         "PFE",
         "2023",
         "-4.987516503142708"
        ],
        [
         "40",
         "116",
         "amazon-com-inc",
         "AMZN",
         "2019",
         "75.02543252169542"
        ],
        [
         "41",
         "117",
         "amazon-com-inc",
         "AMZN",
         "2020",
         "6.194322534998009"
        ],
        [
         "42",
         "118",
         "amazon-com-inc",
         "AMZN",
         "2021",
         "-50.59989457027987"
        ],
        [
         "43",
         "119",
         "amazon-com-inc",
         "AMZN",
         "2022",
         "77.04498133500893"
        ],
        [
         "44",
         "120",
         "amazon-com-inc",
         "AMZN",
         "2023",
         "49.236317568461516"
        ],
        [
         "45",
         "121",
         "disney",
         "DIS",
         "2019",
         "19.635633628190362"
        ],
        [
         "46",
         "122",
         "disney",
         "DIS",
         "2020",
         "-12.837683462669336"
        ],
        [
         "47",
         "123",
         "disney",
         "DIS",
         "2021",
         "-44.38632495005448"
        ],
        [
         "48",
         "124",
         "disney",
         "DIS",
         "2022",
         "1.8143837235537585"
        ],
        [
         "49",
         "125",
         "disney",
         "DIS",
         "2023",
         "24.08907578387387"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 75
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "      <th>ejercicio</th>\n",
       "      <th>variacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019</td>\n",
       "      <td>81.168290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "      <td>39.468211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2021</td>\n",
       "      <td>-28.376331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022</td>\n",
       "      <td>54.798228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023</td>\n",
       "      <td>38.354959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81</td>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2019</td>\n",
       "      <td>41.031366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>82</td>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2020</td>\n",
       "      <td>58.397892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>83</td>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2021</td>\n",
       "      <td>-27.328362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84</td>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2022</td>\n",
       "      <td>58.349750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>85</td>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2023</td>\n",
       "      <td>16.954590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86</td>\n",
       "      <td>google-inc</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2019</td>\n",
       "      <td>28.427392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>87</td>\n",
       "      <td>google-inc</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2020</td>\n",
       "      <td>69.923471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>88</td>\n",
       "      <td>google-inc</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2021</td>\n",
       "      <td>-38.996426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>89</td>\n",
       "      <td>google-inc</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2022</td>\n",
       "      <td>56.743712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>90</td>\n",
       "      <td>google-inc</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2023</td>\n",
       "      <td>40.015033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>91</td>\n",
       "      <td>tesla-motors</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2019</td>\n",
       "      <td>673.939037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>92</td>\n",
       "      <td>tesla-motors</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2020</td>\n",
       "      <td>48.840041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>93</td>\n",
       "      <td>tesla-motors</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2021</td>\n",
       "      <td>-69.539416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>94</td>\n",
       "      <td>tesla-motors</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2022</td>\n",
       "      <td>129.861239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>95</td>\n",
       "      <td>tesla-motors</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2023</td>\n",
       "      <td>73.762180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>96</td>\n",
       "      <td>visa-inc</td>\n",
       "      <td>V</td>\n",
       "      <td>2019</td>\n",
       "      <td>12.855539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>97</td>\n",
       "      <td>visa-inc</td>\n",
       "      <td>V</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.803708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>98</td>\n",
       "      <td>visa-inc</td>\n",
       "      <td>V</td>\n",
       "      <td>2021</td>\n",
       "      <td>-5.327238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>99</td>\n",
       "      <td>visa-inc</td>\n",
       "      <td>V</td>\n",
       "      <td>2022</td>\n",
       "      <td>26.533370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100</td>\n",
       "      <td>visa-inc</td>\n",
       "      <td>V</td>\n",
       "      <td>2023</td>\n",
       "      <td>24.037441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>101</td>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>BRK-A</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.747675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>102</td>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>BRK-A</td>\n",
       "      <td>2020</td>\n",
       "      <td>31.606724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>103</td>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>BRK-A</td>\n",
       "      <td>2021</td>\n",
       "      <td>3.175215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>104</td>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>BRK-A</td>\n",
       "      <td>2022</td>\n",
       "      <td>15.568926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>105</td>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>BRK-A</td>\n",
       "      <td>2023</td>\n",
       "      <td>24.577154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>106</td>\n",
       "      <td>YPF</td>\n",
       "      <td>YPF</td>\n",
       "      <td>2019</td>\n",
       "      <td>-56.216699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>107</td>\n",
       "      <td>YPF</td>\n",
       "      <td>YPF</td>\n",
       "      <td>2020</td>\n",
       "      <td>-11.725663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>108</td>\n",
       "      <td>YPF</td>\n",
       "      <td>YPF</td>\n",
       "      <td>2021</td>\n",
       "      <td>124.009908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>109</td>\n",
       "      <td>YPF</td>\n",
       "      <td>YPF</td>\n",
       "      <td>2022</td>\n",
       "      <td>97.359362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>110</td>\n",
       "      <td>YPF</td>\n",
       "      <td>YPF</td>\n",
       "      <td>2023</td>\n",
       "      <td>158.111369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>111</td>\n",
       "      <td>pfizer</td>\n",
       "      <td>PFE</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.847527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>112</td>\n",
       "      <td>pfizer</td>\n",
       "      <td>PFE</td>\n",
       "      <td>2020</td>\n",
       "      <td>62.545375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>113</td>\n",
       "      <td>pfizer</td>\n",
       "      <td>PFE</td>\n",
       "      <td>2021</td>\n",
       "      <td>-6.448356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>114</td>\n",
       "      <td>pfizer</td>\n",
       "      <td>PFE</td>\n",
       "      <td>2022</td>\n",
       "      <td>-41.287025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>115</td>\n",
       "      <td>pfizer</td>\n",
       "      <td>PFE</td>\n",
       "      <td>2023</td>\n",
       "      <td>-4.987517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>116</td>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2019</td>\n",
       "      <td>75.025433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>117</td>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2020</td>\n",
       "      <td>6.194323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>118</td>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2021</td>\n",
       "      <td>-50.599895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>119</td>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2022</td>\n",
       "      <td>77.044981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>120</td>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2023</td>\n",
       "      <td>49.236318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>121</td>\n",
       "      <td>disney</td>\n",
       "      <td>DIS</td>\n",
       "      <td>2019</td>\n",
       "      <td>19.635634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>122</td>\n",
       "      <td>disney</td>\n",
       "      <td>DIS</td>\n",
       "      <td>2020</td>\n",
       "      <td>-12.837683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>123</td>\n",
       "      <td>disney</td>\n",
       "      <td>DIS</td>\n",
       "      <td>2021</td>\n",
       "      <td>-44.386325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>124</td>\n",
       "      <td>disney</td>\n",
       "      <td>DIS</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.814384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>125</td>\n",
       "      <td>disney</td>\n",
       "      <td>DIS</td>\n",
       "      <td>2023</td>\n",
       "      <td>24.089076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>126</td>\n",
       "      <td>nike</td>\n",
       "      <td>NKE</td>\n",
       "      <td>2019</td>\n",
       "      <td>39.842576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>127</td>\n",
       "      <td>nike</td>\n",
       "      <td>NKE</td>\n",
       "      <td>2020</td>\n",
       "      <td>21.376981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>128</td>\n",
       "      <td>nike</td>\n",
       "      <td>NKE</td>\n",
       "      <td>2021</td>\n",
       "      <td>-27.970598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>129</td>\n",
       "      <td>nike</td>\n",
       "      <td>NKE</td>\n",
       "      <td>2022</td>\n",
       "      <td>-7.390852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>130</td>\n",
       "      <td>nike</td>\n",
       "      <td>NKE</td>\n",
       "      <td>2023</td>\n",
       "      <td>-27.047498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>131</td>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>PG</td>\n",
       "      <td>2019</td>\n",
       "      <td>14.932936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>132</td>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>PG</td>\n",
       "      <td>2020</td>\n",
       "      <td>22.130106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>133</td>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>PG</td>\n",
       "      <td>2021</td>\n",
       "      <td>-4.003617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>134</td>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>PG</td>\n",
       "      <td>2022</td>\n",
       "      <td>-0.864226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>135</td>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>PG</td>\n",
       "      <td>2023</td>\n",
       "      <td>16.814913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>136</td>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>KO</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.804627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>137</td>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>KO</td>\n",
       "      <td>2020</td>\n",
       "      <td>15.254871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>138</td>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>KO</td>\n",
       "      <td>2021</td>\n",
       "      <td>11.032015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>139</td>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>KO</td>\n",
       "      <td>2022</td>\n",
       "      <td>-3.432583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>140</td>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>KO</td>\n",
       "      <td>2023</td>\n",
       "      <td>7.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>141</td>\n",
       "      <td>chevron</td>\n",
       "      <td>CVX</td>\n",
       "      <td>2019</td>\n",
       "      <td>-26.373903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>142</td>\n",
       "      <td>chevron</td>\n",
       "      <td>CVX</td>\n",
       "      <td>2020</td>\n",
       "      <td>46.537884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>143</td>\n",
       "      <td>chevron</td>\n",
       "      <td>CVX</td>\n",
       "      <td>2021</td>\n",
       "      <td>54.908118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>144</td>\n",
       "      <td>chevron</td>\n",
       "      <td>CVX</td>\n",
       "      <td>2022</td>\n",
       "      <td>-10.902560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>145</td>\n",
       "      <td>chevron</td>\n",
       "      <td>CVX</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.484137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>146</td>\n",
       "      <td>3m-co</td>\n",
       "      <td>MMM</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.179640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>147</td>\n",
       "      <td>3m-co</td>\n",
       "      <td>MMM</td>\n",
       "      <td>2020</td>\n",
       "      <td>7.100160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>148</td>\n",
       "      <td>3m-co</td>\n",
       "      <td>MMM</td>\n",
       "      <td>2021</td>\n",
       "      <td>-29.288691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>149</td>\n",
       "      <td>3m-co</td>\n",
       "      <td>MMM</td>\n",
       "      <td>2022</td>\n",
       "      <td>-5.340940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>150</td>\n",
       "      <td>3m-co</td>\n",
       "      <td>MMM</td>\n",
       "      <td>2023</td>\n",
       "      <td>46.447312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                 company ticker  ejercicio   variacion\n",
       "0    76      apple-computer-inc   AAPL       2019   81.168290\n",
       "1    77      apple-computer-inc   AAPL       2020   39.468211\n",
       "2    78      apple-computer-inc   AAPL       2021  -28.376331\n",
       "3    79      apple-computer-inc   AAPL       2022   54.798228\n",
       "4    80      apple-computer-inc   AAPL       2023   38.354959\n",
       "5    81          microsoft-corp   MSFT       2019   41.031366\n",
       "6    82          microsoft-corp   MSFT       2020   58.397892\n",
       "7    83          microsoft-corp   MSFT       2021  -27.328362\n",
       "8    84          microsoft-corp   MSFT       2022   58.349750\n",
       "9    85          microsoft-corp   MSFT       2023   16.954590\n",
       "10   86              google-inc  GOOGL       2019   28.427392\n",
       "11   87              google-inc  GOOGL       2020   69.923471\n",
       "12   88              google-inc  GOOGL       2021  -38.996426\n",
       "13   89              google-inc  GOOGL       2022   56.743712\n",
       "14   90              google-inc  GOOGL       2023   40.015033\n",
       "15   91            tesla-motors   TSLA       2019  673.939037\n",
       "16   92            tesla-motors   TSLA       2020   48.840041\n",
       "17   93            tesla-motors   TSLA       2021  -69.539416\n",
       "18   94            tesla-motors   TSLA       2022  129.861239\n",
       "19   95            tesla-motors   TSLA       2023   73.762180\n",
       "20   96                visa-inc      V       2019   12.855539\n",
       "21   97                visa-inc      V       2020    0.803708\n",
       "22   98                visa-inc      V       2021   -5.327238\n",
       "23   99                visa-inc      V       2022   26.533370\n",
       "24  100                visa-inc      V       2023   24.037441\n",
       "25  101  berkshire-hathaway-inc  BRK-A       2019    0.747675\n",
       "26  102  berkshire-hathaway-inc  BRK-A       2020   31.606724\n",
       "27  103  berkshire-hathaway-inc  BRK-A       2021    3.175215\n",
       "28  104  berkshire-hathaway-inc  BRK-A       2022   15.568926\n",
       "29  105  berkshire-hathaway-inc  BRK-A       2023   24.577154\n",
       "30  106                     YPF    YPF       2019  -56.216699\n",
       "31  107                     YPF    YPF       2020  -11.725663\n",
       "32  108                     YPF    YPF       2021  124.009908\n",
       "33  109                     YPF    YPF       2022   97.359362\n",
       "34  110                     YPF    YPF       2023  158.111369\n",
       "35  111                  pfizer    PFE       2019    3.847527\n",
       "36  112                  pfizer    PFE       2020   62.545375\n",
       "37  113                  pfizer    PFE       2021   -6.448356\n",
       "38  114                  pfizer    PFE       2022  -41.287025\n",
       "39  115                  pfizer    PFE       2023   -4.987517\n",
       "40  116          amazon-com-inc   AMZN       2019   75.025433\n",
       "41  117          amazon-com-inc   AMZN       2020    6.194323\n",
       "42  118          amazon-com-inc   AMZN       2021  -50.599895\n",
       "43  119          amazon-com-inc   AMZN       2022   77.044981\n",
       "44  120          amazon-com-inc   AMZN       2023   49.236318\n",
       "45  121                  disney    DIS       2019   19.635634\n",
       "46  122                  disney    DIS       2020  -12.837683\n",
       "47  123                  disney    DIS       2021  -44.386325\n",
       "48  124                  disney    DIS       2022    1.814384\n",
       "49  125                  disney    DIS       2023   24.089076\n",
       "50  126                    nike    NKE       2019   39.842576\n",
       "51  127                    nike    NKE       2020   21.376981\n",
       "52  128                    nike    NKE       2021  -27.970598\n",
       "53  129                    nike    NKE       2022   -7.390852\n",
       "54  130                    nike    NKE       2023  -27.047498\n",
       "55  131          procter-gamble     PG       2019   14.932936\n",
       "56  132          procter-gamble     PG       2020   22.130106\n",
       "57  133          procter-gamble     PG       2021   -4.003617\n",
       "58  134          procter-gamble     PG       2022   -0.864226\n",
       "59  135          procter-gamble     PG       2023   16.814913\n",
       "60  136            coca-cola-co     KO       2019    1.804627\n",
       "61  137            coca-cola-co     KO       2020   15.254871\n",
       "62  138            coca-cola-co     KO       2021   11.032015\n",
       "63  139            coca-cola-co     KO       2022   -3.432583\n",
       "64  140            coca-cola-co     KO       2023    7.584963\n",
       "65  141                 chevron    CVX       2019  -26.373903\n",
       "66  142                 chevron    CVX       2020   46.537884\n",
       "67  143                 chevron    CVX       2021   54.908118\n",
       "68  144                 chevron    CVX       2022  -10.902560\n",
       "69  145                 chevron    CVX       2023    0.484137\n",
       "70  146                   3m-co    MMM       2019    0.179640\n",
       "71  147                   3m-co    MMM       2020    7.100160\n",
       "72  148                   3m-co    MMM       2021  -29.288691\n",
       "73  149                   3m-co    MMM       2022   -5.340940\n",
       "74  150                   3m-co    MMM       2023   46.447312"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datos variaciones de los precios de las acciones\n",
    "\n",
    "# Consultar datos\n",
    "conn = sqlite3.connect('webmining.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT * FROM datos_variacion\")\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "filas = cursor.fetchall()\n",
    "\n",
    "# Guardar los datos en un dataframe\n",
    "df_var = pd.DataFrame(filas, columns=column_names)\n",
    "df_var[\"ejercicio\"] = df_var[\"ejercicio\"] - 1\n",
    "df_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "razon_corriente",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prueba_acida",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "endeudamiento",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "endeudamiento_a_largo_plazo",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "covertura_de_intereses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ROA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ROE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rotacion_activos",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rotacion_inventario",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "variacion",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cb32ebea-14bb-44ca-99db-8fc2b6c52aa5",
       "rows": [
        [
         "0",
         "3m-co",
         "1.884121791645697",
         "1.3507800704579769",
         "0.726978896001014",
         "0.5590764095739063",
         "13.527410207939509",
         "0.11511080127595749",
         "0.42152084783785876",
         "0.6798909943595919",
         "7.592356687898089",
         "7.100159984043786"
        ],
        [
         "1",
         "3m-co",
         "1.704814609850581",
         "1.153071389042612",
         "0.6788536709721278",
         "0.48691366417403126",
         "15.889344262295081",
         "0.12578602991162474",
         "0.39188563108081276",
         "0.7510834466349422",
         "7.092276830491475",
         "-29.28869132510934"
        ],
        [
         "2",
         "3m-co",
         "1.5423711015436312",
         "0.9782631523679512",
         "0.6820579054999462",
         "0.47706382520718976",
         "7.246753246753247",
         "0.12435690453126681",
         "0.39150176199512066",
         "0.5631471316327629",
         "4.8698808637379",
         "-5.340939645945153"
        ],
        [
         "3",
         "3m-co",
         "1.0707328234294307",
         "0.8129044910766817",
         "0.9037564254646105",
         "0.6013246342427837",
         "4.549415515409139",
         "-0.13829576907868724",
         "-1.4416735366859028",
         "0.48655595096876236",
         "6.2398580121703855",
         "46.44731192663558"
        ],
        [
         "4",
         "3m-co",
         "1.4111584932480454",
         "1.0826226012793176",
         "0.9023276813484499",
         "0.6199959867562957",
         "3.602015113350126",
         "0.10467041236079061",
         "1.0757927300850734",
         "0.6164091501956457",
         "6.645484045429962",
         null
        ],
        [
         "5",
         "YPF",
         "0.8570638494182141",
         "0.5869117730373999",
         "0.6479914996945138",
         "0.4542630359533027",
         "-1.0303854392974887",
         "-0.036401732465114724",
         "-0.10171256332482917",
         "0.3619392863694591",
         "6.915665538212648",
         "-11.725663133324405"
        ],
        [
         "6",
         "YPF",
         "1.1665473383826244",
         "0.7729506645733076",
         "0.6478683515711527",
         "0.48355234962832494",
         "1.3209127591484624",
         "0.00010798155994279078",
         "0.00030264383530993907",
         "0.552778613432738",
         "8.5471229868704",
         "124.0099078264322"
        ],
        [
         "7",
         "YPF",
         "1.0599535957397819",
         "0.6965527420430863",
         "0.5944869326117509",
         "0.40937634559017994",
         "3.187363423589311",
         "0.06318006264302872",
         "0.1548162736054956",
         "0.5522173140435354",
         "8.209048432900321",
         "97.3593623280252"
        ],
        [
         "8",
         "YPF",
         "0.8781638323437764",
         "0.5361517863665333",
         "0.64137121473593",
         "0.44397252999785836",
         "0.6938987603760707",
         "-0.0776318602220062",
         "-0.21459015746748986",
         "0.27272016202068183",
         "4.039536987116599",
         "158.11136929847672"
        ],
        [
         "9",
         "YPF",
         "0.738156424474767",
         "0.5598842173546668",
         "0.6041420180710545",
         "0.3050208768913383",
         "2.6225653522593104",
         "0.0695137492025926",
         "0.17047227259848027",
         "0.5987780866003266",
         "11.22884657136439",
         null
        ],
        [
         "10",
         "amazon-com-inc",
         "1.0502274795268425",
         "0.8619535546148672",
         "0.709198461993493",
         "0.3157147527203101",
         "13.903460837887067",
         "0.06641137004000686",
         "0.22837351719412444",
         "1.2019614253023865",
         "16.224584996848076",
         "6.194322534998009"
        ],
        [
         "11",
         "amazon-com-inc",
         "1.1357597739445826",
         "0.9063303951752352",
         "0.6712749287241201",
         "0.33298854592449395",
         "13.75290215588723",
         "0.07933439385184604",
         "0.2413396506202756",
         "1.1171635172120253",
         "14.39405637254902",
         "-50.59989457027987"
        ],
        [
         "12",
         "amazon-com-inc",
         "0.9446435811136924",
         "0.7232372114574016",
         "0.6843507861890096",
         "0.3484930026476468",
         "5.639205745669624",
         "-0.0058831793375479545",
         "-0.018638346240490815",
         "1.1108942562273734",
         "14.939194884464467",
         "77.04498133500893"
        ],
        [
         "13",
         "amazon-com-inc",
         "1.0450772206625152",
         "0.8430483212767634",
         "0.6175552330758126",
         "0.3051260386394723",
         "11.581395348837209",
         "0.057639044129626754",
         "0.15071207430340558",
         "1.0889090543976174",
         "17.25148568341437",
         "49.236317568461516"
        ],
        [
         "14",
         "amazon-com-inc",
         "1.063734806137178",
         "0.8730542659852534",
         "0.5423703860174686",
         "0.2552320873620166",
         "28.509143807148796",
         "0.09481288026449286",
         "0.2071825715984194",
         "1.020907545919788",
         "18.646139007423862",
         null
        ],
        [
         "15",
         "apple-computer-inc",
         "1.3636044481554577",
         "1.325072111735236",
         "0.7982666847799239",
         "0.47287025144494393",
         "23.07274625826662",
         "0.1772557180259843",
         "0.8786635853012749",
         "0.8475615027416885",
         "67.59788229500123",
         "39.4682109756487"
        ],
        [
         "16",
         "apple-computer-inc",
         "1.0745531195957954",
         "1.0221149018576519",
         "0.8202574344305731",
         "0.4627637449359263",
         "41.19054820415879",
         "0.26974205275183616",
         "1.5007132667617689",
         "1.042207736708053",
         "55.595288753799394",
         "-28.376331018325995"
        ],
        [
         "17",
         "apple-computer-inc",
         "0.8793560286267226",
         "0.8472353911496149",
         "0.8563535598361469",
         "0.41984096610962285",
         "0.0",
         "0.2829244092925685",
         "1.9695887275023682",
         "1.1178523337727317",
         "79.72664779619895",
         "54.79822815057525"
        ],
        [
         "18",
         "apple-computer-inc",
         "0.9880116717592975",
         "0.9444421504665951",
         "0.8237407929480435",
         "0.41161655553444154",
         "0.0",
         "0.27509834563776475",
         "1.5607601454639075",
         "1.087077369016657",
         "60.540988785341966",
         "38.354958595509416"
        ],
        [
         "19",
         "apple-computer-inc",
         "0.8673125765340832",
         "0.8260068483831466",
         "0.8439640528248123",
         "0.36067181763384293",
         "0.0",
         "0.25682503150857583",
         "1.6459350307287095",
         "1.0713874732862074",
         "53.66936590721932",
         null
        ],
        [
         "20",
         "berkshire-hathaway-inc",
         "4.252531451365449",
         "3.83154341822645",
         "0.48343708403864355",
         "0.43121723097207487",
         "17.092823903992162",
         "0.04866611958627904",
         "0.09436445304524593",
         "0.281069988520468",
         "12.785245730945439",
         "31.606724401426376"
        ],
        [
         "21",
         "berkshire-hathaway-inc",
         "4.600278551532034",
         "4.137042932307557",
         "0.4629343001134771",
         "0.4157557906681797",
         "27.599952061361456",
         "0.09380319237701087",
         "0.17500262687821794",
         "0.2880575812696082",
         "13.180538322038752",
         "3.1752146158925854"
        ],
        [
         "22",
         "berkshire-hathaway-inc",
         "4.106035526846992",
         "3.5940048445700445",
         "0.49214678454133787",
         "0.43991502058589405",
         "-6.436351102941177",
         "-0.023995613965723563",
         "-0.04732387923147301",
         "0.31843030580991394",
         "11.906489001024994",
         "15.568926042276775"
        ],
        [
         "23",
         "berkshire-hathaway-inc",
         "4.311795879689749",
         "3.8580704032569404",
         "0.4665591255147302",
         "0.4133000865438355",
         "24.624425344793124",
         "0.08992988640887943",
         "0.16885790195947678",
         "0.34064438708085587",
         "14.096612004950495",
         "24.57715442525923"
        ],
        [
         "24",
         "berkshire-hathaway-inc",
         "5.385806059324274",
         "5.068458203352192",
         "0.43524938880179154",
         "0.36968630214034204",
         "21.872115384615384",
         "0.0771266707745426",
         "0.1366863823532574",
         "0.32189887865386463",
         "15.471217927357548",
         null
        ],
        [
         "25",
         "chevron",
         "1.175584907361493",
         "0.9197132939638462",
         "0.4464906793444264",
         "0.3539805663288711",
         "-6.100430416068867",
         "-0.02311605988573335",
         "-0.041757066232748746",
         "0.392030526710872",
         "16.56183932346723",
         "46.53788403104646"
        ],
        [
         "26",
         "chevron",
         "1.2593034974431712",
         "1.0056735470867082",
         "0.4157847496190536",
         "0.3039388815830672",
         "22.594101123595507",
         "0.06523055085895589",
         "0.11170608253024107",
         "0.6473667731229257",
         "22.82075055187638",
         "54.90811772090103"
        ],
        [
         "27",
         "chevron",
         "1.4716732927970066",
         "1.2305893358278766",
         "0.37820565055935185",
         "0.24546678618131304",
         "81.40503875968992",
         "0.13761645887415652",
         "0.2215191850042786",
         "0.9154356270056536",
         "28.606281071904935",
         "-10.902560098786918"
        ],
        [
         "28",
         "chevron",
         "1.2749705499411",
         "1.007998015996032",
         "0.38108106042074363",
         "0.2577857448630137",
         "57.492537313432834",
         "0.08167578889432485",
         "0.13199948111954635",
         "0.7445534185420744",
         "22.619484440315837",
         "0.48413726459539674"
        ],
        [
         "29",
         "chevron",
         "1.0610249494268376",
         "0.8256911665542819",
         "0.40391456304633805",
         "0.25384723162786355",
         "39.22390572390572",
         "0.06873642668659365",
         "0.11537933872959254",
         "0.7611486039433638",
         "21.552567776063476",
         null
        ],
        [
         "30",
         "coca-cola-co",
         "1.317717964522978",
         "1.0940346551606055",
         "0.7561858504398827",
         "0.5889273277126099",
         "6.953375086986778",
         "0.08874404325513197",
         "0.364341814419414",
         "0.37818456744868034",
         "10.108389467238212",
         "15.254871179810458"
        ],
        [
         "31",
         "coca-cola-co",
         "1.1300250626566417",
         "0.9588972431077695",
         "0.7365319597681049",
         "0.5250919419626296",
         "7.159048215403883",
         "0.10355791548758386",
         "0.3935634591372296",
         "0.4096849066802327",
         "11.32249560632689",
         "11.032014814259995"
        ],
        [
         "32",
         "coca-cola-co",
         "1.1453559115798013",
         "0.9307442709389576",
         "0.7215915828509212",
         "0.5089637032006296",
         "13.992063492063492",
         "0.10286428856332805",
         "0.3698879714695507",
         "0.46359000894753294",
         "10.159225135837467",
         "-3.432582622854663"
        ],
        [
         "33",
         "coca-cola-co",
         "1.1341054685842773",
         "0.9464172075855924",
         "0.7187394450528642",
         "0.47748789699395106",
         "8.674525212835626",
         "0.10965886410857395",
         "0.38972754719726455",
         "0.4682967769669304",
         "10.342224231464737",
         "7.584962889042091"
        ],
        [
         "34",
         "coca-cola-co",
         "1.0296249356410154",
         "0.8423699948512813",
         "0.73771991765209",
         "0.48660851922943044",
         "8.63586956521739",
         "0.1057295447990532",
         "0.4033922744175457",
         "0.46804045788620474",
         "9.953680203045685",
         null
        ],
        [
         "35",
         "disney",
         "1.3238320564818988",
         "1.182852636322668",
         "0.5161871306729381",
         "0.3840703749460429",
         "2.2956891317547057",
         "-0.01420994398384512",
         "-0.02948868433516608",
         "0.32442731048032986",
         "17.418220564730955",
         "-12.837683462669336"
        ],
        [
         "36",
         "disney",
         "1.0830195964861473",
         "0.9699456189464878",
         "0.4979396785014415",
         "0.3453089008835562",
         "2.258732212160414",
         "0.00979819163200055",
         "0.019614204813591316",
         "0.3311150292963474",
         "19.185543540125213",
         "-44.38632495005448"
        ],
        [
         "37",
         "disney",
         "1.000859904378633",
         "0.8759329962508169",
         "0.4677725886530047",
         "0.32499963168672746",
         "4.410587475790833",
         "0.015444603228388604",
         "0.029115517784073026",
         "0.40623480707750786",
         "22.775881057268723",
         "1.8143837235537585"
        ],
        [
         "38",
         "disney",
         "1.0521532483380969",
         "0.8927068948906516",
         "0.4502745903034843",
         "0.29880483901565824",
         "4.729853015712114",
         "0.011450585906148001",
         "0.021022361934700293",
         "0.4324274366545221",
         "17.90493454179255",
         "24.08907578387387"
        ],
        [
         "39",
         "disney",
         "0.7295297551952369",
         "0.6104800716783723",
         "0.46222333209322236",
         "0.285894841987779",
         "5.95072463768116",
         "0.025339034446205517",
         "0.04747853821105604",
         "0.46560730612224094",
         "22.180383588249576",
         null
        ],
        [
         "40",
         "google-inc",
         "3.0667558151810534",
         "3.053946581271774",
         "0.3037144573488186",
         "0.12589482378854625",
         "305.36296296296297",
         "0.12599181517821387",
         "0.18094848659141563",
         "0.57108217360833",
         "250.7239010989011",
         "69.9234714270234"
        ],
        [
         "41",
         "google-inc",
         "2.928113424845146",
         "2.9099044417468174",
         "0.2995897213222441",
         "0.1207427324448601",
         "227.4971098265896",
         "0.21163309841121392",
         "0.30215590041131",
         "0.7171164701559838",
         "220.2025641025641",
         "-38.996425908987575"
        ],
        [
         "42",
         "google-inc",
         "2.377994227994228",
         "2.377994227994228",
         "0.29874282710587413",
         "0.10901703973016777",
         "209.64145658263305",
         "0.16418809409084936",
         "0.2341339246673746",
         "0.7743330851110429",
         "0.0",
         "56.743711870640844"
        ],
        [
         "43",
         "google-inc",
         "2.096584936563424",
         "2.096584936563424",
         "0.29576383228294795",
         "0.0924446808087636",
         "273.67857142857144",
         "0.18339082287918249",
         "0.26041096905557576",
         "0.7639167776695361",
         "0.0",
         "40.01503325058091"
        ],
        [
         "44",
         "google-inc",
         "1.8369313974102914",
         "1.8369313974102914",
         "0.27800184783767456",
         "0.08006556270210724",
         "426.06716417910445",
         "0.22235794747876764",
         "0.30797578472025694",
         "0.7773755374720159",
         "0.0",
         null
        ],
        [
         "45",
         "microsoft-corp",
         "2.5157654542940118",
         "2.489558843866685",
         "0.6073691302342098",
         "0.3673845296056234",
         "20.439598610575068",
         "0.14696111326835065",
         "0.37429841763592103",
         "0.4746424790332912",
         "75.46965699208444",
         "58.39789192405092"
        ],
        [
         "46",
         "microsoft-corp",
         "2.0799936835218875",
         "2.0502611186933914",
         "0.5746047534446445",
         "0.30898888186494655",
         "30.0068669527897",
         "0.18356757015869782",
         "0.4315223821731414",
         "0.5035906992351227",
         "63.76631259484067",
         "-27.328361635927422"
        ],
        [
         "47",
         "microsoft-corp",
         "1.7846069708251824",
         "1.7452514671546664",
         "0.5435204473193729",
         "0.2829075759236926",
         "40.7342452369321",
         "0.19936958666812848",
         "0.4367546925099975",
         "0.5434437013485364",
         "52.98503474078033",
         "58.34974952470342"
        ],
        [
         "48",
         "microsoft-corp",
         "1.76916725076573",
         "1.745163179675273",
         "0.499429578422044",
         "0.24662601704953688",
         "44.44862155388471",
         "0.175643726819038",
         "0.35088714643856406",
         "0.5143867603938094",
         "84.766",
         "16.954590118710012"
        ],
        [
         "49",
         "microsoft-corp",
         "1.2749549031815206",
         "1.2650096579027186",
         "0.47579774407756903",
         "0.23117640282488192",
         "36.68555145826349",
         "0.17208583985957596",
         "0.32828137978299815",
         "0.47860153896318164",
         "196.72712680577848",
         null
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 70
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>razon_corriente</th>\n",
       "      <th>prueba_acida</th>\n",
       "      <th>endeudamiento</th>\n",
       "      <th>endeudamiento_a_largo_plazo</th>\n",
       "      <th>covertura_de_intereses</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>rotacion_activos</th>\n",
       "      <th>rotacion_inventario</th>\n",
       "      <th>variacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>1.884122</td>\n",
       "      <td>1.350780</td>\n",
       "      <td>0.726979</td>\n",
       "      <td>0.559076</td>\n",
       "      <td>13.527410</td>\n",
       "      <td>0.115111</td>\n",
       "      <td>0.421521</td>\n",
       "      <td>0.679891</td>\n",
       "      <td>7.592357</td>\n",
       "      <td>7.100160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>1.704815</td>\n",
       "      <td>1.153071</td>\n",
       "      <td>0.678854</td>\n",
       "      <td>0.486914</td>\n",
       "      <td>15.889344</td>\n",
       "      <td>0.125786</td>\n",
       "      <td>0.391886</td>\n",
       "      <td>0.751083</td>\n",
       "      <td>7.092277</td>\n",
       "      <td>-29.288691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>1.542371</td>\n",
       "      <td>0.978263</td>\n",
       "      <td>0.682058</td>\n",
       "      <td>0.477064</td>\n",
       "      <td>7.246753</td>\n",
       "      <td>0.124357</td>\n",
       "      <td>0.391502</td>\n",
       "      <td>0.563147</td>\n",
       "      <td>4.869881</td>\n",
       "      <td>-5.340940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>1.070733</td>\n",
       "      <td>0.812904</td>\n",
       "      <td>0.903756</td>\n",
       "      <td>0.601325</td>\n",
       "      <td>4.549416</td>\n",
       "      <td>-0.138296</td>\n",
       "      <td>-1.441674</td>\n",
       "      <td>0.486556</td>\n",
       "      <td>6.239858</td>\n",
       "      <td>46.447312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>1.411158</td>\n",
       "      <td>1.082623</td>\n",
       "      <td>0.902328</td>\n",
       "      <td>0.619996</td>\n",
       "      <td>3.602015</td>\n",
       "      <td>0.104670</td>\n",
       "      <td>1.075793</td>\n",
       "      <td>0.616409</td>\n",
       "      <td>6.645484</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YPF</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.586912</td>\n",
       "      <td>0.647991</td>\n",
       "      <td>0.454263</td>\n",
       "      <td>-1.030385</td>\n",
       "      <td>-0.036402</td>\n",
       "      <td>-0.101713</td>\n",
       "      <td>0.361939</td>\n",
       "      <td>6.915666</td>\n",
       "      <td>-11.725663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YPF</td>\n",
       "      <td>1.166547</td>\n",
       "      <td>0.772951</td>\n",
       "      <td>0.647868</td>\n",
       "      <td>0.483552</td>\n",
       "      <td>1.320913</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.552779</td>\n",
       "      <td>8.547123</td>\n",
       "      <td>124.009908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>YPF</td>\n",
       "      <td>1.059954</td>\n",
       "      <td>0.696553</td>\n",
       "      <td>0.594487</td>\n",
       "      <td>0.409376</td>\n",
       "      <td>3.187363</td>\n",
       "      <td>0.063180</td>\n",
       "      <td>0.154816</td>\n",
       "      <td>0.552217</td>\n",
       "      <td>8.209048</td>\n",
       "      <td>97.359362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>YPF</td>\n",
       "      <td>0.878164</td>\n",
       "      <td>0.536152</td>\n",
       "      <td>0.641371</td>\n",
       "      <td>0.443973</td>\n",
       "      <td>0.693899</td>\n",
       "      <td>-0.077632</td>\n",
       "      <td>-0.214590</td>\n",
       "      <td>0.272720</td>\n",
       "      <td>4.039537</td>\n",
       "      <td>158.111369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>YPF</td>\n",
       "      <td>0.738156</td>\n",
       "      <td>0.559884</td>\n",
       "      <td>0.604142</td>\n",
       "      <td>0.305021</td>\n",
       "      <td>2.622565</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.170472</td>\n",
       "      <td>0.598778</td>\n",
       "      <td>11.228847</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>1.050227</td>\n",
       "      <td>0.861954</td>\n",
       "      <td>0.709198</td>\n",
       "      <td>0.315715</td>\n",
       "      <td>13.903461</td>\n",
       "      <td>0.066411</td>\n",
       "      <td>0.228374</td>\n",
       "      <td>1.201961</td>\n",
       "      <td>16.224585</td>\n",
       "      <td>6.194323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>1.135760</td>\n",
       "      <td>0.906330</td>\n",
       "      <td>0.671275</td>\n",
       "      <td>0.332989</td>\n",
       "      <td>13.752902</td>\n",
       "      <td>0.079334</td>\n",
       "      <td>0.241340</td>\n",
       "      <td>1.117164</td>\n",
       "      <td>14.394056</td>\n",
       "      <td>-50.599895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>0.944644</td>\n",
       "      <td>0.723237</td>\n",
       "      <td>0.684351</td>\n",
       "      <td>0.348493</td>\n",
       "      <td>5.639206</td>\n",
       "      <td>-0.005883</td>\n",
       "      <td>-0.018638</td>\n",
       "      <td>1.110894</td>\n",
       "      <td>14.939195</td>\n",
       "      <td>77.044981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>1.045077</td>\n",
       "      <td>0.843048</td>\n",
       "      <td>0.617555</td>\n",
       "      <td>0.305126</td>\n",
       "      <td>11.581395</td>\n",
       "      <td>0.057639</td>\n",
       "      <td>0.150712</td>\n",
       "      <td>1.088909</td>\n",
       "      <td>17.251486</td>\n",
       "      <td>49.236318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>1.063735</td>\n",
       "      <td>0.873054</td>\n",
       "      <td>0.542370</td>\n",
       "      <td>0.255232</td>\n",
       "      <td>28.509144</td>\n",
       "      <td>0.094813</td>\n",
       "      <td>0.207183</td>\n",
       "      <td>1.020908</td>\n",
       "      <td>18.646139</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>1.363604</td>\n",
       "      <td>1.325072</td>\n",
       "      <td>0.798267</td>\n",
       "      <td>0.472870</td>\n",
       "      <td>23.072746</td>\n",
       "      <td>0.177256</td>\n",
       "      <td>0.878664</td>\n",
       "      <td>0.847562</td>\n",
       "      <td>67.597882</td>\n",
       "      <td>39.468211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>1.074553</td>\n",
       "      <td>1.022115</td>\n",
       "      <td>0.820257</td>\n",
       "      <td>0.462764</td>\n",
       "      <td>41.190548</td>\n",
       "      <td>0.269742</td>\n",
       "      <td>1.500713</td>\n",
       "      <td>1.042208</td>\n",
       "      <td>55.595289</td>\n",
       "      <td>-28.376331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>0.879356</td>\n",
       "      <td>0.847235</td>\n",
       "      <td>0.856354</td>\n",
       "      <td>0.419841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282924</td>\n",
       "      <td>1.969589</td>\n",
       "      <td>1.117852</td>\n",
       "      <td>79.726648</td>\n",
       "      <td>54.798228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>0.988012</td>\n",
       "      <td>0.944442</td>\n",
       "      <td>0.823741</td>\n",
       "      <td>0.411617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275098</td>\n",
       "      <td>1.560760</td>\n",
       "      <td>1.087077</td>\n",
       "      <td>60.540989</td>\n",
       "      <td>38.354959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>0.867313</td>\n",
       "      <td>0.826007</td>\n",
       "      <td>0.843964</td>\n",
       "      <td>0.360672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256825</td>\n",
       "      <td>1.645935</td>\n",
       "      <td>1.071387</td>\n",
       "      <td>53.669366</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>4.252531</td>\n",
       "      <td>3.831543</td>\n",
       "      <td>0.483437</td>\n",
       "      <td>0.431217</td>\n",
       "      <td>17.092824</td>\n",
       "      <td>0.048666</td>\n",
       "      <td>0.094364</td>\n",
       "      <td>0.281070</td>\n",
       "      <td>12.785246</td>\n",
       "      <td>31.606724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>4.600279</td>\n",
       "      <td>4.137043</td>\n",
       "      <td>0.462934</td>\n",
       "      <td>0.415756</td>\n",
       "      <td>27.599952</td>\n",
       "      <td>0.093803</td>\n",
       "      <td>0.175003</td>\n",
       "      <td>0.288058</td>\n",
       "      <td>13.180538</td>\n",
       "      <td>3.175215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>4.106036</td>\n",
       "      <td>3.594005</td>\n",
       "      <td>0.492147</td>\n",
       "      <td>0.439915</td>\n",
       "      <td>-6.436351</td>\n",
       "      <td>-0.023996</td>\n",
       "      <td>-0.047324</td>\n",
       "      <td>0.318430</td>\n",
       "      <td>11.906489</td>\n",
       "      <td>15.568926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>4.311796</td>\n",
       "      <td>3.858070</td>\n",
       "      <td>0.466559</td>\n",
       "      <td>0.413300</td>\n",
       "      <td>24.624425</td>\n",
       "      <td>0.089930</td>\n",
       "      <td>0.168858</td>\n",
       "      <td>0.340644</td>\n",
       "      <td>14.096612</td>\n",
       "      <td>24.577154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>5.385806</td>\n",
       "      <td>5.068458</td>\n",
       "      <td>0.435249</td>\n",
       "      <td>0.369686</td>\n",
       "      <td>21.872115</td>\n",
       "      <td>0.077127</td>\n",
       "      <td>0.136686</td>\n",
       "      <td>0.321899</td>\n",
       "      <td>15.471218</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chevron</td>\n",
       "      <td>1.175585</td>\n",
       "      <td>0.919713</td>\n",
       "      <td>0.446491</td>\n",
       "      <td>0.353981</td>\n",
       "      <td>-6.100430</td>\n",
       "      <td>-0.023116</td>\n",
       "      <td>-0.041757</td>\n",
       "      <td>0.392031</td>\n",
       "      <td>16.561839</td>\n",
       "      <td>46.537884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>chevron</td>\n",
       "      <td>1.259303</td>\n",
       "      <td>1.005674</td>\n",
       "      <td>0.415785</td>\n",
       "      <td>0.303939</td>\n",
       "      <td>22.594101</td>\n",
       "      <td>0.065231</td>\n",
       "      <td>0.111706</td>\n",
       "      <td>0.647367</td>\n",
       "      <td>22.820751</td>\n",
       "      <td>54.908118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chevron</td>\n",
       "      <td>1.471673</td>\n",
       "      <td>1.230589</td>\n",
       "      <td>0.378206</td>\n",
       "      <td>0.245467</td>\n",
       "      <td>81.405039</td>\n",
       "      <td>0.137616</td>\n",
       "      <td>0.221519</td>\n",
       "      <td>0.915436</td>\n",
       "      <td>28.606281</td>\n",
       "      <td>-10.902560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>chevron</td>\n",
       "      <td>1.274971</td>\n",
       "      <td>1.007998</td>\n",
       "      <td>0.381081</td>\n",
       "      <td>0.257786</td>\n",
       "      <td>57.492537</td>\n",
       "      <td>0.081676</td>\n",
       "      <td>0.131999</td>\n",
       "      <td>0.744553</td>\n",
       "      <td>22.619484</td>\n",
       "      <td>0.484137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>chevron</td>\n",
       "      <td>1.061025</td>\n",
       "      <td>0.825691</td>\n",
       "      <td>0.403915</td>\n",
       "      <td>0.253847</td>\n",
       "      <td>39.223906</td>\n",
       "      <td>0.068736</td>\n",
       "      <td>0.115379</td>\n",
       "      <td>0.761149</td>\n",
       "      <td>21.552568</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>1.317718</td>\n",
       "      <td>1.094035</td>\n",
       "      <td>0.756186</td>\n",
       "      <td>0.588927</td>\n",
       "      <td>6.953375</td>\n",
       "      <td>0.088744</td>\n",
       "      <td>0.364342</td>\n",
       "      <td>0.378185</td>\n",
       "      <td>10.108389</td>\n",
       "      <td>15.254871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>1.130025</td>\n",
       "      <td>0.958897</td>\n",
       "      <td>0.736532</td>\n",
       "      <td>0.525092</td>\n",
       "      <td>7.159048</td>\n",
       "      <td>0.103558</td>\n",
       "      <td>0.393563</td>\n",
       "      <td>0.409685</td>\n",
       "      <td>11.322496</td>\n",
       "      <td>11.032015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>1.145356</td>\n",
       "      <td>0.930744</td>\n",
       "      <td>0.721592</td>\n",
       "      <td>0.508964</td>\n",
       "      <td>13.992063</td>\n",
       "      <td>0.102864</td>\n",
       "      <td>0.369888</td>\n",
       "      <td>0.463590</td>\n",
       "      <td>10.159225</td>\n",
       "      <td>-3.432583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>1.134105</td>\n",
       "      <td>0.946417</td>\n",
       "      <td>0.718739</td>\n",
       "      <td>0.477488</td>\n",
       "      <td>8.674525</td>\n",
       "      <td>0.109659</td>\n",
       "      <td>0.389728</td>\n",
       "      <td>0.468297</td>\n",
       "      <td>10.342224</td>\n",
       "      <td>7.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>1.029625</td>\n",
       "      <td>0.842370</td>\n",
       "      <td>0.737720</td>\n",
       "      <td>0.486609</td>\n",
       "      <td>8.635870</td>\n",
       "      <td>0.105730</td>\n",
       "      <td>0.403392</td>\n",
       "      <td>0.468040</td>\n",
       "      <td>9.953680</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>disney</td>\n",
       "      <td>1.323832</td>\n",
       "      <td>1.182853</td>\n",
       "      <td>0.516187</td>\n",
       "      <td>0.384070</td>\n",
       "      <td>2.295689</td>\n",
       "      <td>-0.014210</td>\n",
       "      <td>-0.029489</td>\n",
       "      <td>0.324427</td>\n",
       "      <td>17.418221</td>\n",
       "      <td>-12.837683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>disney</td>\n",
       "      <td>1.083020</td>\n",
       "      <td>0.969946</td>\n",
       "      <td>0.497940</td>\n",
       "      <td>0.345309</td>\n",
       "      <td>2.258732</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>0.019614</td>\n",
       "      <td>0.331115</td>\n",
       "      <td>19.185544</td>\n",
       "      <td>-44.386325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>disney</td>\n",
       "      <td>1.000860</td>\n",
       "      <td>0.875933</td>\n",
       "      <td>0.467773</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>4.410587</td>\n",
       "      <td>0.015445</td>\n",
       "      <td>0.029116</td>\n",
       "      <td>0.406235</td>\n",
       "      <td>22.775881</td>\n",
       "      <td>1.814384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>disney</td>\n",
       "      <td>1.052153</td>\n",
       "      <td>0.892707</td>\n",
       "      <td>0.450275</td>\n",
       "      <td>0.298805</td>\n",
       "      <td>4.729853</td>\n",
       "      <td>0.011451</td>\n",
       "      <td>0.021022</td>\n",
       "      <td>0.432427</td>\n",
       "      <td>17.904935</td>\n",
       "      <td>24.089076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>disney</td>\n",
       "      <td>0.729530</td>\n",
       "      <td>0.610480</td>\n",
       "      <td>0.462223</td>\n",
       "      <td>0.285895</td>\n",
       "      <td>5.950725</td>\n",
       "      <td>0.025339</td>\n",
       "      <td>0.047479</td>\n",
       "      <td>0.465607</td>\n",
       "      <td>22.180384</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>3.066756</td>\n",
       "      <td>3.053947</td>\n",
       "      <td>0.303714</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>305.362963</td>\n",
       "      <td>0.125992</td>\n",
       "      <td>0.180948</td>\n",
       "      <td>0.571082</td>\n",
       "      <td>250.723901</td>\n",
       "      <td>69.923471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>2.928113</td>\n",
       "      <td>2.909904</td>\n",
       "      <td>0.299590</td>\n",
       "      <td>0.120743</td>\n",
       "      <td>227.497110</td>\n",
       "      <td>0.211633</td>\n",
       "      <td>0.302156</td>\n",
       "      <td>0.717116</td>\n",
       "      <td>220.202564</td>\n",
       "      <td>-38.996426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>2.377994</td>\n",
       "      <td>2.377994</td>\n",
       "      <td>0.298743</td>\n",
       "      <td>0.109017</td>\n",
       "      <td>209.641457</td>\n",
       "      <td>0.164188</td>\n",
       "      <td>0.234134</td>\n",
       "      <td>0.774333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.743712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>2.096585</td>\n",
       "      <td>2.096585</td>\n",
       "      <td>0.295764</td>\n",
       "      <td>0.092445</td>\n",
       "      <td>273.678571</td>\n",
       "      <td>0.183391</td>\n",
       "      <td>0.260411</td>\n",
       "      <td>0.763917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.015033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>1.836931</td>\n",
       "      <td>1.836931</td>\n",
       "      <td>0.278002</td>\n",
       "      <td>0.080066</td>\n",
       "      <td>426.067164</td>\n",
       "      <td>0.222358</td>\n",
       "      <td>0.307976</td>\n",
       "      <td>0.777376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>2.515765</td>\n",
       "      <td>2.489559</td>\n",
       "      <td>0.607369</td>\n",
       "      <td>0.367385</td>\n",
       "      <td>20.439599</td>\n",
       "      <td>0.146961</td>\n",
       "      <td>0.374298</td>\n",
       "      <td>0.474642</td>\n",
       "      <td>75.469657</td>\n",
       "      <td>58.397892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>2.079994</td>\n",
       "      <td>2.050261</td>\n",
       "      <td>0.574605</td>\n",
       "      <td>0.308989</td>\n",
       "      <td>30.006867</td>\n",
       "      <td>0.183568</td>\n",
       "      <td>0.431522</td>\n",
       "      <td>0.503591</td>\n",
       "      <td>63.766313</td>\n",
       "      <td>-27.328362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>1.784607</td>\n",
       "      <td>1.745251</td>\n",
       "      <td>0.543520</td>\n",
       "      <td>0.282908</td>\n",
       "      <td>40.734245</td>\n",
       "      <td>0.199370</td>\n",
       "      <td>0.436755</td>\n",
       "      <td>0.543444</td>\n",
       "      <td>52.985035</td>\n",
       "      <td>58.349750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>1.769167</td>\n",
       "      <td>1.745163</td>\n",
       "      <td>0.499430</td>\n",
       "      <td>0.246626</td>\n",
       "      <td>44.448622</td>\n",
       "      <td>0.175644</td>\n",
       "      <td>0.350887</td>\n",
       "      <td>0.514387</td>\n",
       "      <td>84.766000</td>\n",
       "      <td>16.954590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>1.274955</td>\n",
       "      <td>1.265010</td>\n",
       "      <td>0.475798</td>\n",
       "      <td>0.231176</td>\n",
       "      <td>36.685551</td>\n",
       "      <td>0.172086</td>\n",
       "      <td>0.328281</td>\n",
       "      <td>0.478602</td>\n",
       "      <td>196.727127</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>nike</td>\n",
       "      <td>2.481410</td>\n",
       "      <td>1.592105</td>\n",
       "      <td>0.742997</td>\n",
       "      <td>0.478687</td>\n",
       "      <td>20.629139</td>\n",
       "      <td>0.081010</td>\n",
       "      <td>0.315208</td>\n",
       "      <td>1.193383</td>\n",
       "      <td>5.077101</td>\n",
       "      <td>21.376981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>nike</td>\n",
       "      <td>2.717697</td>\n",
       "      <td>2.009200</td>\n",
       "      <td>0.661712</td>\n",
       "      <td>0.405379</td>\n",
       "      <td>24.429054</td>\n",
       "      <td>0.151749</td>\n",
       "      <td>0.448578</td>\n",
       "      <td>1.180127</td>\n",
       "      <td>6.498103</td>\n",
       "      <td>-27.970598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>nike</td>\n",
       "      <td>2.629357</td>\n",
       "      <td>1.844641</td>\n",
       "      <td>0.621016</td>\n",
       "      <td>0.354902</td>\n",
       "      <td>22.324415</td>\n",
       "      <td>0.149947</td>\n",
       "      <td>0.395655</td>\n",
       "      <td>1.158453</td>\n",
       "      <td>5.547506</td>\n",
       "      <td>-7.390852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>nike</td>\n",
       "      <td>2.722774</td>\n",
       "      <td>1.809421</td>\n",
       "      <td>0.626868</td>\n",
       "      <td>0.380246</td>\n",
       "      <td>20.326460</td>\n",
       "      <td>0.135088</td>\n",
       "      <td>0.362039</td>\n",
       "      <td>1.364659</td>\n",
       "      <td>6.058316</td>\n",
       "      <td>-27.047498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>nike</td>\n",
       "      <td>2.396111</td>\n",
       "      <td>1.686302</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.343401</td>\n",
       "      <td>25.107807</td>\n",
       "      <td>0.149567</td>\n",
       "      <td>0.395010</td>\n",
       "      <td>1.347730</td>\n",
       "      <td>6.830962</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>1.352199</td>\n",
       "      <td>1.042785</td>\n",
       "      <td>0.588518</td>\n",
       "      <td>0.420437</td>\n",
       "      <td>6.757074</td>\n",
       "      <td>0.059393</td>\n",
       "      <td>0.144379</td>\n",
       "      <td>0.270091</td>\n",
       "      <td>5.193392</td>\n",
       "      <td>62.545375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>1.398819</td>\n",
       "      <td>1.186520</td>\n",
       "      <td>0.573163</td>\n",
       "      <td>0.338025</td>\n",
       "      <td>20.898528</td>\n",
       "      <td>0.121115</td>\n",
       "      <td>0.283900</td>\n",
       "      <td>0.447937</td>\n",
       "      <td>8.973176</td>\n",
       "      <td>-6.448356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>1.216455</td>\n",
       "      <td>1.003322</td>\n",
       "      <td>0.513618</td>\n",
       "      <td>0.299942</td>\n",
       "      <td>32.181745</td>\n",
       "      <td>0.159083</td>\n",
       "      <td>0.327194</td>\n",
       "      <td>0.513045</td>\n",
       "      <td>11.265449</td>\n",
       "      <td>-41.287025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>0.906662</td>\n",
       "      <td>0.693476</td>\n",
       "      <td>0.605794</td>\n",
       "      <td>0.394784</td>\n",
       "      <td>2.859665</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.023743</td>\n",
       "      <td>0.262930</td>\n",
       "      <td>5.844931</td>\n",
       "      <td>-4.987517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>1.171252</td>\n",
       "      <td>0.918874</td>\n",
       "      <td>0.585292</td>\n",
       "      <td>0.383812</td>\n",
       "      <td>5.282433</td>\n",
       "      <td>0.037634</td>\n",
       "      <td>0.090781</td>\n",
       "      <td>0.298164</td>\n",
       "      <td>5.863699</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>0.848708</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>0.611616</td>\n",
       "      <td>0.338409</td>\n",
       "      <td>34.630108</td>\n",
       "      <td>0.107929</td>\n",
       "      <td>0.278343</td>\n",
       "      <td>0.587821</td>\n",
       "      <td>12.904693</td>\n",
       "      <td>22.130106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>0.696940</td>\n",
       "      <td>0.516359</td>\n",
       "      <td>0.608958</td>\n",
       "      <td>0.331255</td>\n",
       "      <td>36.818725</td>\n",
       "      <td>0.119909</td>\n",
       "      <td>0.306943</td>\n",
       "      <td>0.638001</td>\n",
       "      <td>12.722380</td>\n",
       "      <td>-4.003617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.445240</td>\n",
       "      <td>0.600249</td>\n",
       "      <td>0.318007</td>\n",
       "      <td>42.015945</td>\n",
       "      <td>0.125776</td>\n",
       "      <td>0.314980</td>\n",
       "      <td>0.684143</td>\n",
       "      <td>11.581023</td>\n",
       "      <td>-0.864226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>0.633404</td>\n",
       "      <td>0.435591</td>\n",
       "      <td>0.610483</td>\n",
       "      <td>0.314560</td>\n",
       "      <td>25.207672</td>\n",
       "      <td>0.121271</td>\n",
       "      <td>0.311899</td>\n",
       "      <td>0.678695</td>\n",
       "      <td>11.594232</td>\n",
       "      <td>16.814913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>0.734796</td>\n",
       "      <td>0.526155</td>\n",
       "      <td>0.586843</td>\n",
       "      <td>0.312045</td>\n",
       "      <td>22.646486</td>\n",
       "      <td>0.121590</td>\n",
       "      <td>0.294850</td>\n",
       "      <td>0.686761</td>\n",
       "      <td>11.978193</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>1.905238</td>\n",
       "      <td>1.905238</td>\n",
       "      <td>0.552515</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>27.374031</td>\n",
       "      <td>0.134282</td>\n",
       "      <td>0.300083</td>\n",
       "      <td>0.269974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>1.754050</td>\n",
       "      <td>1.754050</td>\n",
       "      <td>0.546552</td>\n",
       "      <td>0.356688</td>\n",
       "      <td>30.812865</td>\n",
       "      <td>0.148511</td>\n",
       "      <td>0.327516</td>\n",
       "      <td>0.290786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.327238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>1.448473</td>\n",
       "      <td>1.448473</td>\n",
       "      <td>0.583853</td>\n",
       "      <td>0.339961</td>\n",
       "      <td>36.581784</td>\n",
       "      <td>0.174934</td>\n",
       "      <td>0.420365</td>\n",
       "      <td>0.342803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.533370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>1.451727</td>\n",
       "      <td>1.451727</td>\n",
       "      <td>0.572006</td>\n",
       "      <td>0.316777</td>\n",
       "      <td>34.048137</td>\n",
       "      <td>0.190864</td>\n",
       "      <td>0.445950</td>\n",
       "      <td>0.360811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.037441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>1.283441</td>\n",
       "      <td>1.283441</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>0.305330</td>\n",
       "      <td>37.346334</td>\n",
       "      <td>0.208896</td>\n",
       "      <td>0.504459</td>\n",
       "      <td>0.380125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company  razon_corriente  prueba_acida  endeudamiento  \\\n",
       "0                    3m-co         1.884122      1.350780       0.726979   \n",
       "1                    3m-co         1.704815      1.153071       0.678854   \n",
       "2                    3m-co         1.542371      0.978263       0.682058   \n",
       "3                    3m-co         1.070733      0.812904       0.903756   \n",
       "4                    3m-co         1.411158      1.082623       0.902328   \n",
       "5                      YPF         0.857064      0.586912       0.647991   \n",
       "6                      YPF         1.166547      0.772951       0.647868   \n",
       "7                      YPF         1.059954      0.696553       0.594487   \n",
       "8                      YPF         0.878164      0.536152       0.641371   \n",
       "9                      YPF         0.738156      0.559884       0.604142   \n",
       "10          amazon-com-inc         1.050227      0.861954       0.709198   \n",
       "11          amazon-com-inc         1.135760      0.906330       0.671275   \n",
       "12          amazon-com-inc         0.944644      0.723237       0.684351   \n",
       "13          amazon-com-inc         1.045077      0.843048       0.617555   \n",
       "14          amazon-com-inc         1.063735      0.873054       0.542370   \n",
       "15      apple-computer-inc         1.363604      1.325072       0.798267   \n",
       "16      apple-computer-inc         1.074553      1.022115       0.820257   \n",
       "17      apple-computer-inc         0.879356      0.847235       0.856354   \n",
       "18      apple-computer-inc         0.988012      0.944442       0.823741   \n",
       "19      apple-computer-inc         0.867313      0.826007       0.843964   \n",
       "20  berkshire-hathaway-inc         4.252531      3.831543       0.483437   \n",
       "21  berkshire-hathaway-inc         4.600279      4.137043       0.462934   \n",
       "22  berkshire-hathaway-inc         4.106036      3.594005       0.492147   \n",
       "23  berkshire-hathaway-inc         4.311796      3.858070       0.466559   \n",
       "24  berkshire-hathaway-inc         5.385806      5.068458       0.435249   \n",
       "25                 chevron         1.175585      0.919713       0.446491   \n",
       "26                 chevron         1.259303      1.005674       0.415785   \n",
       "27                 chevron         1.471673      1.230589       0.378206   \n",
       "28                 chevron         1.274971      1.007998       0.381081   \n",
       "29                 chevron         1.061025      0.825691       0.403915   \n",
       "30            coca-cola-co         1.317718      1.094035       0.756186   \n",
       "31            coca-cola-co         1.130025      0.958897       0.736532   \n",
       "32            coca-cola-co         1.145356      0.930744       0.721592   \n",
       "33            coca-cola-co         1.134105      0.946417       0.718739   \n",
       "34            coca-cola-co         1.029625      0.842370       0.737720   \n",
       "35                  disney         1.323832      1.182853       0.516187   \n",
       "36                  disney         1.083020      0.969946       0.497940   \n",
       "37                  disney         1.000860      0.875933       0.467773   \n",
       "38                  disney         1.052153      0.892707       0.450275   \n",
       "39                  disney         0.729530      0.610480       0.462223   \n",
       "40              google-inc         3.066756      3.053947       0.303714   \n",
       "41              google-inc         2.928113      2.909904       0.299590   \n",
       "42              google-inc         2.377994      2.377994       0.298743   \n",
       "43              google-inc         2.096585      2.096585       0.295764   \n",
       "44              google-inc         1.836931      1.836931       0.278002   \n",
       "45          microsoft-corp         2.515765      2.489559       0.607369   \n",
       "46          microsoft-corp         2.079994      2.050261       0.574605   \n",
       "47          microsoft-corp         1.784607      1.745251       0.543520   \n",
       "48          microsoft-corp         1.769167      1.745163       0.499430   \n",
       "49          microsoft-corp         1.274955      1.265010       0.475798   \n",
       "50                    nike         2.481410      1.592105       0.742997   \n",
       "51                    nike         2.717697      2.009200       0.661712   \n",
       "52                    nike         2.629357      1.844641       0.621016   \n",
       "53                    nike         2.722774      1.809421       0.626868   \n",
       "54                    nike         2.396111      1.686302       0.621359   \n",
       "55                  pfizer         1.352199      1.042785       0.588518   \n",
       "56                  pfizer         1.398819      1.186520       0.573163   \n",
       "57                  pfizer         1.216455      1.003322       0.513618   \n",
       "58                  pfizer         0.906662      0.693476       0.605794   \n",
       "59                  pfizer         1.171252      0.918874       0.585292   \n",
       "60          procter-gamble         0.848708      0.681981       0.611616   \n",
       "61          procter-gamble         0.696940      0.516359       0.608958   \n",
       "62          procter-gamble         0.654545      0.445240       0.600249   \n",
       "63          procter-gamble         0.633404      0.435591       0.610483   \n",
       "64          procter-gamble         0.734796      0.526155       0.586843   \n",
       "70                visa-inc         1.905238      1.905238       0.552515   \n",
       "71                visa-inc         1.754050      1.754050       0.546552   \n",
       "72                visa-inc         1.448473      1.448473       0.583853   \n",
       "73                visa-inc         1.451727      1.451727       0.572006   \n",
       "74                visa-inc         1.283441      1.283441       0.585900   \n",
       "\n",
       "    endeudamiento_a_largo_plazo  covertura_de_intereses       ROA       ROE  \\\n",
       "0                      0.559076               13.527410  0.115111  0.421521   \n",
       "1                      0.486914               15.889344  0.125786  0.391886   \n",
       "2                      0.477064                7.246753  0.124357  0.391502   \n",
       "3                      0.601325                4.549416 -0.138296 -1.441674   \n",
       "4                      0.619996                3.602015  0.104670  1.075793   \n",
       "5                      0.454263               -1.030385 -0.036402 -0.101713   \n",
       "6                      0.483552                1.320913  0.000108  0.000303   \n",
       "7                      0.409376                3.187363  0.063180  0.154816   \n",
       "8                      0.443973                0.693899 -0.077632 -0.214590   \n",
       "9                      0.305021                2.622565  0.069514  0.170472   \n",
       "10                     0.315715               13.903461  0.066411  0.228374   \n",
       "11                     0.332989               13.752902  0.079334  0.241340   \n",
       "12                     0.348493                5.639206 -0.005883 -0.018638   \n",
       "13                     0.305126               11.581395  0.057639  0.150712   \n",
       "14                     0.255232               28.509144  0.094813  0.207183   \n",
       "15                     0.472870               23.072746  0.177256  0.878664   \n",
       "16                     0.462764               41.190548  0.269742  1.500713   \n",
       "17                     0.419841                0.000000  0.282924  1.969589   \n",
       "18                     0.411617                0.000000  0.275098  1.560760   \n",
       "19                     0.360672                0.000000  0.256825  1.645935   \n",
       "20                     0.431217               17.092824  0.048666  0.094364   \n",
       "21                     0.415756               27.599952  0.093803  0.175003   \n",
       "22                     0.439915               -6.436351 -0.023996 -0.047324   \n",
       "23                     0.413300               24.624425  0.089930  0.168858   \n",
       "24                     0.369686               21.872115  0.077127  0.136686   \n",
       "25                     0.353981               -6.100430 -0.023116 -0.041757   \n",
       "26                     0.303939               22.594101  0.065231  0.111706   \n",
       "27                     0.245467               81.405039  0.137616  0.221519   \n",
       "28                     0.257786               57.492537  0.081676  0.131999   \n",
       "29                     0.253847               39.223906  0.068736  0.115379   \n",
       "30                     0.588927                6.953375  0.088744  0.364342   \n",
       "31                     0.525092                7.159048  0.103558  0.393563   \n",
       "32                     0.508964               13.992063  0.102864  0.369888   \n",
       "33                     0.477488                8.674525  0.109659  0.389728   \n",
       "34                     0.486609                8.635870  0.105730  0.403392   \n",
       "35                     0.384070                2.295689 -0.014210 -0.029489   \n",
       "36                     0.345309                2.258732  0.009798  0.019614   \n",
       "37                     0.325000                4.410587  0.015445  0.029116   \n",
       "38                     0.298805                4.729853  0.011451  0.021022   \n",
       "39                     0.285895                5.950725  0.025339  0.047479   \n",
       "40                     0.125895              305.362963  0.125992  0.180948   \n",
       "41                     0.120743              227.497110  0.211633  0.302156   \n",
       "42                     0.109017              209.641457  0.164188  0.234134   \n",
       "43                     0.092445              273.678571  0.183391  0.260411   \n",
       "44                     0.080066              426.067164  0.222358  0.307976   \n",
       "45                     0.367385               20.439599  0.146961  0.374298   \n",
       "46                     0.308989               30.006867  0.183568  0.431522   \n",
       "47                     0.282908               40.734245  0.199370  0.436755   \n",
       "48                     0.246626               44.448622  0.175644  0.350887   \n",
       "49                     0.231176               36.685551  0.172086  0.328281   \n",
       "50                     0.478687               20.629139  0.081010  0.315208   \n",
       "51                     0.405379               24.429054  0.151749  0.448578   \n",
       "52                     0.354902               22.324415  0.149947  0.395655   \n",
       "53                     0.380246               20.326460  0.135088  0.362039   \n",
       "54                     0.343401               25.107807  0.149567  0.395010   \n",
       "55                     0.420437                6.757074  0.059393  0.144379   \n",
       "56                     0.338025               20.898528  0.121115  0.283900   \n",
       "57                     0.299942               32.181745  0.159083  0.327194   \n",
       "58                     0.394784                2.859665  0.009355  0.023743   \n",
       "59                     0.383812                5.282433  0.037634  0.090781   \n",
       "60                     0.338409               34.630108  0.107929  0.278343   \n",
       "61                     0.331255               36.818725  0.119909  0.306943   \n",
       "62                     0.318007               42.015945  0.125776  0.314980   \n",
       "63                     0.314560               25.207672  0.121271  0.311899   \n",
       "64                     0.312045               22.646486  0.121590  0.294850   \n",
       "70                     0.373200               27.374031  0.134282  0.300083   \n",
       "71                     0.356688               30.812865  0.148511  0.327516   \n",
       "72                     0.339961               36.581784  0.174934  0.420365   \n",
       "73                     0.316777               34.048137  0.190864  0.445950   \n",
       "74                     0.305330               37.346334  0.208896  0.504459   \n",
       "\n",
       "    rotacion_activos  rotacion_inventario   variacion  \n",
       "0           0.679891             7.592357    7.100160  \n",
       "1           0.751083             7.092277  -29.288691  \n",
       "2           0.563147             4.869881   -5.340940  \n",
       "3           0.486556             6.239858   46.447312  \n",
       "4           0.616409             6.645484         NaN  \n",
       "5           0.361939             6.915666  -11.725663  \n",
       "6           0.552779             8.547123  124.009908  \n",
       "7           0.552217             8.209048   97.359362  \n",
       "8           0.272720             4.039537  158.111369  \n",
       "9           0.598778            11.228847         NaN  \n",
       "10          1.201961            16.224585    6.194323  \n",
       "11          1.117164            14.394056  -50.599895  \n",
       "12          1.110894            14.939195   77.044981  \n",
       "13          1.088909            17.251486   49.236318  \n",
       "14          1.020908            18.646139         NaN  \n",
       "15          0.847562            67.597882   39.468211  \n",
       "16          1.042208            55.595289  -28.376331  \n",
       "17          1.117852            79.726648   54.798228  \n",
       "18          1.087077            60.540989   38.354959  \n",
       "19          1.071387            53.669366         NaN  \n",
       "20          0.281070            12.785246   31.606724  \n",
       "21          0.288058            13.180538    3.175215  \n",
       "22          0.318430            11.906489   15.568926  \n",
       "23          0.340644            14.096612   24.577154  \n",
       "24          0.321899            15.471218         NaN  \n",
       "25          0.392031            16.561839   46.537884  \n",
       "26          0.647367            22.820751   54.908118  \n",
       "27          0.915436            28.606281  -10.902560  \n",
       "28          0.744553            22.619484    0.484137  \n",
       "29          0.761149            21.552568         NaN  \n",
       "30          0.378185            10.108389   15.254871  \n",
       "31          0.409685            11.322496   11.032015  \n",
       "32          0.463590            10.159225   -3.432583  \n",
       "33          0.468297            10.342224    7.584963  \n",
       "34          0.468040             9.953680         NaN  \n",
       "35          0.324427            17.418221  -12.837683  \n",
       "36          0.331115            19.185544  -44.386325  \n",
       "37          0.406235            22.775881    1.814384  \n",
       "38          0.432427            17.904935   24.089076  \n",
       "39          0.465607            22.180384         NaN  \n",
       "40          0.571082           250.723901   69.923471  \n",
       "41          0.717116           220.202564  -38.996426  \n",
       "42          0.774333             0.000000   56.743712  \n",
       "43          0.763917             0.000000   40.015033  \n",
       "44          0.777376             0.000000         NaN  \n",
       "45          0.474642            75.469657   58.397892  \n",
       "46          0.503591            63.766313  -27.328362  \n",
       "47          0.543444            52.985035   58.349750  \n",
       "48          0.514387            84.766000   16.954590  \n",
       "49          0.478602           196.727127         NaN  \n",
       "50          1.193383             5.077101   21.376981  \n",
       "51          1.180127             6.498103  -27.970598  \n",
       "52          1.158453             5.547506   -7.390852  \n",
       "53          1.364659             6.058316  -27.047498  \n",
       "54          1.347730             6.830962         NaN  \n",
       "55          0.270091             5.193392   62.545375  \n",
       "56          0.447937             8.973176   -6.448356  \n",
       "57          0.513045            11.265449  -41.287025  \n",
       "58          0.262930             5.844931   -4.987517  \n",
       "59          0.298164             5.863699         NaN  \n",
       "60          0.587821            12.904693   22.130106  \n",
       "61          0.638001            12.722380   -4.003617  \n",
       "62          0.684143            11.581023   -0.864226  \n",
       "63          0.678695            11.594232   16.814913  \n",
       "64          0.686761            11.978193         NaN  \n",
       "70          0.269974             0.000000    0.803708  \n",
       "71          0.290786             0.000000   -5.327238  \n",
       "72          0.342803             0.000000   26.533370  \n",
       "73          0.360811             0.000000   24.037441  \n",
       "74          0.380125             0.000000         NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.merge(data[features].reset_index(), df_var, on=[\"company\",\"ejercicio\"], how=\"left\")\n",
    "dt.drop(columns=[\"ticker\",\"id\",\"ejercicio\"], inplace=True)\n",
    "dt.drop(dt[dt[\"company\"]==\"tesla-motors\"].index, inplace=True,axis=0)\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aqui quedamos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Seleccionar las columnas a normalizar\n",
    "columns_to_normalize = [\n",
    "  'razon_corriente', 'prueba_acida', 'endeudamiento', \n",
    "  'endeudamiento_a_largo_plazo', 'covertura_de_intereses', \n",
    "  'ROA', 'ROE', 'rotacion_activos', 'rotacion_inventario'\n",
    "]\n",
    "\n",
    "# Crear un objeto MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Aplicar la normalización\n",
    "dt_normalized = dt.copy()\n",
    "dt_normalized.loc[dt_normalized['variacion']>0, 'variacion'] = 1\n",
    "dt_normalized.loc[dt_normalized['variacion']<=0, 'variacion'] = 0\n",
    "dt_normalized[columns_to_normalize] = scaler.fit_transform(dt[columns_to_normalize])\n",
    "\n",
    "# Mostrar el DataFrame normalizado\n",
    "dt_normalized = dt_normalized[dt_normalized['variacion'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "razon_corriente",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prueba_acida",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "endeudamiento",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "endeudamiento_a_largo_plazo",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "covertura_de_intereses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ROA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ROE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rotacion_activos",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rotacion_inventario",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "variacion",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f13b9b41-c39e-495f-951b-54f9fc102553",
       "rows": [
        [
         "0",
         "3m-co",
         "0.2631758930581433",
         "0.19754265472507937",
         "0.7174970255367619",
         "0.887171430857774",
         "0.046158610521030916",
         "0.6016012132526491",
         "0.5461891347621491",
         "0.3784605038282236",
         "0.030281742804022467",
         "1.0"
        ],
        [
         "1",
         "3m-co",
         "0.22544609105573887",
         "0.15486742089496097",
         "0.6405895177860514",
         "0.7535194968585285",
         "0.051619685335221266",
         "0.6269447964516912",
         "0.537501671160139",
         "0.44307939621430925",
         "0.02828719878482522",
         "0.0"
        ],
        [
         "2",
         "3m-co",
         "0.19126474180002206",
         "0.11713522662753166",
         "0.6457101108146632",
         "0.7352767038466405",
         "0.0316369783509652",
         "0.6235519737576694",
         "0.5373891412354476",
         "0.2724961935512913",
         "0.019423281316195362",
         "0.0"
        ],
        [
         "3",
         "3m-co",
         "0.09202265527647788",
         "0.08144271436189744",
         "1.0",
         "0.9654189657005917",
         "0.0254004100086591",
         "0.0",
         "0.0",
         "0.20297706472695784",
         "0.024887368076284826",
         "1.0"
        ],
        [
         "5",
         "YPF",
         "0.04706244786709626",
         "0.03266239770008762",
         "0.5912695888857253",
         "0.693047579059261",
         "0.012499240983320867",
         "0.24190207840367273",
         "0.3928050292198582",
         "0.08986688827018433",
         "0.027582793295341555",
         "0.0"
        ],
        [
         "6",
         "YPF",
         "0.11218393739551283",
         "0.07281871830753418",
         "0.5910727894890226",
         "0.7472940381772653",
         "0.017935724423027977",
         "0.32857815875250757",
         "0.42271044230729615",
         "0.26308505317956743",
         "0.03408978142653772",
         "1.0"
        ],
        [
         "7",
         "YPF",
         "0.08975449109923933",
         "0.05632829823709261",
         "0.5057655126939546",
         "0.6099133670137885",
         "0.022251182213524068",
         "0.47831476758964486",
         "0.4680055904969511",
         "0.2625755814073776",
         "0.03274138762567419",
         "1.0"
        ],
        [
         "8",
         "YPF",
         "0.051502304486700234",
         "0.02170590208803108",
         "0.5806899060591288",
         "0.6739886309115056",
         "0.01648599285642209",
         "0.14401947478217195",
         "0.359715344111897",
         "0.008885817794113793",
         "0.016111495431475255",
         "1.0"
        ],
        [
         "10",
         "amazon-com-inc",
         "0.08770792254971024",
         "0.09202990881717203",
         "0.6890826365043234",
         "0.4364436222148368",
         "0.04702808467941394",
         "0.4859860700649269",
         "0.48956864777367803",
         "0.8523255262686772",
         "0.06471096263952948",
         "1.0"
        ],
        [
         "11",
         "amazon-com-inc",
         "0.10570562069478587",
         "0.10160860831583964",
         "0.6284781525336409",
         "0.46843625021768154",
         "0.04667997494924989",
         "0.5166660433316612",
         "0.49336962595183537",
         "0.7753574387491878",
         "0.05740998887406075",
         "0.0"
        ],
        [
         "12",
         "amazon-com-inc",
         "0.06549096759069448",
         "0.062088115983770745",
         "0.6493742960576361",
         "0.49715190696236755",
         "0.0279201357259167",
         "0.31435481142699023",
         "0.4171579551020042",
         "0.7696670504009869",
         "0.05958424712995958",
         "1.0"
        ],
        [
         "13",
         "amazon-com-inc",
         "0.08662420551580896",
         "0.08794923189625546",
         "0.542630285703757",
         "0.4168323656360168",
         "0.04165919076987985",
         "0.46516008318010976",
         "0.4668024583469619",
         "0.7497118536670873",
         "0.0688067057340868",
         "1.0"
        ],
        [
         "15",
         "apple-computer-inc",
         "0.1536486777392128",
         "0.19199361589717318",
         "0.8314199456842362",
         "0.7275098257908394",
         "0.06822857229718521",
         "0.7491366826841572",
         "0.6801989827479051",
         "0.5306491444942001",
         "0.2696108428383795",
         "1.0"
        ],
        [
         "16",
         "apple-computer-inc",
         "0.09282652167214844",
         "0.12660058571007582",
         "0.8665627164076166",
         "0.7087916612667315",
         "0.11011910336969481",
         "0.9687043564918829",
         "0.8625507438513611",
         "0.7073227053006494",
         "0.22173908634210807",
         "0.0"
        ],
        [
         "17",
         "apple-computer-inc",
         "0.05175316632755478",
         "0.08885300700925407",
         "0.9242468735774483",
         "0.6292947910885183",
         "0.014881615699109133",
         "1.0",
         "1.0",
         "0.7759826533862381",
         "0.31798583001765673",
         "1.0"
        ],
        [
         "18",
         "apple-computer-inc",
         "0.07461647755019338",
         "0.10983499502325024",
         "0.8721293692808252",
         "0.6140624385320046",
         "0.014881615699109133",
         "0.9814204920451224",
         "0.8801532833372623",
         "0.7480492970794921",
         "0.24146476869574884",
         "1.0"
        ],
        [
         "20",
         "berkshire-hathaway-inc",
         "0.7615364530044513",
         "0.7330131013707245",
         "0.32830001336953213",
         "0.6503646629750306",
         "0.054402274607154154",
         "0.4438578640460607",
         "0.45028434367436637",
         "0.016464662500085298",
         "0.050993326423642966",
         "1.0"
        ],
        [
         "21",
         "berkshire-hathaway-inc",
         "0.834709368360332",
         "0.7989548855405804",
         "0.295535116941735",
         "0.6217286765310746",
         "0.07869601508812424",
         "0.5510157712604412",
         "0.47392315171311455",
         "0.022807055400783566",
         "0.052569931563243855",
         "1.0"
        ],
        [
         "22",
         "berkshire-hathaway-inc",
         "0.7307107929784281",
         "0.6817406225807663",
         "0.34221872977065587",
         "0.6664737563439685",
         "0.0",
         "0.2713548898700233",
         "0.4087488880853384",
         "0.050375312369251385",
         "0.047488448244622415",
         "1.0"
        ],
        [
         "23",
         "berkshire-hathaway-inc",
         "0.7740068689915616",
         "0.7387389262605578",
         "0.3013278438843003",
         "0.6171804902927348",
         "0.071816240447153",
         "0.54182032867004",
         "0.4721218463771839",
         "0.07053825494567625",
         "0.05622364658162332",
         "1.0"
        ],
        [
         "25",
         "chevron",
         "0.11408562189438257",
         "0.1044972944930992",
         "0.26925704985765514",
         "0.5073153714325112",
         "0.0007766889169750421",
         "0.2734429999016728",
         "0.41038078049571247",
         "0.11717965190227583",
         "0.06605608500377556",
         "1.0"
        ],
        [
         "26",
         "chevron",
         "0.13170168052672127",
         "0.12305173467171455",
         "0.2201868059901318",
         "0.4146336433497432",
         "0.06712188733912428",
         "0.48318274002120276",
         "0.45536798372955917",
         "0.34893940875616836",
         "0.09101944589987236",
         "1.0"
        ],
        [
         "27",
         "chevron",
         "0.17638851487308332",
         "0.17159959715252188",
         "0.16013275220723527",
         "0.30633803192132364",
         "0.20309982869236953",
         "0.6550308891177092",
         "0.4875593234652532",
         "0.5922561069099556",
         "0.11409475102503625",
         "0.0"
        ],
        [
         "28",
         "chevron",
         "0.13499834038602104",
         "0.12355346911011199",
         "0.16472786020036617",
         "0.32915385805907116",
         "0.1478112573829244",
         "0.522224644658721",
         "0.4613169249183816",
         "0.437152318706442",
         "0.09021670587118578",
         "1.0"
        ],
        [
         "30",
         "coca-cola-co",
         "0.14399324774077427",
         "0.14212439714433417",
         "0.7641718010527974",
         "0.942458032258305",
         "0.030958652859032144",
         "0.539005071437272",
         "0.5294272944255924",
         "0.10461216022373068",
         "0.040316816318404496",
         "1.0"
        ],
        [
         "31",
         "coca-cola-co",
         "0.10449892323142271",
         "0.1129551132400227",
         "0.7327634959848397",
         "0.8242291218171078",
         "0.03143419379950978",
         "0.5741740234322433",
         "0.5379935207825005",
         "0.13320391350476843",
         "0.045159219191713965",
         "1.0"
        ],
        [
         "32",
         "coca-cola-co",
         "0.1077248391630028",
         "0.10687832054829068",
         "0.708887718721104",
         "0.7943581642946597",
         "0.04723294464250267",
         "0.5725273147514345",
         "0.5310531316144713",
         "0.1821316845134048",
         "0.040519571892868866",
         "0.0"
        ],
        [
         "33",
         "coca-cola-co",
         "0.10535752190102338",
         "0.11026130925375173",
         "0.7043298011284382",
         "0.7360621231671096",
         "0.034938158377562895",
         "0.5886580128854095",
         "0.5368690361656961",
         "0.1864038527898307",
         "0.04124945482315673",
         "1.0"
        ],
        [
         "35",
         "disney",
         "0.14527977445278384",
         "0.16129567524540545",
         "0.38063690039398396",
         "0.5630444196147486",
         "0.020189524307106535",
         "0.2945866116258921",
         "0.41397721517221836",
         "0.055818583208379874",
         "0.06947171964215779",
         "0.0"
        ],
        [
         "36",
         "disney",
         "0.09460803702213547",
         "0.11533989482363856",
         "0.35147618335904535",
         "0.4912546623874424",
         "0.02010407547654572",
         "0.35158325340283314",
         "0.42837156111982955",
         "0.061888791055824205",
         "0.07652060077254956",
         "0.0"
        ],
        [
         "37",
         "disney",
         "0.07732000156945029",
         "0.0950473582096714",
         "0.30326704366271234",
         "0.45364005818653064",
         "0.02507942293060547",
         "0.36498814682038305",
         "0.43115683889522294",
         "0.13007237908188488",
         "0.09084048611817228",
         "1.0"
        ],
        [
         "38",
         "disney",
         "0.08811314265982303",
         "0.09866798853087501",
         "0.27530400675473093",
         "0.4051249319701198",
         "0.025817603150280866",
         "0.3555061287991088",
         "0.42878435761920514",
         "0.15384651043782518",
         "0.0714129545022105",
         "1.0"
        ],
        [
         "40",
         "google-inc",
         "0.5120256440975708",
         "0.565169551937076",
         "0.04109056558348251",
         "0.08487993831190274",
         "0.7209174100297718",
         "0.6274333420559992",
         "0.4756661603863608",
         "0.2796985528901026",
         "1.0",
         "1.0"
        ],
        [
         "41",
         "google-inc",
         "0.48285252406888746",
         "0.5340781909426449",
         "0.03449894616262772",
         "0.0753377989655023",
         "0.5408822186727831",
         "0.8307504850384453",
         "0.5111977039713675",
         "0.41224876280270417",
         "0.8782671422127503",
         "0.0"
        ],
        [
         "42",
         "google-inc",
         "0.3670964892736751",
         "0.4192658691668954",
         "0.03314554940509756",
         "0.053620755079278326",
         "0.49959780684017063",
         "0.7181134207272779",
         "0.49125729174975796",
         "0.46418227775141185",
         "0.0",
         "1.0"
        ],
        [
         "43",
         "google-inc",
         "0.3078823700118309",
         "0.3585239370078951",
         "0.02838490532923077",
         "0.022927246836184884",
         "0.6476592967084746",
         "0.7637017609216742",
         "0.49896031847510236",
         "0.45472776076104604",
         "0.0",
         "1.0"
        ],
        [
         "45",
         "microsoft-corp",
         "0.3960862990396824",
         "0.44334698707957826",
         "0.5263521741152939",
         "0.5321407242550205",
         "0.06214041912697475",
         "0.6772156154770385",
         "0.5323460389973693",
         "0.19216362402729806",
         "0.30100703068717216",
         "1.0"
        ],
        [
         "46",
         "microsoft-corp",
         "0.3043912399524435",
         "0.348524984279288",
         "0.47399238649085745",
         "0.42398670081214784",
         "0.08426109099244061",
         "0.7641213687386568",
         "0.5491210507394926",
         "0.21843890836159727",
         "0.2543288147454569",
         "0.0"
        ],
        [
         "47",
         "microsoft-corp",
         "0.24223599289199704",
         "0.2826889364806987",
         "0.4243174704188834",
         "0.3756817622880012",
         "0.10906407618239178",
         "0.8016362298987578",
         "0.5506548848254218",
         "0.25461208083315123",
         "0.21132821605180646",
         "1.0"
        ],
        [
         "48",
         "microsoft-corp",
         "0.23898716830514183",
         "0.28266987971090785",
         "0.353857148635005",
         "0.30848503238023367",
         "0.11765215971399125",
         "0.7453097264040013",
         "0.5254831039943557",
         "0.22823811448401823",
         "0.3380850394736121",
         "1.0"
        ],
        [
         "50",
         "nike",
         "0.3888572160813988",
         "0.2496324716913415",
         "0.7430944762441396",
         "0.7382825004078993",
         "0.06257865940844162",
         "0.5206428569854001",
         "0.5150238668264651",
         "0.844538901251228",
         "0.020249767020341918",
         "1.0"
        ],
        [
         "51",
         "nike",
         "0.4385767008571364",
         "0.3396619623922946",
         "0.6131954564826185",
         "0.6025097514885148",
         "0.07136451859094643",
         "0.6885818666887507",
         "0.554120954765054",
         "0.8325073529356445",
         "0.025917366748299597",
         "0.0"
        ],
        [
         "52",
         "nike",
         "0.419988210501286",
         "0.3041421157587011",
         "0.548161385097375",
         "0.5090217872687725",
         "0.06649834001905089",
         "0.6843035110592677",
         "0.538606571125334",
         "0.812834827744701",
         "0.02212595573827642",
         "0.0"
        ],
        [
         "53",
         "nike",
         "0.4396451073491592",
         "0.2965398519870619",
         "0.5575134726069999",
         "0.5559607081014127",
         "0.06187883020231218",
         "0.6490289641840445",
         "0.5287523544966856",
         "0.9999999999999999",
         "0.024163295017746864",
         "0.0"
        ],
        [
         "55",
         "pfizer",
         "0.15124875989127257",
         "0.13106231363922277",
         "0.4962272623289388",
         "0.6303985771974179",
         "0.030504780841764494",
         "0.46932324128639274",
         "0.4649460747787673",
         "0.006499400785538401",
         "0.020713587729110878",
         "1.0"
        ],
        [
         "56",
         "pfizer",
         "0.16105849339164352",
         "0.16208729795946047",
         "0.47168804622513777",
         "0.47776347588849255",
         "0.06320151954781758",
         "0.6158557579985093",
         "0.5058461613240738",
         "0.16792388084517348",
         "0.03578907239355763",
         "0.0"
        ],
        [
         "57",
         "pfizer",
         "0.1226855992517315",
         "0.12254424540447943",
         "0.3765309427458649",
         "0.4072304736885489",
         "0.0892896693044299",
         "0.7059940902511503",
         "0.5185374920266168",
         "0.22702006508798048",
         "0.04493169272032575",
         "0.0"
        ],
        [
         "58",
         "pfizer",
         "0.057498870537766505",
         "0.05566422272970363",
         "0.5238353801732629",
         "0.5828872615163098",
         "0.021493504171103513",
         "0.3505319634355747",
         "0.4295817753480436",
         "0.0",
         "0.023312220263469123",
         "0.0"
        ],
        [
         "60",
         "procter-gamble",
         "0.04530424259438509",
         "0.05318296564308182",
         "0.5331382939862537",
         "0.47847593873799654",
         "0.09495057769193507",
         "0.5845506238450997",
         "0.5042169758114999",
         "0.294891838472379",
         "0.0514697344726067",
         "1.0"
        ],
        [
         "61",
         "procter-gamble",
         "0.013369098914833066",
         "0.01743360605998956",
         "0.5288919417135922",
         "0.46522494093493216",
         "0.10001092401372767",
         "0.6129927394233342",
         "0.5126010301576249",
         "0.34043853670866864",
         "0.05074258984134906",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 56
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>razon_corriente</th>\n",
       "      <th>prueba_acida</th>\n",
       "      <th>endeudamiento</th>\n",
       "      <th>endeudamiento_a_largo_plazo</th>\n",
       "      <th>covertura_de_intereses</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>rotacion_activos</th>\n",
       "      <th>rotacion_inventario</th>\n",
       "      <th>variacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>0.263176</td>\n",
       "      <td>0.197543</td>\n",
       "      <td>0.717497</td>\n",
       "      <td>0.887171</td>\n",
       "      <td>0.046159</td>\n",
       "      <td>0.601601</td>\n",
       "      <td>0.546189</td>\n",
       "      <td>0.378461</td>\n",
       "      <td>0.030282</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>0.225446</td>\n",
       "      <td>0.154867</td>\n",
       "      <td>0.640590</td>\n",
       "      <td>0.753519</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.626945</td>\n",
       "      <td>0.537502</td>\n",
       "      <td>0.443079</td>\n",
       "      <td>0.028287</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>0.191265</td>\n",
       "      <td>0.117135</td>\n",
       "      <td>0.645710</td>\n",
       "      <td>0.735277</td>\n",
       "      <td>0.031637</td>\n",
       "      <td>0.623552</td>\n",
       "      <td>0.537389</td>\n",
       "      <td>0.272496</td>\n",
       "      <td>0.019423</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>0.092023</td>\n",
       "      <td>0.081443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965419</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202977</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YPF</td>\n",
       "      <td>0.047062</td>\n",
       "      <td>0.032662</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.693048</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.241902</td>\n",
       "      <td>0.392805</td>\n",
       "      <td>0.089867</td>\n",
       "      <td>0.027583</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YPF</td>\n",
       "      <td>0.112184</td>\n",
       "      <td>0.072819</td>\n",
       "      <td>0.591073</td>\n",
       "      <td>0.747294</td>\n",
       "      <td>0.017936</td>\n",
       "      <td>0.328578</td>\n",
       "      <td>0.422710</td>\n",
       "      <td>0.263085</td>\n",
       "      <td>0.034090</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>YPF</td>\n",
       "      <td>0.089754</td>\n",
       "      <td>0.056328</td>\n",
       "      <td>0.505766</td>\n",
       "      <td>0.609913</td>\n",
       "      <td>0.022251</td>\n",
       "      <td>0.478315</td>\n",
       "      <td>0.468006</td>\n",
       "      <td>0.262576</td>\n",
       "      <td>0.032741</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>YPF</td>\n",
       "      <td>0.051502</td>\n",
       "      <td>0.021706</td>\n",
       "      <td>0.580690</td>\n",
       "      <td>0.673989</td>\n",
       "      <td>0.016486</td>\n",
       "      <td>0.144019</td>\n",
       "      <td>0.359715</td>\n",
       "      <td>0.008886</td>\n",
       "      <td>0.016111</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>0.087708</td>\n",
       "      <td>0.092030</td>\n",
       "      <td>0.689083</td>\n",
       "      <td>0.436444</td>\n",
       "      <td>0.047028</td>\n",
       "      <td>0.485986</td>\n",
       "      <td>0.489569</td>\n",
       "      <td>0.852326</td>\n",
       "      <td>0.064711</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>0.105706</td>\n",
       "      <td>0.101609</td>\n",
       "      <td>0.628478</td>\n",
       "      <td>0.468436</td>\n",
       "      <td>0.046680</td>\n",
       "      <td>0.516666</td>\n",
       "      <td>0.493370</td>\n",
       "      <td>0.775357</td>\n",
       "      <td>0.057410</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.062088</td>\n",
       "      <td>0.649374</td>\n",
       "      <td>0.497152</td>\n",
       "      <td>0.027920</td>\n",
       "      <td>0.314355</td>\n",
       "      <td>0.417158</td>\n",
       "      <td>0.769667</td>\n",
       "      <td>0.059584</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>0.086624</td>\n",
       "      <td>0.087949</td>\n",
       "      <td>0.542630</td>\n",
       "      <td>0.416832</td>\n",
       "      <td>0.041659</td>\n",
       "      <td>0.465160</td>\n",
       "      <td>0.466802</td>\n",
       "      <td>0.749712</td>\n",
       "      <td>0.068807</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>0.153649</td>\n",
       "      <td>0.191994</td>\n",
       "      <td>0.831420</td>\n",
       "      <td>0.727510</td>\n",
       "      <td>0.068229</td>\n",
       "      <td>0.749137</td>\n",
       "      <td>0.680199</td>\n",
       "      <td>0.530649</td>\n",
       "      <td>0.269611</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>0.092827</td>\n",
       "      <td>0.126601</td>\n",
       "      <td>0.866563</td>\n",
       "      <td>0.708792</td>\n",
       "      <td>0.110119</td>\n",
       "      <td>0.968704</td>\n",
       "      <td>0.862551</td>\n",
       "      <td>0.707323</td>\n",
       "      <td>0.221739</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>0.088853</td>\n",
       "      <td>0.924247</td>\n",
       "      <td>0.629295</td>\n",
       "      <td>0.014882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.775983</td>\n",
       "      <td>0.317986</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>0.074616</td>\n",
       "      <td>0.109835</td>\n",
       "      <td>0.872129</td>\n",
       "      <td>0.614062</td>\n",
       "      <td>0.014882</td>\n",
       "      <td>0.981420</td>\n",
       "      <td>0.880153</td>\n",
       "      <td>0.748049</td>\n",
       "      <td>0.241465</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>0.761536</td>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.328300</td>\n",
       "      <td>0.650365</td>\n",
       "      <td>0.054402</td>\n",
       "      <td>0.443858</td>\n",
       "      <td>0.450284</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>0.050993</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>0.834709</td>\n",
       "      <td>0.798955</td>\n",
       "      <td>0.295535</td>\n",
       "      <td>0.621729</td>\n",
       "      <td>0.078696</td>\n",
       "      <td>0.551016</td>\n",
       "      <td>0.473923</td>\n",
       "      <td>0.022807</td>\n",
       "      <td>0.052570</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>0.730711</td>\n",
       "      <td>0.681741</td>\n",
       "      <td>0.342219</td>\n",
       "      <td>0.666474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271355</td>\n",
       "      <td>0.408749</td>\n",
       "      <td>0.050375</td>\n",
       "      <td>0.047488</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>0.774007</td>\n",
       "      <td>0.738739</td>\n",
       "      <td>0.301328</td>\n",
       "      <td>0.617180</td>\n",
       "      <td>0.071816</td>\n",
       "      <td>0.541820</td>\n",
       "      <td>0.472122</td>\n",
       "      <td>0.070538</td>\n",
       "      <td>0.056224</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chevron</td>\n",
       "      <td>0.114086</td>\n",
       "      <td>0.104497</td>\n",
       "      <td>0.269257</td>\n",
       "      <td>0.507315</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.273443</td>\n",
       "      <td>0.410381</td>\n",
       "      <td>0.117180</td>\n",
       "      <td>0.066056</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>chevron</td>\n",
       "      <td>0.131702</td>\n",
       "      <td>0.123052</td>\n",
       "      <td>0.220187</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.067122</td>\n",
       "      <td>0.483183</td>\n",
       "      <td>0.455368</td>\n",
       "      <td>0.348939</td>\n",
       "      <td>0.091019</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chevron</td>\n",
       "      <td>0.176389</td>\n",
       "      <td>0.171600</td>\n",
       "      <td>0.160133</td>\n",
       "      <td>0.306338</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.655031</td>\n",
       "      <td>0.487559</td>\n",
       "      <td>0.592256</td>\n",
       "      <td>0.114095</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>chevron</td>\n",
       "      <td>0.134998</td>\n",
       "      <td>0.123553</td>\n",
       "      <td>0.164728</td>\n",
       "      <td>0.329154</td>\n",
       "      <td>0.147811</td>\n",
       "      <td>0.522225</td>\n",
       "      <td>0.461317</td>\n",
       "      <td>0.437152</td>\n",
       "      <td>0.090217</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>0.143993</td>\n",
       "      <td>0.142124</td>\n",
       "      <td>0.764172</td>\n",
       "      <td>0.942458</td>\n",
       "      <td>0.030959</td>\n",
       "      <td>0.539005</td>\n",
       "      <td>0.529427</td>\n",
       "      <td>0.104612</td>\n",
       "      <td>0.040317</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>0.104499</td>\n",
       "      <td>0.112955</td>\n",
       "      <td>0.732763</td>\n",
       "      <td>0.824229</td>\n",
       "      <td>0.031434</td>\n",
       "      <td>0.574174</td>\n",
       "      <td>0.537994</td>\n",
       "      <td>0.133204</td>\n",
       "      <td>0.045159</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>0.107725</td>\n",
       "      <td>0.106878</td>\n",
       "      <td>0.708888</td>\n",
       "      <td>0.794358</td>\n",
       "      <td>0.047233</td>\n",
       "      <td>0.572527</td>\n",
       "      <td>0.531053</td>\n",
       "      <td>0.182132</td>\n",
       "      <td>0.040520</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>0.105358</td>\n",
       "      <td>0.110261</td>\n",
       "      <td>0.704330</td>\n",
       "      <td>0.736062</td>\n",
       "      <td>0.034938</td>\n",
       "      <td>0.588658</td>\n",
       "      <td>0.536869</td>\n",
       "      <td>0.186404</td>\n",
       "      <td>0.041249</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>disney</td>\n",
       "      <td>0.145280</td>\n",
       "      <td>0.161296</td>\n",
       "      <td>0.380637</td>\n",
       "      <td>0.563044</td>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.294587</td>\n",
       "      <td>0.413977</td>\n",
       "      <td>0.055819</td>\n",
       "      <td>0.069472</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>disney</td>\n",
       "      <td>0.094608</td>\n",
       "      <td>0.115340</td>\n",
       "      <td>0.351476</td>\n",
       "      <td>0.491255</td>\n",
       "      <td>0.020104</td>\n",
       "      <td>0.351583</td>\n",
       "      <td>0.428372</td>\n",
       "      <td>0.061889</td>\n",
       "      <td>0.076521</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>disney</td>\n",
       "      <td>0.077320</td>\n",
       "      <td>0.095047</td>\n",
       "      <td>0.303267</td>\n",
       "      <td>0.453640</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>0.364988</td>\n",
       "      <td>0.431157</td>\n",
       "      <td>0.130072</td>\n",
       "      <td>0.090840</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>disney</td>\n",
       "      <td>0.088113</td>\n",
       "      <td>0.098668</td>\n",
       "      <td>0.275304</td>\n",
       "      <td>0.405125</td>\n",
       "      <td>0.025818</td>\n",
       "      <td>0.355506</td>\n",
       "      <td>0.428784</td>\n",
       "      <td>0.153847</td>\n",
       "      <td>0.071413</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>0.512026</td>\n",
       "      <td>0.565170</td>\n",
       "      <td>0.041091</td>\n",
       "      <td>0.084880</td>\n",
       "      <td>0.720917</td>\n",
       "      <td>0.627433</td>\n",
       "      <td>0.475666</td>\n",
       "      <td>0.279699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>0.482853</td>\n",
       "      <td>0.534078</td>\n",
       "      <td>0.034499</td>\n",
       "      <td>0.075338</td>\n",
       "      <td>0.540882</td>\n",
       "      <td>0.830750</td>\n",
       "      <td>0.511198</td>\n",
       "      <td>0.412249</td>\n",
       "      <td>0.878267</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>0.367096</td>\n",
       "      <td>0.419266</td>\n",
       "      <td>0.033146</td>\n",
       "      <td>0.053621</td>\n",
       "      <td>0.499598</td>\n",
       "      <td>0.718113</td>\n",
       "      <td>0.491257</td>\n",
       "      <td>0.464182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>0.307882</td>\n",
       "      <td>0.358524</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.647659</td>\n",
       "      <td>0.763702</td>\n",
       "      <td>0.498960</td>\n",
       "      <td>0.454728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>0.396086</td>\n",
       "      <td>0.443347</td>\n",
       "      <td>0.526352</td>\n",
       "      <td>0.532141</td>\n",
       "      <td>0.062140</td>\n",
       "      <td>0.677216</td>\n",
       "      <td>0.532346</td>\n",
       "      <td>0.192164</td>\n",
       "      <td>0.301007</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>0.304391</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>0.473992</td>\n",
       "      <td>0.423987</td>\n",
       "      <td>0.084261</td>\n",
       "      <td>0.764121</td>\n",
       "      <td>0.549121</td>\n",
       "      <td>0.218439</td>\n",
       "      <td>0.254329</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>0.242236</td>\n",
       "      <td>0.282689</td>\n",
       "      <td>0.424317</td>\n",
       "      <td>0.375682</td>\n",
       "      <td>0.109064</td>\n",
       "      <td>0.801636</td>\n",
       "      <td>0.550655</td>\n",
       "      <td>0.254612</td>\n",
       "      <td>0.211328</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>0.238987</td>\n",
       "      <td>0.282670</td>\n",
       "      <td>0.353857</td>\n",
       "      <td>0.308485</td>\n",
       "      <td>0.117652</td>\n",
       "      <td>0.745310</td>\n",
       "      <td>0.525483</td>\n",
       "      <td>0.228238</td>\n",
       "      <td>0.338085</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>nike</td>\n",
       "      <td>0.388857</td>\n",
       "      <td>0.249632</td>\n",
       "      <td>0.743094</td>\n",
       "      <td>0.738283</td>\n",
       "      <td>0.062579</td>\n",
       "      <td>0.520643</td>\n",
       "      <td>0.515024</td>\n",
       "      <td>0.844539</td>\n",
       "      <td>0.020250</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>nike</td>\n",
       "      <td>0.438577</td>\n",
       "      <td>0.339662</td>\n",
       "      <td>0.613195</td>\n",
       "      <td>0.602510</td>\n",
       "      <td>0.071365</td>\n",
       "      <td>0.688582</td>\n",
       "      <td>0.554121</td>\n",
       "      <td>0.832507</td>\n",
       "      <td>0.025917</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>nike</td>\n",
       "      <td>0.419988</td>\n",
       "      <td>0.304142</td>\n",
       "      <td>0.548161</td>\n",
       "      <td>0.509022</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.684304</td>\n",
       "      <td>0.538607</td>\n",
       "      <td>0.812835</td>\n",
       "      <td>0.022126</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>nike</td>\n",
       "      <td>0.439645</td>\n",
       "      <td>0.296540</td>\n",
       "      <td>0.557513</td>\n",
       "      <td>0.555961</td>\n",
       "      <td>0.061879</td>\n",
       "      <td>0.649029</td>\n",
       "      <td>0.528752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024163</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>0.151249</td>\n",
       "      <td>0.131062</td>\n",
       "      <td>0.496227</td>\n",
       "      <td>0.630399</td>\n",
       "      <td>0.030505</td>\n",
       "      <td>0.469323</td>\n",
       "      <td>0.464946</td>\n",
       "      <td>0.006499</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>0.161058</td>\n",
       "      <td>0.162087</td>\n",
       "      <td>0.471688</td>\n",
       "      <td>0.477763</td>\n",
       "      <td>0.063202</td>\n",
       "      <td>0.615856</td>\n",
       "      <td>0.505846</td>\n",
       "      <td>0.167924</td>\n",
       "      <td>0.035789</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>0.122686</td>\n",
       "      <td>0.122544</td>\n",
       "      <td>0.376531</td>\n",
       "      <td>0.407230</td>\n",
       "      <td>0.089290</td>\n",
       "      <td>0.705994</td>\n",
       "      <td>0.518537</td>\n",
       "      <td>0.227020</td>\n",
       "      <td>0.044932</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>0.057499</td>\n",
       "      <td>0.055664</td>\n",
       "      <td>0.523835</td>\n",
       "      <td>0.582887</td>\n",
       "      <td>0.021494</td>\n",
       "      <td>0.350532</td>\n",
       "      <td>0.429582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023312</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>0.045304</td>\n",
       "      <td>0.053183</td>\n",
       "      <td>0.533138</td>\n",
       "      <td>0.478476</td>\n",
       "      <td>0.094951</td>\n",
       "      <td>0.584551</td>\n",
       "      <td>0.504217</td>\n",
       "      <td>0.294892</td>\n",
       "      <td>0.051470</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>0.013369</td>\n",
       "      <td>0.017434</td>\n",
       "      <td>0.528892</td>\n",
       "      <td>0.465225</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.612993</td>\n",
       "      <td>0.512601</td>\n",
       "      <td>0.340439</td>\n",
       "      <td>0.050743</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.514974</td>\n",
       "      <td>0.440690</td>\n",
       "      <td>0.112028</td>\n",
       "      <td>0.626922</td>\n",
       "      <td>0.514957</td>\n",
       "      <td>0.382320</td>\n",
       "      <td>0.046190</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531328</td>\n",
       "      <td>0.434305</td>\n",
       "      <td>0.073165</td>\n",
       "      <td>0.616225</td>\n",
       "      <td>0.514054</td>\n",
       "      <td>0.377375</td>\n",
       "      <td>0.046243</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>0.267619</td>\n",
       "      <td>0.317222</td>\n",
       "      <td>0.438692</td>\n",
       "      <td>0.542912</td>\n",
       "      <td>0.078174</td>\n",
       "      <td>0.647116</td>\n",
       "      <td>0.510590</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>0.235806</td>\n",
       "      <td>0.284588</td>\n",
       "      <td>0.429163</td>\n",
       "      <td>0.512330</td>\n",
       "      <td>0.086125</td>\n",
       "      <td>0.680896</td>\n",
       "      <td>0.518632</td>\n",
       "      <td>0.025284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>0.171507</td>\n",
       "      <td>0.218630</td>\n",
       "      <td>0.488771</td>\n",
       "      <td>0.481350</td>\n",
       "      <td>0.099463</td>\n",
       "      <td>0.743624</td>\n",
       "      <td>0.545850</td>\n",
       "      <td>0.072498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>0.172192</td>\n",
       "      <td>0.219332</td>\n",
       "      <td>0.469840</td>\n",
       "      <td>0.438411</td>\n",
       "      <td>0.093605</td>\n",
       "      <td>0.781443</td>\n",
       "      <td>0.553351</td>\n",
       "      <td>0.088842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company  razon_corriente  prueba_acida  endeudamiento  \\\n",
       "0                    3m-co         0.263176      0.197543       0.717497   \n",
       "1                    3m-co         0.225446      0.154867       0.640590   \n",
       "2                    3m-co         0.191265      0.117135       0.645710   \n",
       "3                    3m-co         0.092023      0.081443       1.000000   \n",
       "5                      YPF         0.047062      0.032662       0.591270   \n",
       "6                      YPF         0.112184      0.072819       0.591073   \n",
       "7                      YPF         0.089754      0.056328       0.505766   \n",
       "8                      YPF         0.051502      0.021706       0.580690   \n",
       "10          amazon-com-inc         0.087708      0.092030       0.689083   \n",
       "11          amazon-com-inc         0.105706      0.101609       0.628478   \n",
       "12          amazon-com-inc         0.065491      0.062088       0.649374   \n",
       "13          amazon-com-inc         0.086624      0.087949       0.542630   \n",
       "15      apple-computer-inc         0.153649      0.191994       0.831420   \n",
       "16      apple-computer-inc         0.092827      0.126601       0.866563   \n",
       "17      apple-computer-inc         0.051753      0.088853       0.924247   \n",
       "18      apple-computer-inc         0.074616      0.109835       0.872129   \n",
       "20  berkshire-hathaway-inc         0.761536      0.733013       0.328300   \n",
       "21  berkshire-hathaway-inc         0.834709      0.798955       0.295535   \n",
       "22  berkshire-hathaway-inc         0.730711      0.681741       0.342219   \n",
       "23  berkshire-hathaway-inc         0.774007      0.738739       0.301328   \n",
       "25                 chevron         0.114086      0.104497       0.269257   \n",
       "26                 chevron         0.131702      0.123052       0.220187   \n",
       "27                 chevron         0.176389      0.171600       0.160133   \n",
       "28                 chevron         0.134998      0.123553       0.164728   \n",
       "30            coca-cola-co         0.143993      0.142124       0.764172   \n",
       "31            coca-cola-co         0.104499      0.112955       0.732763   \n",
       "32            coca-cola-co         0.107725      0.106878       0.708888   \n",
       "33            coca-cola-co         0.105358      0.110261       0.704330   \n",
       "35                  disney         0.145280      0.161296       0.380637   \n",
       "36                  disney         0.094608      0.115340       0.351476   \n",
       "37                  disney         0.077320      0.095047       0.303267   \n",
       "38                  disney         0.088113      0.098668       0.275304   \n",
       "40              google-inc         0.512026      0.565170       0.041091   \n",
       "41              google-inc         0.482853      0.534078       0.034499   \n",
       "42              google-inc         0.367096      0.419266       0.033146   \n",
       "43              google-inc         0.307882      0.358524       0.028385   \n",
       "45          microsoft-corp         0.396086      0.443347       0.526352   \n",
       "46          microsoft-corp         0.304391      0.348525       0.473992   \n",
       "47          microsoft-corp         0.242236      0.282689       0.424317   \n",
       "48          microsoft-corp         0.238987      0.282670       0.353857   \n",
       "50                    nike         0.388857      0.249632       0.743094   \n",
       "51                    nike         0.438577      0.339662       0.613195   \n",
       "52                    nike         0.419988      0.304142       0.548161   \n",
       "53                    nike         0.439645      0.296540       0.557513   \n",
       "55                  pfizer         0.151249      0.131062       0.496227   \n",
       "56                  pfizer         0.161058      0.162087       0.471688   \n",
       "57                  pfizer         0.122686      0.122544       0.376531   \n",
       "58                  pfizer         0.057499      0.055664       0.523835   \n",
       "60          procter-gamble         0.045304      0.053183       0.533138   \n",
       "61          procter-gamble         0.013369      0.017434       0.528892   \n",
       "62          procter-gamble         0.004448      0.002083       0.514974   \n",
       "63          procter-gamble         0.000000      0.000000       0.531328   \n",
       "70                visa-inc         0.267619      0.317222       0.438692   \n",
       "71                visa-inc         0.235806      0.284588       0.429163   \n",
       "72                visa-inc         0.171507      0.218630       0.488771   \n",
       "73                visa-inc         0.172192      0.219332       0.469840   \n",
       "\n",
       "    endeudamiento_a_largo_plazo  covertura_de_intereses       ROA       ROE  \\\n",
       "0                      0.887171                0.046159  0.601601  0.546189   \n",
       "1                      0.753519                0.051620  0.626945  0.537502   \n",
       "2                      0.735277                0.031637  0.623552  0.537389   \n",
       "3                      0.965419                0.025400  0.000000  0.000000   \n",
       "5                      0.693048                0.012499  0.241902  0.392805   \n",
       "6                      0.747294                0.017936  0.328578  0.422710   \n",
       "7                      0.609913                0.022251  0.478315  0.468006   \n",
       "8                      0.673989                0.016486  0.144019  0.359715   \n",
       "10                     0.436444                0.047028  0.485986  0.489569   \n",
       "11                     0.468436                0.046680  0.516666  0.493370   \n",
       "12                     0.497152                0.027920  0.314355  0.417158   \n",
       "13                     0.416832                0.041659  0.465160  0.466802   \n",
       "15                     0.727510                0.068229  0.749137  0.680199   \n",
       "16                     0.708792                0.110119  0.968704  0.862551   \n",
       "17                     0.629295                0.014882  1.000000  1.000000   \n",
       "18                     0.614062                0.014882  0.981420  0.880153   \n",
       "20                     0.650365                0.054402  0.443858  0.450284   \n",
       "21                     0.621729                0.078696  0.551016  0.473923   \n",
       "22                     0.666474                0.000000  0.271355  0.408749   \n",
       "23                     0.617180                0.071816  0.541820  0.472122   \n",
       "25                     0.507315                0.000777  0.273443  0.410381   \n",
       "26                     0.414634                0.067122  0.483183  0.455368   \n",
       "27                     0.306338                0.203100  0.655031  0.487559   \n",
       "28                     0.329154                0.147811  0.522225  0.461317   \n",
       "30                     0.942458                0.030959  0.539005  0.529427   \n",
       "31                     0.824229                0.031434  0.574174  0.537994   \n",
       "32                     0.794358                0.047233  0.572527  0.531053   \n",
       "33                     0.736062                0.034938  0.588658  0.536869   \n",
       "35                     0.563044                0.020190  0.294587  0.413977   \n",
       "36                     0.491255                0.020104  0.351583  0.428372   \n",
       "37                     0.453640                0.025079  0.364988  0.431157   \n",
       "38                     0.405125                0.025818  0.355506  0.428784   \n",
       "40                     0.084880                0.720917  0.627433  0.475666   \n",
       "41                     0.075338                0.540882  0.830750  0.511198   \n",
       "42                     0.053621                0.499598  0.718113  0.491257   \n",
       "43                     0.022927                0.647659  0.763702  0.498960   \n",
       "45                     0.532141                0.062140  0.677216  0.532346   \n",
       "46                     0.423987                0.084261  0.764121  0.549121   \n",
       "47                     0.375682                0.109064  0.801636  0.550655   \n",
       "48                     0.308485                0.117652  0.745310  0.525483   \n",
       "50                     0.738283                0.062579  0.520643  0.515024   \n",
       "51                     0.602510                0.071365  0.688582  0.554121   \n",
       "52                     0.509022                0.066498  0.684304  0.538607   \n",
       "53                     0.555961                0.061879  0.649029  0.528752   \n",
       "55                     0.630399                0.030505  0.469323  0.464946   \n",
       "56                     0.477763                0.063202  0.615856  0.505846   \n",
       "57                     0.407230                0.089290  0.705994  0.518537   \n",
       "58                     0.582887                0.021494  0.350532  0.429582   \n",
       "60                     0.478476                0.094951  0.584551  0.504217   \n",
       "61                     0.465225                0.100011  0.612993  0.512601   \n",
       "62                     0.440690                0.112028  0.626922  0.514957   \n",
       "63                     0.434305                0.073165  0.616225  0.514054   \n",
       "70                     0.542912                0.078174  0.647116  0.510590   \n",
       "71                     0.512330                0.086125  0.680896  0.518632   \n",
       "72                     0.481350                0.099463  0.743624  0.545850   \n",
       "73                     0.438411                0.093605  0.781443  0.553351   \n",
       "\n",
       "    rotacion_activos  rotacion_inventario  variacion  \n",
       "0           0.378461             0.030282        1.0  \n",
       "1           0.443079             0.028287        0.0  \n",
       "2           0.272496             0.019423        0.0  \n",
       "3           0.202977             0.024887        1.0  \n",
       "5           0.089867             0.027583        0.0  \n",
       "6           0.263085             0.034090        1.0  \n",
       "7           0.262576             0.032741        1.0  \n",
       "8           0.008886             0.016111        1.0  \n",
       "10          0.852326             0.064711        1.0  \n",
       "11          0.775357             0.057410        0.0  \n",
       "12          0.769667             0.059584        1.0  \n",
       "13          0.749712             0.068807        1.0  \n",
       "15          0.530649             0.269611        1.0  \n",
       "16          0.707323             0.221739        0.0  \n",
       "17          0.775983             0.317986        1.0  \n",
       "18          0.748049             0.241465        1.0  \n",
       "20          0.016465             0.050993        1.0  \n",
       "21          0.022807             0.052570        1.0  \n",
       "22          0.050375             0.047488        1.0  \n",
       "23          0.070538             0.056224        1.0  \n",
       "25          0.117180             0.066056        1.0  \n",
       "26          0.348939             0.091019        1.0  \n",
       "27          0.592256             0.114095        0.0  \n",
       "28          0.437152             0.090217        1.0  \n",
       "30          0.104612             0.040317        1.0  \n",
       "31          0.133204             0.045159        1.0  \n",
       "32          0.182132             0.040520        0.0  \n",
       "33          0.186404             0.041249        1.0  \n",
       "35          0.055819             0.069472        0.0  \n",
       "36          0.061889             0.076521        0.0  \n",
       "37          0.130072             0.090840        1.0  \n",
       "38          0.153847             0.071413        1.0  \n",
       "40          0.279699             1.000000        1.0  \n",
       "41          0.412249             0.878267        0.0  \n",
       "42          0.464182             0.000000        1.0  \n",
       "43          0.454728             0.000000        1.0  \n",
       "45          0.192164             0.301007        1.0  \n",
       "46          0.218439             0.254329        0.0  \n",
       "47          0.254612             0.211328        1.0  \n",
       "48          0.228238             0.338085        1.0  \n",
       "50          0.844539             0.020250        1.0  \n",
       "51          0.832507             0.025917        0.0  \n",
       "52          0.812835             0.022126        0.0  \n",
       "53          1.000000             0.024163        0.0  \n",
       "55          0.006499             0.020714        1.0  \n",
       "56          0.167924             0.035789        0.0  \n",
       "57          0.227020             0.044932        0.0  \n",
       "58          0.000000             0.023312        0.0  \n",
       "60          0.294892             0.051470        1.0  \n",
       "61          0.340439             0.050743        0.0  \n",
       "62          0.382320             0.046190        0.0  \n",
       "63          0.377375             0.046243        1.0  \n",
       "70          0.006393             0.000000        1.0  \n",
       "71          0.025284             0.000000        0.0  \n",
       "72          0.072498             0.000000        1.0  \n",
       "73          0.088842             0.000000        1.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4050x300 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear el correlograma\n",
    "sns.pairplot(dt_normalized.reset_index(), y_vars=[\"variacion\"], x_vars=features, kind=\"reg\", height=3, aspect=1.5)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company                         0\n",
       "razon_corriente                 0\n",
       "prueba_acida                    0\n",
       "endeudamiento                   0\n",
       "endeudamiento_a_largo_plazo     0\n",
       "covertura_de_intereses          0\n",
       "ROA                             0\n",
       "ROE                             0\n",
       "rotacion_activos                0\n",
       "rotacion_inventario             0\n",
       "variacion                      14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 11)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.3333333333333333\n",
      "R^2 Score: -0.4999999999999998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "dt_normalized = dt_normalized[dt_normalized[\"variacion\"].notna()]\n",
    "# Separar las características (X) y el target (y)\n",
    "X = dt_normalized.drop(columns=[\"variacion\", \"company\"])\n",
    "y = dt_normalized[\"variacion\"]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo de regresión lineal\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "razon_corriente",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prueba_acida",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "endeudamiento",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "endeudamiento_a_largo_plazo",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "covertura_de_intereses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ROA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ROE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rotacion_activos",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rotacion_inventario",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "variacion",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "34ea252c-40f7-4965-af30-cd8385558227",
       "rows": [
        [
         "0",
         "3m-co",
         "0.2631758930581433",
         "0.19754265472507937",
         "0.7174970255367619",
         "0.887171430857774",
         "0.046158610521030916",
         "0.6016012132526491",
         "0.5461891347621491",
         "0.3784605038282236",
         "0.030281742804022467",
         "0.27645874728930325"
        ],
        [
         "1",
         "3m-co",
         "0.22544609105573887",
         "0.15486742089496097",
         "0.6405895177860514",
         "0.7535194968585285",
         "0.051619685335221266",
         "0.6269447964516912",
         "0.537501671160139",
         "0.44307939621430925",
         "0.02828719878482522",
         "0.1021085438808497"
        ],
        [
         "2",
         "3m-co",
         "0.19126474180002206",
         "0.11713522662753166",
         "0.6457101108146632",
         "0.7352767038466405",
         "0.0316369783509652",
         "0.6235519737576694",
         "0.5373891412354476",
         "0.2724961935512913",
         "0.019423281316195362",
         "0.21684960401943043"
        ],
        [
         "3",
         "3m-co",
         "0.09202265527647788",
         "0.08144271436189744",
         "1.0",
         "0.9654189657005917",
         "0.0254004100086591",
         "0.0",
         "0.0",
         "0.20297706472695784",
         "0.024887368076284826",
         "0.46498308092246243"
        ],
        [
         "5",
         "YPF",
         "0.04706244786709626",
         "0.03266239770008762",
         "0.5912695888857253",
         "0.693047579059261",
         "0.012499240983320867",
         "0.24190207840367273",
         "0.3928050292198582",
         "0.08986688827018433",
         "0.027582793295341555",
         "0.18625842571391193"
        ],
        [
         "6",
         "YPF",
         "0.11218393739551283",
         "0.07281871830753418",
         "0.5910727894890226",
         "0.7472940381772653",
         "0.017935724423027977",
         "0.32857815875250757",
         "0.42271044230729615",
         "0.26308505317956743",
         "0.03408978142653772",
         "0.8366093863842037"
        ],
        [
         "7",
         "YPF",
         "0.08975449109923933",
         "0.05632829823709261",
         "0.5057655126939546",
         "0.6099133670137885",
         "0.022251182213524068",
         "0.47831476758964486",
         "0.4680055904969511",
         "0.2625755814073776",
         "0.03274138762567419",
         "0.7089184079271637"
        ],
        [
         "8",
         "YPF",
         "0.051502304486700234",
         "0.02170590208803108",
         "0.5806899060591288",
         "0.6739886309115056",
         "0.01648599285642209",
         "0.14401947478217195",
         "0.359715344111897",
         "0.008885817794113793",
         "0.016111495431475255",
         "1.0"
        ],
        [
         "10",
         "amazon-com-inc",
         "0.08770792254971024",
         "0.09202990881717203",
         "0.6890826365043234",
         "0.4364436222148368",
         "0.04702808467941394",
         "0.4859860700649269",
         "0.48956864777367803",
         "0.8523255262686772",
         "0.06471096263952948",
         "0.2721186008484509"
        ],
        [
         "11",
         "amazon-com-inc",
         "0.10570562069478587",
         "0.10160860831583964",
         "0.6284781525336409",
         "0.46843625021768154",
         "0.04667997494924989",
         "0.5166660433316612",
         "0.49336962595183537",
         "0.7753574387491878",
         "0.05740998887406075",
         "0.0"
        ],
        [
         "12",
         "amazon-com-inc",
         "0.06549096759069448",
         "0.062088115983770745",
         "0.6493742960576361",
         "0.49715190696236755",
         "0.0279201357259167",
         "0.31435481142699023",
         "0.4171579551020042",
         "0.7696670504009869",
         "0.05958424712995958",
         "0.6115859467247318"
        ],
        [
         "13",
         "amazon-com-inc",
         "0.08662420551580896",
         "0.08794923189625546",
         "0.542630285703757",
         "0.4168323656360168",
         "0.04165919076987985",
         "0.46516008318010976",
         "0.4668024583469619",
         "0.7497118536670873",
         "0.0688067057340868",
         "0.47834606665752916"
        ],
        [
         "15",
         "apple-computer-inc",
         "0.1536486777392128",
         "0.19199361589717318",
         "0.8314199456842362",
         "0.7275098257908394",
         "0.06822857229718521",
         "0.7491366826841572",
         "0.6801989827479051",
         "0.5306491444942001",
         "0.2696108428383795",
         "0.4315440569732063"
        ],
        [
         "16",
         "apple-computer-inc",
         "0.09282652167214844",
         "0.12660058571007582",
         "0.8665627164076166",
         "0.7087916612667315",
         "0.11011910336969481",
         "0.9687043564918829",
         "0.8625507438513611",
         "0.7073227053006494",
         "0.22173908634210807",
         "0.1064799433437798"
        ],
        [
         "17",
         "apple-computer-inc",
         "0.05175316632755478",
         "0.08885300700925407",
         "0.9242468735774483",
         "0.6292947910885183",
         "0.014881615699109133",
         "1.0",
         "1.0",
         "0.7759826533862381",
         "0.31798583001765673",
         "0.5049948947035862"
        ],
        [
         "18",
         "apple-computer-inc",
         "0.07461647755019338",
         "0.10983499502325024",
         "0.8721293692808252",
         "0.6140624385320046",
         "0.014881615699109133",
         "0.9814204920451224",
         "0.8801532833372623",
         "0.7480492970794921",
         "0.24146476869574884",
         "0.42621012166227196"
        ],
        [
         "20",
         "berkshire-hathaway-inc",
         "0.7615364530044513",
         "0.7330131013707245",
         "0.32830001336953213",
         "0.6503646629750306",
         "0.054402274607154154",
         "0.4438578640460607",
         "0.45028434367436637",
         "0.016464662500085298",
         "0.050993326423642966",
         "0.3938772515095307"
        ],
        [
         "21",
         "berkshire-hathaway-inc",
         "0.834709368360332",
         "0.7989548855405804",
         "0.295535116941735",
         "0.6217286765310746",
         "0.07869601508812424",
         "0.5510157712604412",
         "0.47392315171311455",
         "0.022807055400783566",
         "0.052569931563243855",
         "0.25765312417439884"
        ],
        [
         "22",
         "berkshire-hathaway-inc",
         "0.7307107929784281",
         "0.6817406225807663",
         "0.34221872977065587",
         "0.6664737563439685",
         "0.0",
         "0.2713548898700233",
         "0.4087488880853384",
         "0.050375312369251385",
         "0.047488448244622415",
         "0.31703521595348794"
        ],
        [
         "23",
         "berkshire-hathaway-inc",
         "0.7740068689915616",
         "0.7387389262605578",
         "0.3013278438843003",
         "0.6171804902927348",
         "0.071816240447153",
         "0.54182032867004",
         "0.4721218463771839",
         "0.07053825494567625",
         "0.05622364658162332",
         "0.3601964149036657"
        ],
        [
         "25",
         "chevron",
         "0.11408562189438257",
         "0.1044972944930992",
         "0.26925704985765514",
         "0.5073153714325112",
         "0.0007766889169750421",
         "0.2734429999016728",
         "0.41038078049571247",
         "0.11717965190227583",
         "0.06605608500377556",
         "0.46541703979335425"
        ],
        [
         "26",
         "chevron",
         "0.13170168052672127",
         "0.12305173467171455",
         "0.2201868059901318",
         "0.4146336433497432",
         "0.06712188733912428",
         "0.48318274002120276",
         "0.45536798372955917",
         "0.34893940875616836",
         "0.09101944589987236",
         "0.5055214095082442"
        ],
        [
         "27",
         "chevron",
         "0.17638851487308332",
         "0.17159959715252188",
         "0.16013275220723527",
         "0.30633803192132364",
         "0.20309982869236953",
         "0.6550308891177092",
         "0.4875593234652532",
         "0.5922561069099556",
         "0.11409475102503625",
         "0.19020216607214713"
        ],
        [
         "28",
         "chevron",
         "0.13499834038602104",
         "0.12355346911011199",
         "0.16472786020036617",
         "0.32915385805907116",
         "0.1478112573829244",
         "0.522224644658721",
         "0.4613169249183816",
         "0.437152318706442",
         "0.09021670587118578",
         "0.2447593430654434"
        ],
        [
         "30",
         "coca-cola-co",
         "0.14399324774077427",
         "0.14212439714433417",
         "0.7641718010527974",
         "0.942458032258305",
         "0.030958652859032144",
         "0.539005071437272",
         "0.5294272944255924",
         "0.10461216022373068",
         "0.040316816318404496",
         "0.315530482300666"
        ],
        [
         "31",
         "coca-cola-co",
         "0.10449892323142271",
         "0.1129551132400227",
         "0.7327634959848397",
         "0.8242291218171078",
         "0.03143419379950978",
         "0.5741740234322433",
         "0.5379935207825005",
         "0.13320391350476843",
         "0.045159219191713965",
         "0.2952974757667881"
        ],
        [
         "32",
         "coca-cola-co",
         "0.1077248391630028",
         "0.10687832054829068",
         "0.708887718721104",
         "0.7943581642946597",
         "0.04723294464250267",
         "0.5725273147514345",
         "0.5310531316144713",
         "0.1821316845134048",
         "0.040519571892868866",
         "0.22599313076406513"
        ],
        [
         "33",
         "coca-cola-co",
         "0.10535752190102338",
         "0.11026130925375173",
         "0.7043298011284382",
         "0.7360621231671096",
         "0.034938158377562895",
         "0.5886580128854095",
         "0.5368690361656961",
         "0.1864038527898307",
         "0.04124945482315673",
         "0.2787815874466182"
        ],
        [
         "35",
         "disney",
         "0.14527977445278384",
         "0.16129567524540545",
         "0.38063690039398396",
         "0.5630444196147486",
         "0.020189524307106535",
         "0.2945866116258921",
         "0.41397721517221836",
         "0.055818583208379874",
         "0.06947171964215779",
         "0.18093039353811044"
        ],
        [
         "36",
         "disney",
         "0.09460803702213547",
         "0.11533989482363856",
         "0.35147618335904535",
         "0.4912546623874424",
         "0.02010407547654572",
         "0.35158325340283314",
         "0.42837156111982955",
         "0.061888791055824205",
         "0.07652060077254956",
         "0.029771127370167516"
        ],
        [
         "37",
         "disney",
         "0.07732000156945029",
         "0.0950473582096714",
         "0.30326704366271234",
         "0.45364005818653064",
         "0.02507942293060547",
         "0.36498814682038305",
         "0.43115683889522294",
         "0.13007237908188488",
         "0.09084048611817228",
         "0.25113296389596484"
        ],
        [
         "38",
         "disney",
         "0.08811314265982303",
         "0.09866798853087501",
         "0.27530400675473093",
         "0.4051249319701198",
         "0.025817603150280866",
         "0.3555061287991088",
         "0.42878435761920514",
         "0.15384651043782518",
         "0.0714129545022105",
         "0.3578578796835816"
        ],
        [
         "40",
         "google-inc",
         "0.5120256440975708",
         "0.565169551937076",
         "0.04109056558348251",
         "0.08487993831190274",
         "0.7209174100297718",
         "0.6274333420559992",
         "0.4756661603863608",
         "0.2796985528901026",
         "1.0",
         "0.5774645975652359"
        ],
        [
         "41",
         "google-inc",
         "0.48285252406888746",
         "0.5340781909426449",
         "0.03449894616262772",
         "0.0753377989655023",
         "0.5408822186727831",
         "0.8307504850384453",
         "0.5111977039713675",
         "0.41224876280270417",
         "0.8782671422127503",
         "0.0555957951008762"
        ],
        [
         "42",
         "google-inc",
         "0.3670964892736751",
         "0.4192658691668954",
         "0.03314554940509756",
         "0.053620755079278326",
         "0.49959780684017063",
         "0.7181134207272779",
         "0.49125729174975796",
         "0.46418227775141185",
         "0.0",
         "0.5143163068976543"
        ],
        [
         "43",
         "google-inc",
         "0.3078823700118309",
         "0.3585239370078951",
         "0.02838490532923077",
         "0.022927246836184884",
         "0.6476592967084746",
         "0.7637017609216742",
         "0.49896031847510236",
         "0.45472776076104604",
         "0.0",
         "0.4341640510492139"
        ],
        [
         "45",
         "microsoft-corp",
         "0.3960862990396824",
         "0.44334698707957826",
         "0.5263521741152939",
         "0.5321407242550205",
         "0.06214041912697475",
         "0.6772156154770385",
         "0.5323460389973693",
         "0.19216362402729806",
         "0.30100703068717216",
         "0.5222419934310379"
        ],
        [
         "46",
         "microsoft-corp",
         "0.3043912399524435",
         "0.348524984279288",
         "0.47399238649085745",
         "0.42398670081214784",
         "0.08426109099244061",
         "0.7641213687386568",
         "0.5491210507394926",
         "0.21843890836159727",
         "0.2543288147454569",
         "0.11150108768919265"
        ],
        [
         "47",
         "microsoft-corp",
         "0.24223599289199704",
         "0.2826889364806987",
         "0.4243174704188834",
         "0.3756817622880012",
         "0.10906407618239178",
         "0.8016362298987578",
         "0.5506548848254218",
         "0.25461208083315123",
         "0.21132821605180646",
         "0.5220113283559714"
        ],
        [
         "48",
         "microsoft-corp",
         "0.23898716830514183",
         "0.28266987971090785",
         "0.353857148635005",
         "0.30848503238023367",
         "0.11765215971399125",
         "0.7453097264040013",
         "0.5254831039943557",
         "0.22823811448401823",
         "0.3380850394736121",
         "0.32367435967169467"
        ],
        [
         "50",
         "nike",
         "0.3888572160813988",
         "0.2496324716913415",
         "0.7430944762441396",
         "0.7382825004078993",
         "0.06257865940844162",
         "0.5206428569854001",
         "0.5150238668264651",
         "0.844538901251228",
         "0.020249767020341918",
         "0.344863399166467"
        ],
        [
         "51",
         "nike",
         "0.4385767008571364",
         "0.3396619623922946",
         "0.6131954564826185",
         "0.6025097514885148",
         "0.07136451859094643",
         "0.6885818666887507",
         "0.554120954765054",
         "0.8325073529356445",
         "0.025917366748299597",
         "0.10842393486654073"
        ],
        [
         "52",
         "nike",
         "0.419988210501286",
         "0.3041421157587011",
         "0.548161385097375",
         "0.5090217872687725",
         "0.06649834001905089",
         "0.6843035110592677",
         "0.538606571125334",
         "0.812834827744701",
         "0.02212595573827642",
         "0.20702783994205898"
        ],
        [
         "53",
         "nike",
         "0.4396451073491592",
         "0.2965398519870619",
         "0.5575134726069999",
         "0.5559607081014127",
         "0.06187883020231218",
         "0.6490289641840445",
         "0.5287523544966856",
         "0.9999999999999999",
         "0.024163295017746864",
         "0.11284679324061814"
        ],
        [
         "55",
         "pfizer",
         "0.15124875989127257",
         "0.13106231363922277",
         "0.4962272623289388",
         "0.6303985771974179",
         "0.030504780841764494",
         "0.46932324128639274",
         "0.4649460747787673",
         "0.006499400785538401",
         "0.020713587729110878",
         "0.5421138656595734"
        ],
        [
         "56",
         "pfizer",
         "0.16105849339164352",
         "0.16208729795946047",
         "0.47168804622513777",
         "0.47776347588849255",
         "0.06320151954781758",
         "0.6158557579985093",
         "0.5058461613240738",
         "0.16792388084517348",
         "0.03578907239355763",
         "0.2115436314648641"
        ],
        [
         "57",
         "pfizer",
         "0.1226855992517315",
         "0.12254424540447943",
         "0.3765309427458649",
         "0.4072304736885489",
         "0.0892896693044299",
         "0.7059940902511503",
         "0.5185374920266168",
         "0.22702006508798048",
         "0.04493169272032575",
         "0.04462082978565465"
        ],
        [
         "58",
         "pfizer",
         "0.057498870537766505",
         "0.05566422272970363",
         "0.5238353801732629",
         "0.5828872615163098",
         "0.021493504171103513",
         "0.3505319634355747",
         "0.4295817753480436",
         "0.0",
         "0.023312220263469123",
         "0.21854296323853173"
        ],
        [
         "60",
         "procter-gamble",
         "0.04530424259438509",
         "0.05318296564308182",
         "0.5331382939862537",
         "0.47847593873799654",
         "0.09495057769193507",
         "0.5845506238450997",
         "0.5042169758114999",
         "0.294891838472379",
         "0.0514697344726067",
         "0.3484718494107324"
        ],
        [
         "61",
         "procter-gamble",
         "0.013369098914833066",
         "0.01743360605998956",
         "0.5288919417135922",
         "0.46522494093493216",
         "0.10001092401372767",
         "0.6129927394233342",
         "0.5126010301576249",
         "0.34043853670866864",
         "0.05074258984134906",
         "0.22325713112573758"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 56
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>razon_corriente</th>\n",
       "      <th>prueba_acida</th>\n",
       "      <th>endeudamiento</th>\n",
       "      <th>endeudamiento_a_largo_plazo</th>\n",
       "      <th>covertura_de_intereses</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>rotacion_activos</th>\n",
       "      <th>rotacion_inventario</th>\n",
       "      <th>variacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>0.263176</td>\n",
       "      <td>0.197543</td>\n",
       "      <td>0.717497</td>\n",
       "      <td>0.887171</td>\n",
       "      <td>0.046159</td>\n",
       "      <td>0.601601</td>\n",
       "      <td>0.546189</td>\n",
       "      <td>0.378461</td>\n",
       "      <td>0.030282</td>\n",
       "      <td>0.276459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>0.225446</td>\n",
       "      <td>0.154867</td>\n",
       "      <td>0.640590</td>\n",
       "      <td>0.753519</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.626945</td>\n",
       "      <td>0.537502</td>\n",
       "      <td>0.443079</td>\n",
       "      <td>0.028287</td>\n",
       "      <td>0.102109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>0.191265</td>\n",
       "      <td>0.117135</td>\n",
       "      <td>0.645710</td>\n",
       "      <td>0.735277</td>\n",
       "      <td>0.031637</td>\n",
       "      <td>0.623552</td>\n",
       "      <td>0.537389</td>\n",
       "      <td>0.272496</td>\n",
       "      <td>0.019423</td>\n",
       "      <td>0.216850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3m-co</td>\n",
       "      <td>0.092023</td>\n",
       "      <td>0.081443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965419</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202977</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.464983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YPF</td>\n",
       "      <td>0.047062</td>\n",
       "      <td>0.032662</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.693048</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.241902</td>\n",
       "      <td>0.392805</td>\n",
       "      <td>0.089867</td>\n",
       "      <td>0.027583</td>\n",
       "      <td>0.186258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YPF</td>\n",
       "      <td>0.112184</td>\n",
       "      <td>0.072819</td>\n",
       "      <td>0.591073</td>\n",
       "      <td>0.747294</td>\n",
       "      <td>0.017936</td>\n",
       "      <td>0.328578</td>\n",
       "      <td>0.422710</td>\n",
       "      <td>0.263085</td>\n",
       "      <td>0.034090</td>\n",
       "      <td>0.836609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>YPF</td>\n",
       "      <td>0.089754</td>\n",
       "      <td>0.056328</td>\n",
       "      <td>0.505766</td>\n",
       "      <td>0.609913</td>\n",
       "      <td>0.022251</td>\n",
       "      <td>0.478315</td>\n",
       "      <td>0.468006</td>\n",
       "      <td>0.262576</td>\n",
       "      <td>0.032741</td>\n",
       "      <td>0.708918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>YPF</td>\n",
       "      <td>0.051502</td>\n",
       "      <td>0.021706</td>\n",
       "      <td>0.580690</td>\n",
       "      <td>0.673989</td>\n",
       "      <td>0.016486</td>\n",
       "      <td>0.144019</td>\n",
       "      <td>0.359715</td>\n",
       "      <td>0.008886</td>\n",
       "      <td>0.016111</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>0.087708</td>\n",
       "      <td>0.092030</td>\n",
       "      <td>0.689083</td>\n",
       "      <td>0.436444</td>\n",
       "      <td>0.047028</td>\n",
       "      <td>0.485986</td>\n",
       "      <td>0.489569</td>\n",
       "      <td>0.852326</td>\n",
       "      <td>0.064711</td>\n",
       "      <td>0.272119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>0.105706</td>\n",
       "      <td>0.101609</td>\n",
       "      <td>0.628478</td>\n",
       "      <td>0.468436</td>\n",
       "      <td>0.046680</td>\n",
       "      <td>0.516666</td>\n",
       "      <td>0.493370</td>\n",
       "      <td>0.775357</td>\n",
       "      <td>0.057410</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.062088</td>\n",
       "      <td>0.649374</td>\n",
       "      <td>0.497152</td>\n",
       "      <td>0.027920</td>\n",
       "      <td>0.314355</td>\n",
       "      <td>0.417158</td>\n",
       "      <td>0.769667</td>\n",
       "      <td>0.059584</td>\n",
       "      <td>0.611586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>amazon-com-inc</td>\n",
       "      <td>0.086624</td>\n",
       "      <td>0.087949</td>\n",
       "      <td>0.542630</td>\n",
       "      <td>0.416832</td>\n",
       "      <td>0.041659</td>\n",
       "      <td>0.465160</td>\n",
       "      <td>0.466802</td>\n",
       "      <td>0.749712</td>\n",
       "      <td>0.068807</td>\n",
       "      <td>0.478346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>0.153649</td>\n",
       "      <td>0.191994</td>\n",
       "      <td>0.831420</td>\n",
       "      <td>0.727510</td>\n",
       "      <td>0.068229</td>\n",
       "      <td>0.749137</td>\n",
       "      <td>0.680199</td>\n",
       "      <td>0.530649</td>\n",
       "      <td>0.269611</td>\n",
       "      <td>0.431544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>0.092827</td>\n",
       "      <td>0.126601</td>\n",
       "      <td>0.866563</td>\n",
       "      <td>0.708792</td>\n",
       "      <td>0.110119</td>\n",
       "      <td>0.968704</td>\n",
       "      <td>0.862551</td>\n",
       "      <td>0.707323</td>\n",
       "      <td>0.221739</td>\n",
       "      <td>0.106480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>0.088853</td>\n",
       "      <td>0.924247</td>\n",
       "      <td>0.629295</td>\n",
       "      <td>0.014882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.775983</td>\n",
       "      <td>0.317986</td>\n",
       "      <td>0.504995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>apple-computer-inc</td>\n",
       "      <td>0.074616</td>\n",
       "      <td>0.109835</td>\n",
       "      <td>0.872129</td>\n",
       "      <td>0.614062</td>\n",
       "      <td>0.014882</td>\n",
       "      <td>0.981420</td>\n",
       "      <td>0.880153</td>\n",
       "      <td>0.748049</td>\n",
       "      <td>0.241465</td>\n",
       "      <td>0.426210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>0.761536</td>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.328300</td>\n",
       "      <td>0.650365</td>\n",
       "      <td>0.054402</td>\n",
       "      <td>0.443858</td>\n",
       "      <td>0.450284</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>0.050993</td>\n",
       "      <td>0.393877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>0.834709</td>\n",
       "      <td>0.798955</td>\n",
       "      <td>0.295535</td>\n",
       "      <td>0.621729</td>\n",
       "      <td>0.078696</td>\n",
       "      <td>0.551016</td>\n",
       "      <td>0.473923</td>\n",
       "      <td>0.022807</td>\n",
       "      <td>0.052570</td>\n",
       "      <td>0.257653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>0.730711</td>\n",
       "      <td>0.681741</td>\n",
       "      <td>0.342219</td>\n",
       "      <td>0.666474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271355</td>\n",
       "      <td>0.408749</td>\n",
       "      <td>0.050375</td>\n",
       "      <td>0.047488</td>\n",
       "      <td>0.317035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>berkshire-hathaway-inc</td>\n",
       "      <td>0.774007</td>\n",
       "      <td>0.738739</td>\n",
       "      <td>0.301328</td>\n",
       "      <td>0.617180</td>\n",
       "      <td>0.071816</td>\n",
       "      <td>0.541820</td>\n",
       "      <td>0.472122</td>\n",
       "      <td>0.070538</td>\n",
       "      <td>0.056224</td>\n",
       "      <td>0.360196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chevron</td>\n",
       "      <td>0.114086</td>\n",
       "      <td>0.104497</td>\n",
       "      <td>0.269257</td>\n",
       "      <td>0.507315</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.273443</td>\n",
       "      <td>0.410381</td>\n",
       "      <td>0.117180</td>\n",
       "      <td>0.066056</td>\n",
       "      <td>0.465417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>chevron</td>\n",
       "      <td>0.131702</td>\n",
       "      <td>0.123052</td>\n",
       "      <td>0.220187</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.067122</td>\n",
       "      <td>0.483183</td>\n",
       "      <td>0.455368</td>\n",
       "      <td>0.348939</td>\n",
       "      <td>0.091019</td>\n",
       "      <td>0.505521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chevron</td>\n",
       "      <td>0.176389</td>\n",
       "      <td>0.171600</td>\n",
       "      <td>0.160133</td>\n",
       "      <td>0.306338</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.655031</td>\n",
       "      <td>0.487559</td>\n",
       "      <td>0.592256</td>\n",
       "      <td>0.114095</td>\n",
       "      <td>0.190202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>chevron</td>\n",
       "      <td>0.134998</td>\n",
       "      <td>0.123553</td>\n",
       "      <td>0.164728</td>\n",
       "      <td>0.329154</td>\n",
       "      <td>0.147811</td>\n",
       "      <td>0.522225</td>\n",
       "      <td>0.461317</td>\n",
       "      <td>0.437152</td>\n",
       "      <td>0.090217</td>\n",
       "      <td>0.244759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>0.143993</td>\n",
       "      <td>0.142124</td>\n",
       "      <td>0.764172</td>\n",
       "      <td>0.942458</td>\n",
       "      <td>0.030959</td>\n",
       "      <td>0.539005</td>\n",
       "      <td>0.529427</td>\n",
       "      <td>0.104612</td>\n",
       "      <td>0.040317</td>\n",
       "      <td>0.315530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>0.104499</td>\n",
       "      <td>0.112955</td>\n",
       "      <td>0.732763</td>\n",
       "      <td>0.824229</td>\n",
       "      <td>0.031434</td>\n",
       "      <td>0.574174</td>\n",
       "      <td>0.537994</td>\n",
       "      <td>0.133204</td>\n",
       "      <td>0.045159</td>\n",
       "      <td>0.295297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>0.107725</td>\n",
       "      <td>0.106878</td>\n",
       "      <td>0.708888</td>\n",
       "      <td>0.794358</td>\n",
       "      <td>0.047233</td>\n",
       "      <td>0.572527</td>\n",
       "      <td>0.531053</td>\n",
       "      <td>0.182132</td>\n",
       "      <td>0.040520</td>\n",
       "      <td>0.225993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>coca-cola-co</td>\n",
       "      <td>0.105358</td>\n",
       "      <td>0.110261</td>\n",
       "      <td>0.704330</td>\n",
       "      <td>0.736062</td>\n",
       "      <td>0.034938</td>\n",
       "      <td>0.588658</td>\n",
       "      <td>0.536869</td>\n",
       "      <td>0.186404</td>\n",
       "      <td>0.041249</td>\n",
       "      <td>0.278782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>disney</td>\n",
       "      <td>0.145280</td>\n",
       "      <td>0.161296</td>\n",
       "      <td>0.380637</td>\n",
       "      <td>0.563044</td>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.294587</td>\n",
       "      <td>0.413977</td>\n",
       "      <td>0.055819</td>\n",
       "      <td>0.069472</td>\n",
       "      <td>0.180930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>disney</td>\n",
       "      <td>0.094608</td>\n",
       "      <td>0.115340</td>\n",
       "      <td>0.351476</td>\n",
       "      <td>0.491255</td>\n",
       "      <td>0.020104</td>\n",
       "      <td>0.351583</td>\n",
       "      <td>0.428372</td>\n",
       "      <td>0.061889</td>\n",
       "      <td>0.076521</td>\n",
       "      <td>0.029771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>disney</td>\n",
       "      <td>0.077320</td>\n",
       "      <td>0.095047</td>\n",
       "      <td>0.303267</td>\n",
       "      <td>0.453640</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>0.364988</td>\n",
       "      <td>0.431157</td>\n",
       "      <td>0.130072</td>\n",
       "      <td>0.090840</td>\n",
       "      <td>0.251133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>disney</td>\n",
       "      <td>0.088113</td>\n",
       "      <td>0.098668</td>\n",
       "      <td>0.275304</td>\n",
       "      <td>0.405125</td>\n",
       "      <td>0.025818</td>\n",
       "      <td>0.355506</td>\n",
       "      <td>0.428784</td>\n",
       "      <td>0.153847</td>\n",
       "      <td>0.071413</td>\n",
       "      <td>0.357858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>0.512026</td>\n",
       "      <td>0.565170</td>\n",
       "      <td>0.041091</td>\n",
       "      <td>0.084880</td>\n",
       "      <td>0.720917</td>\n",
       "      <td>0.627433</td>\n",
       "      <td>0.475666</td>\n",
       "      <td>0.279699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>0.482853</td>\n",
       "      <td>0.534078</td>\n",
       "      <td>0.034499</td>\n",
       "      <td>0.075338</td>\n",
       "      <td>0.540882</td>\n",
       "      <td>0.830750</td>\n",
       "      <td>0.511198</td>\n",
       "      <td>0.412249</td>\n",
       "      <td>0.878267</td>\n",
       "      <td>0.055596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>0.367096</td>\n",
       "      <td>0.419266</td>\n",
       "      <td>0.033146</td>\n",
       "      <td>0.053621</td>\n",
       "      <td>0.499598</td>\n",
       "      <td>0.718113</td>\n",
       "      <td>0.491257</td>\n",
       "      <td>0.464182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>google-inc</td>\n",
       "      <td>0.307882</td>\n",
       "      <td>0.358524</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.647659</td>\n",
       "      <td>0.763702</td>\n",
       "      <td>0.498960</td>\n",
       "      <td>0.454728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>0.396086</td>\n",
       "      <td>0.443347</td>\n",
       "      <td>0.526352</td>\n",
       "      <td>0.532141</td>\n",
       "      <td>0.062140</td>\n",
       "      <td>0.677216</td>\n",
       "      <td>0.532346</td>\n",
       "      <td>0.192164</td>\n",
       "      <td>0.301007</td>\n",
       "      <td>0.522242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>0.304391</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>0.473992</td>\n",
       "      <td>0.423987</td>\n",
       "      <td>0.084261</td>\n",
       "      <td>0.764121</td>\n",
       "      <td>0.549121</td>\n",
       "      <td>0.218439</td>\n",
       "      <td>0.254329</td>\n",
       "      <td>0.111501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>0.242236</td>\n",
       "      <td>0.282689</td>\n",
       "      <td>0.424317</td>\n",
       "      <td>0.375682</td>\n",
       "      <td>0.109064</td>\n",
       "      <td>0.801636</td>\n",
       "      <td>0.550655</td>\n",
       "      <td>0.254612</td>\n",
       "      <td>0.211328</td>\n",
       "      <td>0.522011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>microsoft-corp</td>\n",
       "      <td>0.238987</td>\n",
       "      <td>0.282670</td>\n",
       "      <td>0.353857</td>\n",
       "      <td>0.308485</td>\n",
       "      <td>0.117652</td>\n",
       "      <td>0.745310</td>\n",
       "      <td>0.525483</td>\n",
       "      <td>0.228238</td>\n",
       "      <td>0.338085</td>\n",
       "      <td>0.323674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>nike</td>\n",
       "      <td>0.388857</td>\n",
       "      <td>0.249632</td>\n",
       "      <td>0.743094</td>\n",
       "      <td>0.738283</td>\n",
       "      <td>0.062579</td>\n",
       "      <td>0.520643</td>\n",
       "      <td>0.515024</td>\n",
       "      <td>0.844539</td>\n",
       "      <td>0.020250</td>\n",
       "      <td>0.344863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>nike</td>\n",
       "      <td>0.438577</td>\n",
       "      <td>0.339662</td>\n",
       "      <td>0.613195</td>\n",
       "      <td>0.602510</td>\n",
       "      <td>0.071365</td>\n",
       "      <td>0.688582</td>\n",
       "      <td>0.554121</td>\n",
       "      <td>0.832507</td>\n",
       "      <td>0.025917</td>\n",
       "      <td>0.108424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>nike</td>\n",
       "      <td>0.419988</td>\n",
       "      <td>0.304142</td>\n",
       "      <td>0.548161</td>\n",
       "      <td>0.509022</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.684304</td>\n",
       "      <td>0.538607</td>\n",
       "      <td>0.812835</td>\n",
       "      <td>0.022126</td>\n",
       "      <td>0.207028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>nike</td>\n",
       "      <td>0.439645</td>\n",
       "      <td>0.296540</td>\n",
       "      <td>0.557513</td>\n",
       "      <td>0.555961</td>\n",
       "      <td>0.061879</td>\n",
       "      <td>0.649029</td>\n",
       "      <td>0.528752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024163</td>\n",
       "      <td>0.112847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>0.151249</td>\n",
       "      <td>0.131062</td>\n",
       "      <td>0.496227</td>\n",
       "      <td>0.630399</td>\n",
       "      <td>0.030505</td>\n",
       "      <td>0.469323</td>\n",
       "      <td>0.464946</td>\n",
       "      <td>0.006499</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>0.542114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>0.161058</td>\n",
       "      <td>0.162087</td>\n",
       "      <td>0.471688</td>\n",
       "      <td>0.477763</td>\n",
       "      <td>0.063202</td>\n",
       "      <td>0.615856</td>\n",
       "      <td>0.505846</td>\n",
       "      <td>0.167924</td>\n",
       "      <td>0.035789</td>\n",
       "      <td>0.211544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>0.122686</td>\n",
       "      <td>0.122544</td>\n",
       "      <td>0.376531</td>\n",
       "      <td>0.407230</td>\n",
       "      <td>0.089290</td>\n",
       "      <td>0.705994</td>\n",
       "      <td>0.518537</td>\n",
       "      <td>0.227020</td>\n",
       "      <td>0.044932</td>\n",
       "      <td>0.044621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>0.057499</td>\n",
       "      <td>0.055664</td>\n",
       "      <td>0.523835</td>\n",
       "      <td>0.582887</td>\n",
       "      <td>0.021494</td>\n",
       "      <td>0.350532</td>\n",
       "      <td>0.429582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023312</td>\n",
       "      <td>0.218543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>0.045304</td>\n",
       "      <td>0.053183</td>\n",
       "      <td>0.533138</td>\n",
       "      <td>0.478476</td>\n",
       "      <td>0.094951</td>\n",
       "      <td>0.584551</td>\n",
       "      <td>0.504217</td>\n",
       "      <td>0.294892</td>\n",
       "      <td>0.051470</td>\n",
       "      <td>0.348472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>0.013369</td>\n",
       "      <td>0.017434</td>\n",
       "      <td>0.528892</td>\n",
       "      <td>0.465225</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.612993</td>\n",
       "      <td>0.512601</td>\n",
       "      <td>0.340439</td>\n",
       "      <td>0.050743</td>\n",
       "      <td>0.223257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.514974</td>\n",
       "      <td>0.440690</td>\n",
       "      <td>0.112028</td>\n",
       "      <td>0.626922</td>\n",
       "      <td>0.514957</td>\n",
       "      <td>0.382320</td>\n",
       "      <td>0.046190</td>\n",
       "      <td>0.238299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>procter-gamble</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531328</td>\n",
       "      <td>0.434305</td>\n",
       "      <td>0.073165</td>\n",
       "      <td>0.616225</td>\n",
       "      <td>0.514054</td>\n",
       "      <td>0.377375</td>\n",
       "      <td>0.046243</td>\n",
       "      <td>0.323005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>0.267619</td>\n",
       "      <td>0.317222</td>\n",
       "      <td>0.438692</td>\n",
       "      <td>0.542912</td>\n",
       "      <td>0.078174</td>\n",
       "      <td>0.647116</td>\n",
       "      <td>0.510590</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.246291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>0.235806</td>\n",
       "      <td>0.284588</td>\n",
       "      <td>0.429163</td>\n",
       "      <td>0.512330</td>\n",
       "      <td>0.086125</td>\n",
       "      <td>0.680896</td>\n",
       "      <td>0.518632</td>\n",
       "      <td>0.025284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>0.171507</td>\n",
       "      <td>0.218630</td>\n",
       "      <td>0.488771</td>\n",
       "      <td>0.481350</td>\n",
       "      <td>0.099463</td>\n",
       "      <td>0.743624</td>\n",
       "      <td>0.545850</td>\n",
       "      <td>0.072498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>visa-inc</td>\n",
       "      <td>0.172192</td>\n",
       "      <td>0.219332</td>\n",
       "      <td>0.469840</td>\n",
       "      <td>0.438411</td>\n",
       "      <td>0.093605</td>\n",
       "      <td>0.781443</td>\n",
       "      <td>0.553351</td>\n",
       "      <td>0.088842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company  razon_corriente  prueba_acida  endeudamiento  \\\n",
       "0                    3m-co         0.263176      0.197543       0.717497   \n",
       "1                    3m-co         0.225446      0.154867       0.640590   \n",
       "2                    3m-co         0.191265      0.117135       0.645710   \n",
       "3                    3m-co         0.092023      0.081443       1.000000   \n",
       "5                      YPF         0.047062      0.032662       0.591270   \n",
       "6                      YPF         0.112184      0.072819       0.591073   \n",
       "7                      YPF         0.089754      0.056328       0.505766   \n",
       "8                      YPF         0.051502      0.021706       0.580690   \n",
       "10          amazon-com-inc         0.087708      0.092030       0.689083   \n",
       "11          amazon-com-inc         0.105706      0.101609       0.628478   \n",
       "12          amazon-com-inc         0.065491      0.062088       0.649374   \n",
       "13          amazon-com-inc         0.086624      0.087949       0.542630   \n",
       "15      apple-computer-inc         0.153649      0.191994       0.831420   \n",
       "16      apple-computer-inc         0.092827      0.126601       0.866563   \n",
       "17      apple-computer-inc         0.051753      0.088853       0.924247   \n",
       "18      apple-computer-inc         0.074616      0.109835       0.872129   \n",
       "20  berkshire-hathaway-inc         0.761536      0.733013       0.328300   \n",
       "21  berkshire-hathaway-inc         0.834709      0.798955       0.295535   \n",
       "22  berkshire-hathaway-inc         0.730711      0.681741       0.342219   \n",
       "23  berkshire-hathaway-inc         0.774007      0.738739       0.301328   \n",
       "25                 chevron         0.114086      0.104497       0.269257   \n",
       "26                 chevron         0.131702      0.123052       0.220187   \n",
       "27                 chevron         0.176389      0.171600       0.160133   \n",
       "28                 chevron         0.134998      0.123553       0.164728   \n",
       "30            coca-cola-co         0.143993      0.142124       0.764172   \n",
       "31            coca-cola-co         0.104499      0.112955       0.732763   \n",
       "32            coca-cola-co         0.107725      0.106878       0.708888   \n",
       "33            coca-cola-co         0.105358      0.110261       0.704330   \n",
       "35                  disney         0.145280      0.161296       0.380637   \n",
       "36                  disney         0.094608      0.115340       0.351476   \n",
       "37                  disney         0.077320      0.095047       0.303267   \n",
       "38                  disney         0.088113      0.098668       0.275304   \n",
       "40              google-inc         0.512026      0.565170       0.041091   \n",
       "41              google-inc         0.482853      0.534078       0.034499   \n",
       "42              google-inc         0.367096      0.419266       0.033146   \n",
       "43              google-inc         0.307882      0.358524       0.028385   \n",
       "45          microsoft-corp         0.396086      0.443347       0.526352   \n",
       "46          microsoft-corp         0.304391      0.348525       0.473992   \n",
       "47          microsoft-corp         0.242236      0.282689       0.424317   \n",
       "48          microsoft-corp         0.238987      0.282670       0.353857   \n",
       "50                    nike         0.388857      0.249632       0.743094   \n",
       "51                    nike         0.438577      0.339662       0.613195   \n",
       "52                    nike         0.419988      0.304142       0.548161   \n",
       "53                    nike         0.439645      0.296540       0.557513   \n",
       "55                  pfizer         0.151249      0.131062       0.496227   \n",
       "56                  pfizer         0.161058      0.162087       0.471688   \n",
       "57                  pfizer         0.122686      0.122544       0.376531   \n",
       "58                  pfizer         0.057499      0.055664       0.523835   \n",
       "60          procter-gamble         0.045304      0.053183       0.533138   \n",
       "61          procter-gamble         0.013369      0.017434       0.528892   \n",
       "62          procter-gamble         0.004448      0.002083       0.514974   \n",
       "63          procter-gamble         0.000000      0.000000       0.531328   \n",
       "70                visa-inc         0.267619      0.317222       0.438692   \n",
       "71                visa-inc         0.235806      0.284588       0.429163   \n",
       "72                visa-inc         0.171507      0.218630       0.488771   \n",
       "73                visa-inc         0.172192      0.219332       0.469840   \n",
       "\n",
       "    endeudamiento_a_largo_plazo  covertura_de_intereses       ROA       ROE  \\\n",
       "0                      0.887171                0.046159  0.601601  0.546189   \n",
       "1                      0.753519                0.051620  0.626945  0.537502   \n",
       "2                      0.735277                0.031637  0.623552  0.537389   \n",
       "3                      0.965419                0.025400  0.000000  0.000000   \n",
       "5                      0.693048                0.012499  0.241902  0.392805   \n",
       "6                      0.747294                0.017936  0.328578  0.422710   \n",
       "7                      0.609913                0.022251  0.478315  0.468006   \n",
       "8                      0.673989                0.016486  0.144019  0.359715   \n",
       "10                     0.436444                0.047028  0.485986  0.489569   \n",
       "11                     0.468436                0.046680  0.516666  0.493370   \n",
       "12                     0.497152                0.027920  0.314355  0.417158   \n",
       "13                     0.416832                0.041659  0.465160  0.466802   \n",
       "15                     0.727510                0.068229  0.749137  0.680199   \n",
       "16                     0.708792                0.110119  0.968704  0.862551   \n",
       "17                     0.629295                0.014882  1.000000  1.000000   \n",
       "18                     0.614062                0.014882  0.981420  0.880153   \n",
       "20                     0.650365                0.054402  0.443858  0.450284   \n",
       "21                     0.621729                0.078696  0.551016  0.473923   \n",
       "22                     0.666474                0.000000  0.271355  0.408749   \n",
       "23                     0.617180                0.071816  0.541820  0.472122   \n",
       "25                     0.507315                0.000777  0.273443  0.410381   \n",
       "26                     0.414634                0.067122  0.483183  0.455368   \n",
       "27                     0.306338                0.203100  0.655031  0.487559   \n",
       "28                     0.329154                0.147811  0.522225  0.461317   \n",
       "30                     0.942458                0.030959  0.539005  0.529427   \n",
       "31                     0.824229                0.031434  0.574174  0.537994   \n",
       "32                     0.794358                0.047233  0.572527  0.531053   \n",
       "33                     0.736062                0.034938  0.588658  0.536869   \n",
       "35                     0.563044                0.020190  0.294587  0.413977   \n",
       "36                     0.491255                0.020104  0.351583  0.428372   \n",
       "37                     0.453640                0.025079  0.364988  0.431157   \n",
       "38                     0.405125                0.025818  0.355506  0.428784   \n",
       "40                     0.084880                0.720917  0.627433  0.475666   \n",
       "41                     0.075338                0.540882  0.830750  0.511198   \n",
       "42                     0.053621                0.499598  0.718113  0.491257   \n",
       "43                     0.022927                0.647659  0.763702  0.498960   \n",
       "45                     0.532141                0.062140  0.677216  0.532346   \n",
       "46                     0.423987                0.084261  0.764121  0.549121   \n",
       "47                     0.375682                0.109064  0.801636  0.550655   \n",
       "48                     0.308485                0.117652  0.745310  0.525483   \n",
       "50                     0.738283                0.062579  0.520643  0.515024   \n",
       "51                     0.602510                0.071365  0.688582  0.554121   \n",
       "52                     0.509022                0.066498  0.684304  0.538607   \n",
       "53                     0.555961                0.061879  0.649029  0.528752   \n",
       "55                     0.630399                0.030505  0.469323  0.464946   \n",
       "56                     0.477763                0.063202  0.615856  0.505846   \n",
       "57                     0.407230                0.089290  0.705994  0.518537   \n",
       "58                     0.582887                0.021494  0.350532  0.429582   \n",
       "60                     0.478476                0.094951  0.584551  0.504217   \n",
       "61                     0.465225                0.100011  0.612993  0.512601   \n",
       "62                     0.440690                0.112028  0.626922  0.514957   \n",
       "63                     0.434305                0.073165  0.616225  0.514054   \n",
       "70                     0.542912                0.078174  0.647116  0.510590   \n",
       "71                     0.512330                0.086125  0.680896  0.518632   \n",
       "72                     0.481350                0.099463  0.743624  0.545850   \n",
       "73                     0.438411                0.093605  0.781443  0.553351   \n",
       "\n",
       "    rotacion_activos  rotacion_inventario  variacion  \n",
       "0           0.378461             0.030282   0.276459  \n",
       "1           0.443079             0.028287   0.102109  \n",
       "2           0.272496             0.019423   0.216850  \n",
       "3           0.202977             0.024887   0.464983  \n",
       "5           0.089867             0.027583   0.186258  \n",
       "6           0.263085             0.034090   0.836609  \n",
       "7           0.262576             0.032741   0.708918  \n",
       "8           0.008886             0.016111   1.000000  \n",
       "10          0.852326             0.064711   0.272119  \n",
       "11          0.775357             0.057410   0.000000  \n",
       "12          0.769667             0.059584   0.611586  \n",
       "13          0.749712             0.068807   0.478346  \n",
       "15          0.530649             0.269611   0.431544  \n",
       "16          0.707323             0.221739   0.106480  \n",
       "17          0.775983             0.317986   0.504995  \n",
       "18          0.748049             0.241465   0.426210  \n",
       "20          0.016465             0.050993   0.393877  \n",
       "21          0.022807             0.052570   0.257653  \n",
       "22          0.050375             0.047488   0.317035  \n",
       "23          0.070538             0.056224   0.360196  \n",
       "25          0.117180             0.066056   0.465417  \n",
       "26          0.348939             0.091019   0.505521  \n",
       "27          0.592256             0.114095   0.190202  \n",
       "28          0.437152             0.090217   0.244759  \n",
       "30          0.104612             0.040317   0.315530  \n",
       "31          0.133204             0.045159   0.295297  \n",
       "32          0.182132             0.040520   0.225993  \n",
       "33          0.186404             0.041249   0.278782  \n",
       "35          0.055819             0.069472   0.180930  \n",
       "36          0.061889             0.076521   0.029771  \n",
       "37          0.130072             0.090840   0.251133  \n",
       "38          0.153847             0.071413   0.357858  \n",
       "40          0.279699             1.000000   0.577465  \n",
       "41          0.412249             0.878267   0.055596  \n",
       "42          0.464182             0.000000   0.514316  \n",
       "43          0.454728             0.000000   0.434164  \n",
       "45          0.192164             0.301007   0.522242  \n",
       "46          0.218439             0.254329   0.111501  \n",
       "47          0.254612             0.211328   0.522011  \n",
       "48          0.228238             0.338085   0.323674  \n",
       "50          0.844539             0.020250   0.344863  \n",
       "51          0.832507             0.025917   0.108424  \n",
       "52          0.812835             0.022126   0.207028  \n",
       "53          1.000000             0.024163   0.112847  \n",
       "55          0.006499             0.020714   0.542114  \n",
       "56          0.167924             0.035789   0.211544  \n",
       "57          0.227020             0.044932   0.044621  \n",
       "58          0.000000             0.023312   0.218543  \n",
       "60          0.294892             0.051470   0.348472  \n",
       "61          0.340439             0.050743   0.223257  \n",
       "62          0.382320             0.046190   0.238299  \n",
       "63          0.377375             0.046243   0.323005  \n",
       "70          0.006393             0.000000   0.246291  \n",
       "71          0.025284             0.000000   0.216915  \n",
       "72          0.072498             0.000000   0.369569  \n",
       "73          0.088842             0.000000   0.357610  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"n_estimators\": 2000,\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 150),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 100),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**param, early_stopping_rounds=50)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)])\n",
    "\n",
    "\n",
    "    # Puedes usar la métrica de tu preferencia aquí\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMRegressor(**study.best_params, early_stopping_rounds=50)\n",
    "model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)])\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22111786475165882"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 19:57:52,160] A new study created in memory with name: no-name-689ed09d-0adc-48ee-bb14-cfedb938704c\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,201] Trial 0 finished with value: 0.5 and parameters: {'learning_rate': 0.04250542436440819, 'max_depth': 9, 'num_leaves': 86, 'min_child_samples': 27, 'subsample': 0.5359458694707138, 'colsample_bytree': 0.5683687612059338, 'reg_alpha': 0.6010987601874597, 'reg_lambda': 0.06409637683650739}. Best is trial 0 with value: 0.5.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,233] Trial 1 finished with value: 0.5 and parameters: {'learning_rate': 0.07689391835440276, 'max_depth': 8, 'num_leaves': 55, 'min_child_samples': 67, 'subsample': 0.8201068169233774, 'colsample_bytree': 0.9645896727309902, 'reg_alpha': 0.012079396511041564, 'reg_lambda': 0.04526798814567573}. Best is trial 0 with value: 0.5.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,252] Trial 2 finished with value: 0.5 and parameters: {'learning_rate': 0.0039608933665051275, 'max_depth': 8, 'num_leaves': 59, 'min_child_samples': 27, 'subsample': 0.6705768679603973, 'colsample_bytree': 0.609118208258915, 'reg_alpha': 0.32304620092007413, 'reg_lambda': 0.2344606814780907}. Best is trial 0 with value: 0.5.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,285] Trial 3 finished with value: 0.5 and parameters: {'learning_rate': 0.002421346392072027, 'max_depth': 5, 'num_leaves': 132, 'min_child_samples': 52, 'subsample': 0.9058004983605865, 'colsample_bytree': 0.7281463278283193, 'reg_alpha': 0.02243072023986291, 'reg_lambda': 0.7702355553402268}. Best is trial 0 with value: 0.5.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,308] Trial 4 finished with value: 0.5 and parameters: {'learning_rate': 0.02665711768698308, 'max_depth': 3, 'num_leaves': 53, 'min_child_samples': 71, 'subsample': 0.5136127677029273, 'colsample_bytree': 0.5667126757695642, 'reg_alpha': 0.7810596256365095, 'reg_lambda': 0.5631279143413936}. Best is trial 0 with value: 0.5.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,338] Trial 5 finished with value: 0.5 and parameters: {'learning_rate': 0.008473918040598789, 'max_depth': 8, 'num_leaves': 66, 'min_child_samples': 62, 'subsample': 0.7544560685453061, 'colsample_bytree': 0.8076951817531761, 'reg_alpha': 0.22594392720690518, 'reg_lambda': 0.13782570692790078}. Best is trial 0 with value: 0.5.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,360] Trial 6 finished with value: 0.34375 and parameters: {'learning_rate': 0.09144516323610388, 'max_depth': 7, 'num_leaves': 59, 'min_child_samples': 19, 'subsample': 0.9373635389579995, 'colsample_bytree': 0.7557414919891927, 'reg_alpha': 0.044094808213924266, 'reg_lambda': 0.12646643636510405}. Best is trial 6 with value: 0.34375.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,378] Trial 7 finished with value: 0.5 and parameters: {'learning_rate': 0.04381246556637502, 'max_depth': 5, 'num_leaves': 130, 'min_child_samples': 71, 'subsample': 0.8663498040992323, 'colsample_bytree': 0.7682488906512914, 'reg_alpha': 0.13261692028956015, 'reg_lambda': 0.1801461255773762}. Best is trial 6 with value: 0.34375.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,397] Trial 8 finished with value: 0.5 and parameters: {'learning_rate': 0.03518674361327035, 'max_depth': 7, 'num_leaves': 75, 'min_child_samples': 79, 'subsample': 0.7984668754208312, 'colsample_bytree': 0.5915622626670924, 'reg_alpha': 0.01434903725521361, 'reg_lambda': 0.049246104984678636}. Best is trial 6 with value: 0.34375.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,414] Trial 9 finished with value: 0.5 and parameters: {'learning_rate': 0.0016891203062010527, 'max_depth': 3, 'num_leaves': 111, 'min_child_samples': 49, 'subsample': 0.8103916676776961, 'colsample_bytree': 0.8863470730257774, 'reg_alpha': 0.14227122569919556, 'reg_lambda': 0.06970762689186849}. Best is trial 6 with value: 0.34375.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,490] Trial 10 finished with value: 0.625 and parameters: {'learning_rate': 0.012878862869747605, 'max_depth': 10, 'num_leaves': 20, 'min_child_samples': 12, 'subsample': 0.985016449399331, 'colsample_bytree': 0.6773391485988913, 'reg_alpha': 0.03934776901344593, 'reg_lambda': 0.012638980784269938}. Best is trial 6 with value: 0.34375.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,559] Trial 11 finished with value: 0.5 and parameters: {'learning_rate': 0.08530823157432267, 'max_depth': 10, 'num_leaves': 100, 'min_child_samples': 29, 'subsample': 0.6504483228199056, 'colsample_bytree': 0.6699207456865579, 'reg_alpha': 0.05001160442125957, 'reg_lambda': 0.018939466298769345}. Best is trial 6 with value: 0.34375.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,624] Trial 12 finished with value: 0.625 and parameters: {'learning_rate': 0.09929299153382577, 'max_depth': 9, 'num_leaves': 32, 'min_child_samples': 10, 'subsample': 0.5285780168489809, 'colsample_bytree': 0.5250253640986655, 'reg_alpha': 0.6838810603360114, 'reg_lambda': 0.37320797179248505}. Best is trial 6 with value: 0.34375.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,695] Trial 13 finished with value: 0.5 and parameters: {'learning_rate': 0.01949900022075, 'max_depth': 6, 'num_leaves': 90, 'min_child_samples': 98, 'subsample': 0.6121520345939278, 'colsample_bytree': 0.8429876443496471, 'reg_alpha': 0.08103628455410872, 'reg_lambda': 0.02995907474639401}. Best is trial 6 with value: 0.34375.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,766] Trial 14 finished with value: 0.5 and parameters: {'learning_rate': 0.047190995115854825, 'max_depth': 7, 'num_leaves': 84, 'min_child_samples': 35, 'subsample': 0.9757225392521722, 'colsample_bytree': 0.5022553556492473, 'reg_alpha': 0.3781770478797553, 'reg_lambda': 0.09603279741794785}. Best is trial 6 with value: 0.34375.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,838] Trial 15 finished with value: 0.5 and parameters: {'learning_rate': 0.010253942109538679, 'max_depth': 9, 'num_leaves': 37, 'min_child_samples': 38, 'subsample': 0.7219001816424656, 'colsample_bytree': 0.6800853827021122, 'reg_alpha': 0.06101442765251843, 'reg_lambda': 0.10600336414181429}. Best is trial 6 with value: 0.34375.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,908] Trial 16 finished with value: 0.375 and parameters: {'learning_rate': 0.05642071869188171, 'max_depth': 6, 'num_leaves': 112, 'min_child_samples': 21, 'subsample': 0.6057654782133266, 'colsample_bytree': 0.9036280381384532, 'reg_alpha': 0.03365609204687421, 'reg_lambda': 0.27881313803174806}. Best is trial 6 with value: 0.34375.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:52,983] Trial 17 finished with value: 0.3125 and parameters: {'learning_rate': 0.0060879287457853756, 'max_depth': 5, 'num_leaves': 150, 'min_child_samples': 19, 'subsample': 0.5888688993422226, 'colsample_bytree': 0.9894440056432319, 'reg_alpha': 0.028167170246414498, 'reg_lambda': 0.3512269210856065}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:53,088] Trial 18 finished with value: 0.5 and parameters: {'learning_rate': 0.005210713230177465, 'max_depth': 4, 'num_leaves': 149, 'min_child_samples': 43, 'subsample': 0.8935629563894657, 'colsample_bytree': 0.9839056164327947, 'reg_alpha': 0.024429463900919077, 'reg_lambda': 0.9922827201843454}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:53,175] Trial 19 finished with value: 0.3125 and parameters: {'learning_rate': 0.001142398937290024, 'max_depth': 5, 'num_leaves': 147, 'min_child_samples': 18, 'subsample': 0.7311203924430605, 'colsample_bytree': 0.9342283904834096, 'reg_alpha': 0.08264588079393864, 'reg_lambda': 0.40318216691212255}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:53,259] Trial 20 finished with value: 0.6875 and parameters: {'learning_rate': 0.0013392916439223133, 'max_depth': 5, 'num_leaves': 149, 'min_child_samples': 17, 'subsample': 0.7151088371018729, 'colsample_bytree': 0.9417793272499684, 'reg_alpha': 0.09603988279111121, 'reg_lambda': 0.43697765072053024}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:53,349] Trial 21 finished with value: 0.375 and parameters: {'learning_rate': 0.0010035118984708595, 'max_depth': 4, 'num_leaves': 129, 'min_child_samples': 21, 'subsample': 0.5984855857120871, 'colsample_bytree': 0.8660907843006357, 'reg_alpha': 0.021875042603410912, 'reg_lambda': 0.2970918520661163}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:53,426] Trial 22 finished with value: 0.5 and parameters: {'learning_rate': 0.0034572975229231356, 'max_depth': 6, 'num_leaves': 139, 'min_child_samples': 32, 'subsample': 0.7610556735858204, 'colsample_bytree': 0.9305163618880457, 'reg_alpha': 0.06449151720963923, 'reg_lambda': 0.17658522347183267}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:53,516] Trial 23 finished with value: 0.3125 and parameters: {'learning_rate': 0.005729081264882519, 'max_depth': 4, 'num_leaves': 111, 'min_child_samples': 18, 'subsample': 0.6994923656237075, 'colsample_bytree': 0.9879740109449906, 'reg_alpha': 0.03846483246328565, 'reg_lambda': 0.5868467594447355}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:53,586] Trial 24 finished with value: 0.5 and parameters: {'learning_rate': 0.006704330936759435, 'max_depth': 4, 'num_leaves': 115, 'min_child_samples': 43, 'subsample': 0.6754241730001043, 'colsample_bytree': 0.985620172791232, 'reg_alpha': 0.03213021727289585, 'reg_lambda': 0.5819209021088008}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:53,666] Trial 25 finished with value: 0.625 and parameters: {'learning_rate': 0.0024101891953779925, 'max_depth': 5, 'num_leaves': 123, 'min_child_samples': 11, 'subsample': 0.5726949089590954, 'colsample_bytree': 0.9380968095717072, 'reg_alpha': 0.017631294552955992, 'reg_lambda': 0.5036989269035296}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:53,755] Trial 26 finished with value: 0.5 and parameters: {'learning_rate': 0.0151593749407932, 'max_depth': 4, 'num_leaves': 138, 'min_child_samples': 24, 'subsample': 0.7078356957104769, 'colsample_bytree': 0.994828357569345, 'reg_alpha': 0.13960916293884665, 'reg_lambda': 0.7908294564499905}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:53,844] Trial 27 finished with value: 0.6875 and parameters: {'learning_rate': 0.005206390856782866, 'max_depth': 3, 'num_leaves': 101, 'min_child_samples': 17, 'subsample': 0.6298193833717883, 'colsample_bytree': 0.8231709760673158, 'reg_alpha': 0.07584734996638434, 'reg_lambda': 0.36235596963852756}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:53,930] Trial 28 finished with value: 0.5 and parameters: {'learning_rate': 0.002580539392008553, 'max_depth': 5, 'num_leaves': 141, 'min_child_samples': 40, 'subsample': 0.5591215427272825, 'colsample_bytree': 0.9212669447355666, 'reg_alpha': 0.02845921912916718, 'reg_lambda': 0.23427273428378773}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:54,100] Trial 29 finished with value: 0.5 and parameters: {'learning_rate': 0.0017067758899069595, 'max_depth': 4, 'num_leaves': 119, 'min_child_samples': 30, 'subsample': 0.6753815268947089, 'colsample_bytree': 0.9576850613520599, 'reg_alpha': 0.011135802487701699, 'reg_lambda': 0.6258431815507023}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:54,201] Trial 30 finished with value: 0.5 and parameters: {'learning_rate': 0.0038621580025237335, 'max_depth': 6, 'num_leaves': 149, 'min_child_samples': 100, 'subsample': 0.7710421257365713, 'colsample_bytree': 0.8650883305197001, 'reg_alpha': 0.05547502801156632, 'reg_lambda': 0.968264013132682}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:54,290] Trial 31 finished with value: 0.3125 and parameters: {'learning_rate': 0.007474571598142086, 'max_depth': 7, 'num_leaves': 74, 'min_child_samples': 18, 'subsample': 0.8430558822964218, 'colsample_bytree': 0.9999607536714772, 'reg_alpha': 0.04329827673939506, 'reg_lambda': 0.1621640080890348}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:54,367] Trial 32 finished with value: 0.6875 and parameters: {'learning_rate': 0.006532845042437692, 'max_depth': 5, 'num_leaves': 77, 'min_child_samples': 15, 'subsample': 0.8579852700096755, 'colsample_bytree': 0.9693153827311299, 'reg_alpha': 0.042958930942952035, 'reg_lambda': 0.19702749337441305}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:54,455] Trial 33 finished with value: 0.5 and parameters: {'learning_rate': 0.008023629386556009, 'max_depth': 7, 'num_leaves': 102, 'min_child_samples': 25, 'subsample': 0.83796943652756, 'colsample_bytree': 0.9986368783897478, 'reg_alpha': 0.10895983234832039, 'reg_lambda': 0.33916808833211376}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:54,550] Trial 34 finished with value: 0.5 and parameters: {'learning_rate': 0.011801537002293026, 'max_depth': 6, 'num_leaves': 92, 'min_child_samples': 26, 'subsample': 0.786493833858974, 'colsample_bytree': 0.905348976501151, 'reg_alpha': 0.015558684356603623, 'reg_lambda': 0.43644411152634377}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:54,662] Trial 35 finished with value: 0.5 and parameters: {'learning_rate': 0.01605474908038112, 'max_depth': 8, 'num_leaves': 124, 'min_child_samples': 33, 'subsample': 0.7341034041421719, 'colsample_bytree': 0.9541679567819356, 'reg_alpha': 0.02005296333238518, 'reg_lambda': 0.2472567078392217}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:54,748] Trial 36 finished with value: 0.5 and parameters: {'learning_rate': 0.004896637741155574, 'max_depth': 3, 'num_leaves': 69, 'min_child_samples': 23, 'subsample': 0.6839069294389225, 'colsample_bytree': 0.9642985280031404, 'reg_alpha': 0.17843888560704593, 'reg_lambda': 0.6823748838814923}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:54,835] Trial 37 finished with value: 0.6875 and parameters: {'learning_rate': 0.024195090903005763, 'max_depth': 8, 'num_leaves': 142, 'min_child_samples': 15, 'subsample': 0.8318575258308148, 'colsample_bytree': 0.9071190432572303, 'reg_alpha': 0.02947981810594599, 'reg_lambda': 0.4470051191504436}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:54,914] Trial 38 finished with value: 0.5 and parameters: {'learning_rate': 0.0028581668548902307, 'max_depth': 5, 'num_leaves': 54, 'min_child_samples': 62, 'subsample': 0.6362010574633806, 'colsample_bytree': 0.883006122049371, 'reg_alpha': 0.08184025471603718, 'reg_lambda': 0.14025702278896135}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:54,995] Trial 39 finished with value: 0.5 and parameters: {'learning_rate': 0.0089657646095459, 'max_depth': 4, 'num_leaves': 134, 'min_child_samples': 89, 'subsample': 0.6989797141803095, 'colsample_bytree': 0.7912068127940506, 'reg_alpha': 0.03948363721161349, 'reg_lambda': 0.08052363459277356}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:55,077] Trial 40 finished with value: 0.5 and parameters: {'learning_rate': 0.006126822777903275, 'max_depth': 7, 'num_leaves': 44, 'min_child_samples': 47, 'subsample': 0.7435246403760285, 'colsample_bytree': 0.9993372659365871, 'reg_alpha': 0.010068006712039319, 'reg_lambda': 0.20808849142664015}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:55,162] Trial 41 finished with value: 0.34375 and parameters: {'learning_rate': 0.025985812529476827, 'max_depth': 7, 'num_leaves': 62, 'min_child_samples': 19, 'subsample': 0.9400264848076703, 'colsample_bytree': 0.7324466423111211, 'reg_alpha': 0.04569515164171735, 'reg_lambda': 0.1495898858539188}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:55,247] Trial 42 finished with value: 0.875 and parameters: {'learning_rate': 0.003428799350334853, 'max_depth': 6, 'num_leaves': 74, 'min_child_samples': 14, 'subsample': 0.9141427027555571, 'colsample_bytree': 0.6194595750344423, 'reg_alpha': 0.06238451430869672, 'reg_lambda': 0.11592515557120503}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:55,326] Trial 43 finished with value: 0.5 and parameters: {'learning_rate': 0.007611470003741021, 'max_depth': 8, 'num_leaves': 83, 'min_child_samples': 29, 'subsample': 0.9478745548953909, 'colsample_bytree': 0.9681825416306843, 'reg_alpha': 0.025340555794606926, 'reg_lambda': 0.29456657244982826}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:55,411] Trial 44 finished with value: 0.625 and parameters: {'learning_rate': 0.0019237164332352149, 'max_depth': 7, 'num_leaves': 51, 'min_child_samples': 10, 'subsample': 0.859523102123571, 'colsample_bytree': 0.9444286661902784, 'reg_alpha': 0.036933143927063934, 'reg_lambda': 0.05802283316452245}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:55,492] Trial 45 finished with value: 0.34375 and parameters: {'learning_rate': 0.011241777341781984, 'max_depth': 5, 'num_leaves': 60, 'min_child_samples': 20, 'subsample': 0.7879813561634442, 'colsample_bytree': 0.7739826970748028, 'reg_alpha': 0.05006221900741047, 'reg_lambda': 0.17012033792017273}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:55,605] Trial 46 finished with value: 0.5 and parameters: {'learning_rate': 0.004402259744096498, 'max_depth': 8, 'num_leaves': 67, 'min_child_samples': 36, 'subsample': 0.8829163652075752, 'colsample_bytree': 0.7119515597537796, 'reg_alpha': 0.1005884029789077, 'reg_lambda': 0.03008980494486998}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:55,680] Trial 47 finished with value: 0.5 and parameters: {'learning_rate': 0.03599919795582961, 'max_depth': 6, 'num_leaves': 78, 'min_child_samples': 27, 'subsample': 0.5109413134575591, 'colsample_bytree': 0.6383678150881619, 'reg_alpha': 0.28906766502964387, 'reg_lambda': 0.09156572018001112}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:55,759] Trial 48 finished with value: 0.5 and parameters: {'learning_rate': 0.0179741976077237, 'max_depth': 3, 'num_leaves': 93, 'min_child_samples': 59, 'subsample': 0.9954124229479092, 'colsample_bytree': 0.8213624113658845, 'reg_alpha': 0.01419493008073516, 'reg_lambda': 0.5008694008439379}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:55,837] Trial 49 finished with value: 0.5 and parameters: {'learning_rate': 0.06636491377412788, 'max_depth': 7, 'num_leaves': 105, 'min_child_samples': 75, 'subsample': 0.92153446943116, 'colsample_bytree': 0.9208638841806942, 'reg_alpha': 0.0704296512156635, 'reg_lambda': 0.3587657501840305}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:55,920] Trial 50 finished with value: 0.4375 and parameters: {'learning_rate': 0.013782136402055665, 'max_depth': 5, 'num_leaves': 46, 'min_child_samples': 19, 'subsample': 0.8127413161244365, 'colsample_bytree': 0.5757493589151381, 'reg_alpha': 0.05150407697692085, 'reg_lambda': 0.12364240212883057}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:56,051] Trial 51 finished with value: 0.6875 and parameters: {'learning_rate': 0.024874659748080407, 'max_depth': 7, 'num_leaves': 57, 'min_child_samples': 17, 'subsample': 0.9516405303428186, 'colsample_bytree': 0.7360216059319254, 'reg_alpha': 0.04282297397809954, 'reg_lambda': 0.16791921848191607}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:56,129] Trial 52 finished with value: 0.75 and parameters: {'learning_rate': 0.056810254553515536, 'max_depth': 7, 'num_leaves': 62, 'min_child_samples': 22, 'subsample': 0.9622350248119937, 'colsample_bytree': 0.7004187277491352, 'reg_alpha': 0.04421889375016402, 'reg_lambda': 0.1364204370356913}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:56,213] Trial 53 finished with value: 0.6875 and parameters: {'learning_rate': 0.08863388198102196, 'max_depth': 6, 'num_leaves': 70, 'min_child_samples': 13, 'subsample': 0.9332984946384484, 'colsample_bytree': 0.7589884803295405, 'reg_alpha': 0.033391727211435115, 'reg_lambda': 0.0798936210791368}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:56,293] Trial 54 finished with value: 0.34375 and parameters: {'learning_rate': 0.03477722231593767, 'max_depth': 9, 'num_leaves': 63, 'min_child_samples': 19, 'subsample': 0.8798738943832579, 'colsample_bytree': 0.7391782035072987, 'reg_alpha': 0.08818008651908787, 'reg_lambda': 0.23967715940336365}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:56,373] Trial 55 finished with value: 0.5 and parameters: {'learning_rate': 0.009315123179434545, 'max_depth': 7, 'num_leaves': 25, 'min_child_samples': 25, 'subsample': 0.9712219401488829, 'colsample_bytree': 0.6529986272612535, 'reg_alpha': 0.12229036147845151, 'reg_lambda': 0.1539211688760799}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:56,454] Trial 56 finished with value: 0.5 and parameters: {'learning_rate': 0.00574944069917883, 'max_depth': 4, 'num_leaves': 87, 'min_child_samples': 32, 'subsample': 0.901711738500236, 'colsample_bytree': 0.9796641924748972, 'reg_alpha': 0.026799086683292644, 'reg_lambda': 0.8279534521743361}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:56,561] Trial 57 finished with value: 0.625 and parameters: {'learning_rate': 0.001355444614496229, 'max_depth': 8, 'num_leaves': 146, 'min_child_samples': 10, 'subsample': 0.5817410770983269, 'colsample_bytree': 0.7127677524846062, 'reg_alpha': 0.055879771754868746, 'reg_lambda': 0.29960643497925404}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:56,642] Trial 58 finished with value: 0.6875 and parameters: {'learning_rate': 0.021608588647816805, 'max_depth': 9, 'num_leaves': 130, 'min_child_samples': 17, 'subsample': 0.6500072650997396, 'colsample_bytree': 0.7827407930955469, 'reg_alpha': 0.020310589292267638, 'reg_lambda': 0.04343647053289993}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:56,721] Trial 59 finished with value: 0.5 and parameters: {'learning_rate': 0.03066851267185394, 'max_depth': 6, 'num_leaves': 39, 'min_child_samples': 54, 'subsample': 0.5352376867439148, 'colsample_bytree': 0.8531843357248748, 'reg_alpha': 0.033630175134707924, 'reg_lambda': 0.6978008351308274}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:56,806] Trial 60 finished with value: 0.5 and parameters: {'learning_rate': 0.04657299526510618, 'max_depth': 8, 'num_leaves': 135, 'min_child_samples': 29, 'subsample': 0.84076253378403, 'colsample_bytree': 0.8880011531821972, 'reg_alpha': 0.526153441154388, 'reg_lambda': 0.20495077296248884}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:56,887] Trial 61 finished with value: 0.390625 and parameters: {'learning_rate': 0.0075256892712112925, 'max_depth': 5, 'num_leaves': 48, 'min_child_samples': 21, 'subsample': 0.7511732441977756, 'colsample_bytree': 0.7715994512662194, 'reg_alpha': 0.05000563486097002, 'reg_lambda': 0.16889967170588527}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:56,971] Trial 62 finished with value: 0.34375 and parameters: {'learning_rate': 0.011089783870147763, 'max_depth': 4, 'num_leaves': 60, 'min_child_samples': 20, 'subsample': 0.7847623617418961, 'colsample_bytree': 0.7999425689719997, 'reg_alpha': 0.06281516476619729, 'reg_lambda': 0.1109265880198997}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:57,070] Trial 63 finished with value: 0.6875 and parameters: {'learning_rate': 0.010038802678855055, 'max_depth': 5, 'num_leaves': 64, 'min_child_samples': 13, 'subsample': 0.7208210290485231, 'colsample_bytree': 0.6898021788749978, 'reg_alpha': 0.9739265136176292, 'reg_lambda': 0.2522244814019471}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:57,161] Trial 64 finished with value: 0.5 and parameters: {'learning_rate': 0.0043816115343806574, 'max_depth': 5, 'num_leaves': 73, 'min_child_samples': 23, 'subsample': 0.8037608663795177, 'colsample_bytree': 0.9788808955099093, 'reg_alpha': 0.04908905529757143, 'reg_lambda': 0.14338944670763598}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:57,256] Trial 65 finished with value: 0.34375 and parameters: {'learning_rate': 0.0030948312195810067, 'max_depth': 7, 'num_leaves': 145, 'min_child_samples': 18, 'subsample': 0.7799497198596301, 'colsample_bytree': 0.7234474998887669, 'reg_alpha': 0.038348049919006554, 'reg_lambda': 0.5112693801844773}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:57,354] Trial 66 finished with value: 0.875 and parameters: {'learning_rate': 0.0010383421504300621, 'max_depth': 6, 'num_leaves': 58, 'min_child_samples': 14, 'subsample': 0.7360748968508176, 'colsample_bytree': 0.7522396510867865, 'reg_alpha': 0.07350055568092348, 'reg_lambda': 0.09733296937522092}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:57,437] Trial 67 finished with value: 0.5 and parameters: {'learning_rate': 0.012910160622144977, 'max_depth': 5, 'num_leaves': 79, 'min_child_samples': 23, 'subsample': 0.7689935037340307, 'colsample_bytree': 0.951444836786089, 'reg_alpha': 0.0227823789366576, 'reg_lambda': 0.42603497774731075}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:57,536] Trial 68 finished with value: 0.671875 and parameters: {'learning_rate': 0.06882424279757168, 'max_depth': 4, 'num_leaves': 108, 'min_child_samples': 16, 'subsample': 0.6916385214172096, 'colsample_bytree': 0.9833915380910776, 'reg_alpha': 0.029668641755014658, 'reg_lambda': 0.18672870563755697}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:57,673] Trial 69 finished with value: 0.5 and parameters: {'learning_rate': 0.01761102616863971, 'max_depth': 6, 'num_leaves': 126, 'min_child_samples': 27, 'subsample': 0.9275122618410192, 'colsample_bytree': 0.5445948512150247, 'reg_alpha': 0.04543696774024382, 'reg_lambda': 0.012606398232738302}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:57,757] Trial 70 finished with value: 0.5 and parameters: {'learning_rate': 0.002157808929803517, 'max_depth': 4, 'num_leaves': 53, 'min_child_samples': 40, 'subsample': 0.554602760709894, 'colsample_bytree': 0.8202113812187384, 'reg_alpha': 0.054890005724208595, 'reg_lambda': 0.3268338977279227}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:57,842] Trial 71 finished with value: 0.34375 and parameters: {'learning_rate': 0.03041191783982754, 'max_depth': 9, 'num_leaves': 69, 'min_child_samples': 19, 'subsample': 0.8673015151384045, 'colsample_bytree': 0.7270120532024892, 'reg_alpha': 0.09192244037696572, 'reg_lambda': 0.2036152823662174}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:57,928] Trial 72 finished with value: 0.390625 and parameters: {'learning_rate': 0.03950939897339678, 'max_depth': 10, 'num_leaves': 61, 'min_child_samples': 21, 'subsample': 0.896554042969463, 'colsample_bytree': 0.7753881866023198, 'reg_alpha': 0.0838796892168501, 'reg_lambda': 0.23736144073100987}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:58,012] Trial 73 finished with value: 0.625 and parameters: {'learning_rate': 0.05190228542684681, 'max_depth': 5, 'num_leaves': 65, 'min_child_samples': 12, 'subsample': 0.8850244923009715, 'colsample_bytree': 0.7435163503628016, 'reg_alpha': 0.11715426626896923, 'reg_lambda': 0.39195541822528673}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:58,127] Trial 74 finished with value: 0.34375 and parameters: {'learning_rate': 0.007007887510121347, 'max_depth': 9, 'num_leaves': 96, 'min_child_samples': 19, 'subsample': 0.8332149291133016, 'colsample_bytree': 0.6670255642484229, 'reg_alpha': 0.03737507732975774, 'reg_lambda': 0.2787447628318071}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:58,215] Trial 75 finished with value: 0.5 and parameters: {'learning_rate': 0.020746682863285047, 'max_depth': 10, 'num_leaves': 82, 'min_child_samples': 26, 'subsample': 0.9435595651243367, 'colsample_bytree': 0.9283290013109168, 'reg_alpha': 0.06959198107159095, 'reg_lambda': 0.12835395070279013}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:58,315] Trial 76 finished with value: 0.5 and parameters: {'learning_rate': 0.014896142223727066, 'max_depth': 7, 'num_leaves': 73, 'min_child_samples': 31, 'subsample': 0.8745572200619338, 'colsample_bytree': 0.7617047961421628, 'reg_alpha': 0.20832606882827712, 'reg_lambda': 0.1575710205055032}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:58,397] Trial 77 finished with value: 0.5 and parameters: {'learning_rate': 0.0056048017249040166, 'max_depth': 4, 'num_leaves': 50, 'min_child_samples': 35, 'subsample': 0.8227196348899566, 'colsample_bytree': 0.9696256922335003, 'reg_alpha': 0.17004654460184038, 'reg_lambda': 0.219993885074349}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:58,480] Trial 78 finished with value: 0.5 and parameters: {'learning_rate': 0.0303205371973357, 'max_depth': 3, 'num_leaves': 118, 'min_child_samples': 84, 'subsample': 0.9095257575242234, 'colsample_bytree': 0.8378636946129612, 'reg_alpha': 0.055693807636235985, 'reg_lambda': 0.26207704249073255}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:58,570] Trial 79 finished with value: 0.6875 and parameters: {'learning_rate': 0.07609660890741363, 'max_depth': 5, 'num_leaves': 42, 'min_child_samples': 15, 'subsample': 0.8480370648593749, 'colsample_bytree': 0.7418246157901482, 'reg_alpha': 0.09455269342063974, 'reg_lambda': 0.3187180125380891}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:58,669] Trial 80 finished with value: 0.625 and parameters: {'learning_rate': 0.008910888970549936, 'max_depth': 6, 'num_leaves': 54, 'min_child_samples': 12, 'subsample': 0.6563271342681052, 'colsample_bytree': 0.8074382460963911, 'reg_alpha': 0.04120596538196266, 'reg_lambda': 0.5451962436579003}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:58,791] Trial 81 finished with value: 0.34375 and parameters: {'learning_rate': 0.01084692111028722, 'max_depth': 4, 'num_leaves': 60, 'min_child_samples': 20, 'subsample': 0.7582020243272168, 'colsample_bytree': 0.7957837295376557, 'reg_alpha': 0.06599893864912722, 'reg_lambda': 0.12187269810964213}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:58,889] Trial 82 finished with value: 0.5 and parameters: {'learning_rate': 0.010475909983952396, 'max_depth': 3, 'num_leaves': 57, 'min_child_samples': 23, 'subsample': 0.7915323284463068, 'colsample_bytree': 0.999702467588949, 'reg_alpha': 0.07964159458827154, 'reg_lambda': 0.10657498758977203}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:58,987] Trial 83 finished with value: 0.34375 and parameters: {'learning_rate': 0.0121254959322082, 'max_depth': 4, 'num_leaves': 63, 'min_child_samples': 18, 'subsample': 0.7947310676932965, 'colsample_bytree': 0.7992867747818377, 'reg_alpha': 0.0633968485885346, 'reg_lambda': 0.08607956910862374}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:59,144] Trial 84 finished with value: 0.5 and parameters: {'learning_rate': 0.09589494692214852, 'max_depth': 8, 'num_leaves': 68, 'min_child_samples': 29, 'subsample': 0.8165012639968903, 'colsample_bytree': 0.7039751759444789, 'reg_alpha': 0.0470826394612534, 'reg_lambda': 0.1106915887038529}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:59,267] Trial 85 finished with value: 0.5 and parameters: {'learning_rate': 0.00842553678509558, 'max_depth': 4, 'num_leaves': 71, 'min_child_samples': 25, 'subsample': 0.7784650187109503, 'colsample_bytree': 0.9578378736042219, 'reg_alpha': 0.02973631022826799, 'reg_lambda': 0.06957212893093645}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:59,404] Trial 86 finished with value: 0.3125 and parameters: {'learning_rate': 0.004714320523994297, 'max_depth': 7, 'num_leaves': 138, 'min_child_samples': 20, 'subsample': 0.7331330398732775, 'colsample_bytree': 0.9881925716852457, 'reg_alpha': 0.03425257310073987, 'reg_lambda': 0.15545339865327504}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:59,508] Trial 87 finished with value: 0.6875 and parameters: {'learning_rate': 0.004165793146782093, 'max_depth': 7, 'num_leaves': 150, 'min_child_samples': 15, 'subsample': 0.7378269789305084, 'colsample_bytree': 0.9427220904599214, 'reg_alpha': 0.024678012295882856, 'reg_lambda': 0.17462616346279802}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:59,605] Trial 88 finished with value: 0.5 and parameters: {'learning_rate': 0.004906588317158297, 'max_depth': 7, 'num_leaves': 145, 'min_child_samples': 27, 'subsample': 0.6199333620002745, 'colsample_bytree': 0.9890411102223082, 'reg_alpha': 0.036451808301591275, 'reg_lambda': 0.14701120088029954}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:59,717] Trial 89 finished with value: 0.734375 and parameters: {'learning_rate': 0.0053923261487577884, 'max_depth': 8, 'num_leaves': 141, 'min_child_samples': 10, 'subsample': 0.7048405400955966, 'colsample_bytree': 0.972986015544073, 'reg_alpha': 0.01804388745664107, 'reg_lambda': 0.393172779930138}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:59,828] Trial 90 finished with value: 0.6875 and parameters: {'learning_rate': 0.006645959863503657, 'max_depth': 6, 'num_leaves': 136, 'min_child_samples': 17, 'subsample': 0.7158779099853376, 'colsample_bytree': 0.9585687328320375, 'reg_alpha': 0.030798448663538223, 'reg_lambda': 0.22930734584904744}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:57:59,937] Trial 91 finished with value: 0.390625 and parameters: {'learning_rate': 0.006114723891463648, 'max_depth': 7, 'num_leaves': 66, 'min_child_samples': 21, 'subsample': 0.7631726766744251, 'colsample_bytree': 0.7795789434100302, 'reg_alpha': 0.05774353742417954, 'reg_lambda': 0.18617592169384087}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:58:00,047] Trial 92 finished with value: 0.34375 and parameters: {'learning_rate': 0.0073219197559578, 'max_depth': 7, 'num_leaves': 58, 'min_child_samples': 20, 'subsample': 0.7264396191930752, 'colsample_bytree': 0.7572558482581206, 'reg_alpha': 0.0426787064820889, 'reg_lambda': 0.1286595821429868}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:58:00,138] Trial 93 finished with value: 0.5 and parameters: {'learning_rate': 0.014133707222849984, 'max_depth': 5, 'num_leaves': 147, 'min_child_samples': 24, 'subsample': 0.8535495991546799, 'colsample_bytree': 0.9922990458586899, 'reg_alpha': 0.03353348873720096, 'reg_lambda': 0.16079742646485207}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:58:00,253] Trial 94 finished with value: 0.5 and parameters: {'learning_rate': 0.003763954450643412, 'max_depth': 7, 'num_leaves': 138, 'min_child_samples': 68, 'subsample': 0.8015723647235088, 'colsample_bytree': 0.7342053993808392, 'reg_alpha': 0.02709064049452164, 'reg_lambda': 0.46253390107081976}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:58:00,341] Trial 95 finished with value: 0.875 and parameters: {'learning_rate': 0.011418047484581804, 'max_depth': 5, 'num_leaves': 51, 'min_child_samples': 14, 'subsample': 0.7537754716611285, 'colsample_bytree': 0.7191885506583572, 'reg_alpha': 0.060229000515181576, 'reg_lambda': 0.6138211811400908}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:58:00,425] Trial 96 finished with value: 0.6875 and parameters: {'learning_rate': 0.016632514571935313, 'max_depth': 4, 'num_leaves': 76, 'min_child_samples': 16, 'subsample': 0.9814510405186855, 'colsample_bytree': 0.6892247935928386, 'reg_alpha': 0.04958706803774072, 'reg_lambda': 0.1155070265332712}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:58:00,513] Trial 97 finished with value: 0.75 and parameters: {'learning_rate': 0.008042716941213626, 'max_depth': 6, 'num_leaves': 143, 'min_child_samples': 22, 'subsample': 0.7449601943065602, 'colsample_bytree': 0.934583537963396, 'reg_alpha': 0.10307537873227089, 'reg_lambda': 0.09511197721205936}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:58:00,611] Trial 98 finished with value: 0.3125 and parameters: {'learning_rate': 0.00476605499335736, 'max_depth': 3, 'num_leaves': 132, 'min_child_samples': 19, 'subsample': 0.99602714246255, 'colsample_bytree': 0.9216266912500652, 'reg_alpha': 0.08556197409872264, 'reg_lambda': 0.27000022153797504}. Best is trial 17 with value: 0.3125.\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
      "C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_1796\\147230598.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
      "[I 2025-04-08 19:58:00,720] Trial 99 finished with value: 0.625 and parameters: {'learning_rate': 0.0032742561069450597, 'max_depth': 3, 'num_leaves': 132, 'min_child_samples': 12, 'subsample': 0.9992847398350101, 'colsample_bytree': 0.9163568657626725, 'reg_alpha': 0.15340465216737748, 'reg_lambda': 0.2699868483775564}. Best is trial 17 with value: 0.3125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros:\n",
      "{'learning_rate': 0.0060879287457853756, 'max_depth': 5, 'num_leaves': 150, 'min_child_samples': 19, 'subsample': 0.5888688993422226, 'colsample_bytree': 0.9894440056432319, 'reg_alpha': 0.028167170246414498, 'reg_lambda': 0.3512269210856065}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"n_estimators\": 2000,\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 150),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 100),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 1.0),\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**param, early_stopping_rounds=50)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=\"auc\",\n",
    "\n",
    "    )\n",
    "\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    return 1 - auc  # Minimizar: 1 - AUC\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Mejores hiperparámetros:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.638026\n",
      "Accuracy: 0.6666666666666666\n",
      "AUC: 0.6875\n",
      "Mean Squared Error: 0.22291002598266027\n"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(**study.best_params, early_stopping_rounds=50)\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = model.predict(X_test)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "mse = mean_squared_error(y_test, y_pred_proba)\n",
    "acc = model.score(X_test, y_test)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"AUC: {auc}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
